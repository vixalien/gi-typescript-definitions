
/// <reference path="./GLib-2.0.d.ts" />
/// <reference path="./GModule-2.0.d.ts" />
/// <reference path="./GObject-2.0.d.ts" />
/// <reference path="./Gst-1.0.d.ts" />
/// <reference path="./GstBase-1.0.d.ts" />
/// <reference path="./GstVideo-1.0.d.ts" />

/**
 * Type Definitions for GJS (https://gjs.guide/), generated by [GirGen](https://github.com/aylur/girgen)
 * If you found a bug, create a bug report on [GirGen's Repository](https://github.com/aylur/girgen/issues/new)
 */
declare module "gi://GstCodecs?version=1.0" {
    import type GLib from "gi://GLib?version=2.0"
    import type GModule from "gi://GModule?version=2.0"
    import type GObject from "gi://GObject?version=2.0"
    import type Gst from "gi://Gst?version=1.0"
    import type GstBase from "gi://GstBase?version=1.0"
    import type GstVideo from "gi://GstVideo?version=1.0"

    


    namespace GstCodecs {
        const __name__: "GstCodecs"
        const __version: "1.0"
        

        namespace AV1Decoder {
            interface SignalSignatures extends GstVideo.VideoDecoder.SignalSignatures {
            }

            interface ReadableProperties extends GstVideo.VideoDecoder.ReadableProperties {
            }

            interface WritableProperties extends GstVideo.VideoDecoder.WritableProperties {
            }

            interface ConstructOnlyProperties extends GstVideo.VideoDecoder.ConstructOnlyProperties {
            }
        }

        /**
         * The opaque #GstAV1Decoder data structure.
         * @since 1.20
         */
        interface AV1Decoder extends GstVideo.VideoDecoder {
            readonly $signals: AV1Decoder.SignalSignatures
            readonly $readableProperties: AV1Decoder.ReadableProperties
            readonly $writableProperties: AV1Decoder.WritableProperties
            readonly $constructOnlyProperties: AV1Decoder.ConstructOnlyProperties
            /**
             * Provides the tile data with tile group header and required raw
             * bitstream for subclass to decode it.
             * @since 1.20
             * @param picture a #GstAV1Picture
             * @param tile a #GstAV1Tile
             */
            vfunc_decode_tile(picture: AV1Picture, tile: AV1Tile): Gst.FlowReturn
            /**
             * Called when need to duplicate an existing #GstAV1Picture. As
             * duplicated key-frame will populate the DPB, this virtual
             * function is not optional.
             * @since 1.22
             * @param frame the current #GstVideoCodecFrame
             * @param picture a #GstAV1Picture
             */
            vfunc_duplicate_picture(frame: GstVideo.VideoCodecFrame, picture: AV1Picture): AV1Picture
            /**
             * Optional. Called per one #GstAV1Picture to notify subclass to finish
             * decoding process for the #GstAV1Picture
             * @since 1.20
             * @param picture a #GstAV1Picture
             */
            vfunc_end_picture(picture: AV1Picture): Gst.FlowReturn
            /**
             * Optional. Called by baseclass to query whether delaying output is
             * preferred by subclass or not.
             * @since 1.22
             * @param live whether upstream is live or not
             * @returns the number of perferred delayed output frame
             */
            vfunc_get_preferred_output_delay(live: boolean): number
            /**
             * Optional. Called whenever new #GstAV1Picture is created.
             * Subclass can set implementation specific user data
             * on the #GstAV1Picture via gst_av1_picture_set_user_data
             * @since 1.20
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstAV1Picture
             */
            vfunc_new_picture(frame: GstVideo.VideoCodecFrame, picture: AV1Picture): Gst.FlowReturn
            /**
             * Called with a #GstAV1Picture which is required to be outputted.
             * The #GstVideoCodecFrame must be consumed by subclass.
             * @since 1.20
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstAV1Picture
             */
            vfunc_output_picture(frame: GstVideo.VideoCodecFrame, picture: AV1Picture): Gst.FlowReturn
            /**
             * Optional. Called per one #GstAV1Picture to notify subclass to prepare
             * decoding process for the #GstAV1Picture
             * @since 1.20
             * @param picture a #GstAV1Picture
             * @param dpb a #GstAV1Dpb
             */
            vfunc_start_picture(picture: AV1Picture, dpb: AV1Dpb): Gst.FlowReturn
        }

        interface AV1DecoderClass extends Omit<GstVideo.VideoDecoderClass, "new"> {
            readonly $gtype: GObject.GType<AV1Decoder>
            readonly prototype: AV1Decoder
            new (props?: Partial<GObject.ConstructorProps<AV1Decoder>>): AV1Decoder
        }

        const AV1Decoder: AV1DecoderClass
        

        namespace H264Decoder {
            interface SignalSignatures extends GstVideo.VideoDecoder.SignalSignatures {
            }

            interface ReadableProperties extends GstVideo.VideoDecoder.ReadableProperties {
                "compliance": H264DecoderCompliance
            }

            interface WritableProperties extends GstVideo.VideoDecoder.WritableProperties {
                "compliance": H264DecoderCompliance
            }

            interface ConstructOnlyProperties extends GstVideo.VideoDecoder.ConstructOnlyProperties {
            }
        }

        /**
         * The opaque #GstH264Decoder data structure.
         */
        interface H264Decoder extends GstVideo.VideoDecoder {
            readonly $signals: H264Decoder.SignalSignatures
            readonly $readableProperties: H264Decoder.ReadableProperties
            readonly $writableProperties: H264Decoder.WritableProperties
            readonly $constructOnlyProperties: H264Decoder.ConstructOnlyProperties
            /**
             * The compliance controls the behavior of the decoder to handle some
             * subtle cases and contexts, such as the low-latency DPB bumping or
             * mapping the baseline profile as the constrained-baseline profile,
             * etc.
             * @since 1.20
             * @default GST_H264_DECODER_COMPLIANCE_AUTO
             */
            get compliance(): H264DecoderCompliance
            set compliance(value: H264DecoderCompliance)
            /**
             * Retrive DPB and return a #GstH264Picture corresponding to
             * the @system_frame_number
             * @since 1.18
             * @param system_frame_number a target system frame number of #GstH264Picture
             * @returns a #GstH264Picture if successful, or %NULL otherwise
             */
            get_picture(system_frame_number: number): H264Picture | null
            /**
             * Called to en/disable reference picture modification process.
             * @since 1.18
             * @param process whether subclass is requiring reference picture modification process
             */
            set_process_ref_pic_lists(process: boolean): void
            /**
             * Provides per slice data with parsed slice header and required raw bitstream
             * for subclass to decode it. If gst_h264_decoder_set_process_ref_pic_lists()
             * is called with %TRUE by the subclass, @ref_pic_list0 and @ref_pic_list1
             * are non-%NULL.
             * In case of interlaced stream, @ref_pic_list0 and @ref_pic_list1 will
             * contain only the first field of complementary reference field pair
             * if currently being decoded picture is a frame picture. Subclasses might
             * need to retrive the other field (i.e., the second field) of the picture
             * if needed.
             * @param picture a #GstH264Picture
             * @param slice a #GstH264Slice
             * @param ref_pic_list0 
               an array of #GstH264Picture pointers
             * @param ref_pic_list1 
               an array of #GstH264Picture pointers
             */
            vfunc_decode_slice(picture: H264Picture, slice: H264Slice, ref_pic_list0: H264Picture[], ref_pic_list1: H264Picture[]): Gst.FlowReturn
            /**
             * Optional. Called per one #GstH264Picture to notify subclass to finish
             * decoding process for the #GstH264Picture
             * @param picture a #GstH264Picture
             */
            vfunc_end_picture(picture: H264Picture): Gst.FlowReturn
            /**
             * Optional. Called by baseclass to query whether delaying output is
             * preferred by subclass or not.
             * @since 1.20
             * @param live whether upstream is live or not
             * @returns the number of perferred delayed output frame
             */
            vfunc_get_preferred_output_delay(live: boolean): number
            /**
             * Called when a new field picture is created for interlaced field picture.
             * Subclass can attach implementation specific user data on @second_field via
             * gst_h264_picture_set_user_data
             * @since 1.20
             * @param first_field the first field #GstH264Picture already decoded
             * @param second_field a #GstH264Picture for the second field
             */
            vfunc_new_field_picture(first_field: H264Picture, second_field: H264Picture): Gst.FlowReturn
            /**
             * Optional. Called whenever new #GstH264Picture is created.
             * Subclass can set implementation specific user data
             * on the #GstH264Picture via gst_h264_picture_set_user_data
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstH264Picture
             */
            vfunc_new_picture(frame: GstVideo.VideoCodecFrame, picture: H264Picture): Gst.FlowReturn
            /**
             * Called with a #GstH264Picture which is required to be outputted.
             * The #GstVideoCodecFrame must be consumed by subclass.
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstH264Picture
             */
            vfunc_output_picture(frame: GstVideo.VideoCodecFrame, picture: H264Picture): Gst.FlowReturn
            /**
             * Optional. Called per one #GstH264Picture to notify subclass to prepare
             * decoding process for the #GstH264Picture
             * @param picture a #GstH264Picture
             * @param slice a #GstH264Slice
             * @param dpb a #GstH264Dpb
             */
            vfunc_start_picture(picture: H264Picture, slice: H264Slice, dpb: H264Dpb): Gst.FlowReturn
        }

        interface H264DecoderClass extends Omit<GstVideo.VideoDecoderClass, "new"> {
            readonly $gtype: GObject.GType<H264Decoder>
            readonly prototype: H264Decoder
            new (props?: Partial<GObject.ConstructorProps<H264Decoder>>): H264Decoder
        }

        const H264Decoder: H264DecoderClass
        

        namespace H265Decoder {
            interface SignalSignatures extends GstVideo.VideoDecoder.SignalSignatures {
            }

            interface ReadableProperties extends GstVideo.VideoDecoder.ReadableProperties {
            }

            interface WritableProperties extends GstVideo.VideoDecoder.WritableProperties {
            }

            interface ConstructOnlyProperties extends GstVideo.VideoDecoder.ConstructOnlyProperties {
            }
        }

        /**
         * The opaque #GstH265Decoder data structure.
         */
        interface H265Decoder extends GstVideo.VideoDecoder {
            readonly $signals: H265Decoder.SignalSignatures
            readonly $readableProperties: H265Decoder.ReadableProperties
            readonly $writableProperties: H265Decoder.WritableProperties
            readonly $constructOnlyProperties: H265Decoder.ConstructOnlyProperties
            /**
             * Retrive DPB and return a #GstH265Picture corresponding to
             * the @system_frame_number
             * @since 1.20
             * @param system_frame_number a target system frame number of #GstH265Picture
             * @returns a #GstH265Picture if successful, or %NULL otherwise
             */
            get_picture(system_frame_number: number): H265Picture | null
            /**
             * Called to en/disable reference picture modification process.
             * @since 1.20
             * @param process whether subclass is requiring reference picture modification process
             */
            set_process_ref_pic_lists(process: boolean): void
            /**
             * Provides per slice data with parsed slice header and required raw bitstream
             * for subclass to decode it. If gst_h265_decoder_set_process_ref_pic_lists()
             * is called with %TRUE by the subclass, @ref_pic_list0 and @ref_pic_list1
             * are non-%NULL.
             * @param picture a #GstH265Picture
             * @param slice a #GstH265Slice
             * @param ref_pic_list0 
               an array of #GstH265Picture pointers
             * @param ref_pic_list1 
               an array of #GstH265Picture pointers
             */
            vfunc_decode_slice(picture: H265Picture, slice: H265Slice, ref_pic_list0: H265Picture[], ref_pic_list1: H265Picture[]): Gst.FlowReturn
            /**
             * Optional. Called per one #GstH265Picture to notify subclass to finish
             * decoding process for the #GstH265Picture
             * @param picture a #GstH265Picture
             */
            vfunc_end_picture(picture: H265Picture): Gst.FlowReturn
            /**
             * Optional. Called by baseclass to query whether delaying output is
             * preferred by subclass or not.
             * @since 1.22
             * @param live whether upstream is live or not
             * @returns the number of perferred delayed output frame
             */
            vfunc_get_preferred_output_delay(live: boolean): number
            /**
             * Optional. Called whenever new #GstH265Picture is created.
             * Subclass can set implementation specific user data
             * on the #GstH265Picture via gst_h265_picture_set_user_data
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstH265Picture
             */
            vfunc_new_picture(frame: GstVideo.VideoCodecFrame, picture: H265Picture): Gst.FlowReturn
            /**
             * @param frame
             * @param picture
             */
            vfunc_output_picture(frame: GstVideo.VideoCodecFrame, picture: H265Picture): Gst.FlowReturn
            /**
             * Optional. Called per one #GstH265Picture to notify subclass to prepare
             * decoding process for the #GstH265Picture
             * @param picture a #GstH265Picture
             * @param slice a #GstH265Slice
             * @param dpb a #GstH265Dpb
             */
            vfunc_start_picture(picture: H265Picture, slice: H265Slice, dpb: H265Dpb): Gst.FlowReturn
        }

        interface H265DecoderClass extends Omit<GstVideo.VideoDecoderClass, "new"> {
            readonly $gtype: GObject.GType<H265Decoder>
            readonly prototype: H265Decoder
            new (props?: Partial<GObject.ConstructorProps<H265Decoder>>): H265Decoder
        }

        const H265Decoder: H265DecoderClass
        

        namespace H266Decoder {
            interface SignalSignatures extends GstVideo.VideoDecoder.SignalSignatures {
            }

            interface ReadableProperties extends GstVideo.VideoDecoder.ReadableProperties {
            }

            interface WritableProperties extends GstVideo.VideoDecoder.WritableProperties {
            }

            interface ConstructOnlyProperties extends GstVideo.VideoDecoder.ConstructOnlyProperties {
            }
        }

        /**
         * The opaque #GstH266Decoder data structure.
         * @since 1.26
         */
        interface H266Decoder extends GstVideo.VideoDecoder {
            readonly $signals: H266Decoder.SignalSignatures
            readonly $readableProperties: H266Decoder.ReadableProperties
            readonly $writableProperties: H266Decoder.WritableProperties
            readonly $constructOnlyProperties: H266Decoder.ConstructOnlyProperties
            /**
             * Provides per slice data with parsed slice header and required raw bitstream
             * for subclass to decode it.
             * @since 1.26
             * @param picture a #GstH266Picture
             * @param slice a #GstH266Slice
             */
            vfunc_decode_slice(picture: H266Picture, slice: H266Slice): Gst.FlowReturn
            /**
             * Optional. Called per one #GstH266Picture to notify subclass to finish
             * decoding process for the #GstH266Picture
             * @since 1.26
             * @param picture a #GstH266Picture
             */
            vfunc_end_picture(picture: H266Picture): Gst.FlowReturn
            /**
             * Optional. Called by baseclass to query whether delaying output is
             * preferred by subclass or not.
             * @since 1.26
             * @param live whether upstream is live or not
             * @returns the number of perferred delayed output frame
             */
            vfunc_get_preferred_output_delay(live: boolean): number
            /**
             * Optional. Called whenever new #GstH266Picture is created.
             * Subclass can set implementation specific user data
             * on the #GstH266Picture via gst_h266_picture_set_user_data
             * @since 1.26
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstH266Picture
             */
            vfunc_new_picture(frame: GstVideo.VideoCodecFrame, picture: H266Picture): Gst.FlowReturn
            /**
             * @param frame
             * @param picture
             */
            vfunc_output_picture(frame: GstVideo.VideoCodecFrame, picture: H266Picture): Gst.FlowReturn
            /**
             * Optional. Called per one #GstH266Picture to notify subclass to prepare
             * decoding process for the #GstH266Picture
             * @since 1.26
             * @param picture a #GstH266Picture
             * @param slice a #GstH266Slice
             * @param dpb a #GstH266Dpb
             */
            vfunc_start_picture(picture: H266Picture, slice: H266Slice, dpb: H266Dpb): Gst.FlowReturn
        }

        interface H266DecoderClass extends Omit<GstVideo.VideoDecoderClass, "new"> {
            readonly $gtype: GObject.GType<H266Decoder>
            readonly prototype: H266Decoder
            new (props?: Partial<GObject.ConstructorProps<H266Decoder>>): H266Decoder
        }

        const H266Decoder: H266DecoderClass
        

        namespace Mpeg2Decoder {
            interface SignalSignatures extends GstVideo.VideoDecoder.SignalSignatures {
            }

            interface ReadableProperties extends GstVideo.VideoDecoder.ReadableProperties {
            }

            interface WritableProperties extends GstVideo.VideoDecoder.WritableProperties {
            }

            interface ConstructOnlyProperties extends GstVideo.VideoDecoder.ConstructOnlyProperties {
            }
        }

        /**
         * The opaque #GstMpeg2Decoder data structure.
         * @since 1.20
         */
        interface Mpeg2Decoder extends GstVideo.VideoDecoder {
            readonly $signals: Mpeg2Decoder.SignalSignatures
            readonly $readableProperties: Mpeg2Decoder.ReadableProperties
            readonly $writableProperties: Mpeg2Decoder.WritableProperties
            readonly $constructOnlyProperties: Mpeg2Decoder.ConstructOnlyProperties
            /**
             * Provides per slice data with parsed slice header and required raw bitstream
             * for subclass to decode it.
             * @since 1.20
             * @param picture a #GstMpeg2Picture
             * @param slice a #GstMpeg2Slice
             */
            vfunc_decode_slice(picture: Mpeg2Picture, slice: Mpeg2Slice): Gst.FlowReturn
            /**
             * Optional. Called per one #GstMpeg2Picture to notify subclass to finish
             * decoding process for the #GstMpeg2Picture
             * @since 1.20
             * @param picture a #GstMpeg2Picture
             */
            vfunc_end_picture(picture: Mpeg2Picture): Gst.FlowReturn
            /**
             * Optional. Called by baseclass to query whether delaying output is
             * preferred by subclass or not.
             * @since 1.20
             * @param is_live whether upstream is live or not
             * @returns the number of perferred delayed output frames
             */
            vfunc_get_preferred_output_delay(is_live: boolean): number
            /**
             * Called when a new field picture is created for interlaced field picture.
             * Subclass can attach implementation specific user data on @second_field via
             * gst_mpeg2_picture_set_user_data
             * @since 1.20
             * @param first_field the first field #GstMpeg2Picture already decoded
             * @param second_field a #GstMpeg2Picture for the second field
             */
            vfunc_new_field_picture(first_field: Mpeg2Picture, second_field: Mpeg2Picture): Gst.FlowReturn
            /**
             * Optional. Called whenever new #GstMpeg2Picture is created.
             * Subclass can set implementation specific user data
             * on the #GstMpeg2Picture via gst_mpeg2_picture_set_user_data
             * @since 1.20
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstMpeg2Picture
             */
            vfunc_new_picture(frame: GstVideo.VideoCodecFrame, picture: Mpeg2Picture): Gst.FlowReturn
            /**
             * Called with a #GstMpeg2Picture which is required to be outputted.
             * The #GstVideoCodecFrame must be consumed by subclass.
             * @since 1.20
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstMpeg2Picture
             */
            vfunc_output_picture(frame: GstVideo.VideoCodecFrame, picture: Mpeg2Picture): Gst.FlowReturn
            /**
             * Optional. Called per one #GstMpeg2Picture to notify subclass to prepare
             * decoding process for the #GstMpeg2Picture
             * @since 1.20
             * @param picture a #GstMpeg2Picture
             * @param slice a #GstMpeg2Slice
             * @param prev_picture a #GstMpeg2Picture
             * @param next_picture a #GstMpeg2Picture
             */
            vfunc_start_picture(picture: Mpeg2Picture, slice: Mpeg2Slice, prev_picture: Mpeg2Picture, next_picture: Mpeg2Picture): Gst.FlowReturn
        }

        interface Mpeg2DecoderClass extends Omit<GstVideo.VideoDecoderClass, "new"> {
            readonly $gtype: GObject.GType<Mpeg2Decoder>
            readonly prototype: Mpeg2Decoder
            new (props?: Partial<GObject.ConstructorProps<Mpeg2Decoder>>): Mpeg2Decoder
        }

        const Mpeg2Decoder: Mpeg2DecoderClass
        

        namespace Vp8Decoder {
            interface SignalSignatures extends GstVideo.VideoDecoder.SignalSignatures {
            }

            interface ReadableProperties extends GstVideo.VideoDecoder.ReadableProperties {
            }

            interface WritableProperties extends GstVideo.VideoDecoder.WritableProperties {
            }

            interface ConstructOnlyProperties extends GstVideo.VideoDecoder.ConstructOnlyProperties {
            }
        }

        /**
         * The opaque #GstVp8Decoder data structure.
         */
        interface Vp8Decoder extends GstVideo.VideoDecoder {
            readonly $signals: Vp8Decoder.SignalSignatures
            readonly $readableProperties: Vp8Decoder.ReadableProperties
            readonly $writableProperties: Vp8Decoder.WritableProperties
            readonly $constructOnlyProperties: Vp8Decoder.ConstructOnlyProperties
            /**
             * Optional.
             *                     Called per one #GstVp8Picture to notify subclass to finish
             *                     decoding process for the #GstVp8Picture
             * @param picture
             */
            vfunc_end_picture(picture: Vp8Picture): Gst.FlowReturn
            /**
             * Optional. Called by baseclass to query whether delaying output is
             * preferred by subclass or not.
             * @since 1.20
             * @param is_live whether upstream is live or not
             * @returns the number of perferred delayed output frame
             */
            vfunc_get_preferred_output_delay(is_live: boolean): number
            /**
             * Optional.
             *                     Called whenever new #GstVp8Picture is created.
             *                     Subclass can set implementation specific user data
             *                     on the #GstVp8Picture via gst_vp8_picture_set_user_data
             * @param frame
             * @param picture
             */
            vfunc_new_picture(frame: GstVideo.VideoCodecFrame, picture: Vp8Picture): Gst.FlowReturn
            /**
             * Called with a #GstVp8Picture which is required to be outputted.
             *                     Subclass can retrieve parent #GstVideoCodecFrame by using
             *                     gst_video_decoder_get_frame() with system_frame_number
             *                     and the #GstVideoCodecFrame must be consumed by subclass via
             *                     gst_video_decoder_{finish,drop,release}_frame().
             * @param frame
             * @param picture
             */
            vfunc_output_picture(frame: GstVideo.VideoCodecFrame, picture: Vp8Picture): Gst.FlowReturn
            /**
             * Optional.
             *                     Called per one #GstVp8Picture to notify subclass to prepare
             *                     decoding process for the #GstVp8Picture
             * @param picture
             */
            vfunc_start_picture(picture: Vp8Picture): Gst.FlowReturn
        }

        interface Vp8DecoderClass extends Omit<GstVideo.VideoDecoderClass, "new"> {
            readonly $gtype: GObject.GType<Vp8Decoder>
            readonly prototype: Vp8Decoder
            new (props?: Partial<GObject.ConstructorProps<Vp8Decoder>>): Vp8Decoder
        }

        const Vp8Decoder: Vp8DecoderClass
        

        namespace Vp9Decoder {
            interface SignalSignatures extends GstVideo.VideoDecoder.SignalSignatures {
            }

            interface ReadableProperties extends GstVideo.VideoDecoder.ReadableProperties {
            }

            interface WritableProperties extends GstVideo.VideoDecoder.WritableProperties {
            }

            interface ConstructOnlyProperties extends GstVideo.VideoDecoder.ConstructOnlyProperties {
            }
        }

        /**
         * The opaque #GstVp9Decoder data structure.
         */
        interface Vp9Decoder extends GstVideo.VideoDecoder {
            readonly $signals: Vp9Decoder.SignalSignatures
            readonly $readableProperties: Vp9Decoder.ReadableProperties
            readonly $writableProperties: Vp9Decoder.WritableProperties
            readonly $constructOnlyProperties: Vp9Decoder.ConstructOnlyProperties
            /**
             * Called to set non-keyframe format change awareness
             * @since 1.20
             * @param support whether subclass can support non-keyframe format change
             */
            set_non_keyframe_format_change_support(support: boolean): void
            /**
             * Called to notify decoding for subclass to decoder given @picture with
             * given @dpb
             * @since 1.18
             * @param picture a #GstVp9Picture to decoder
             * @param dpb a #GstVp9Dpb
             */
            vfunc_decode_picture(picture: Vp9Picture, dpb: Vp9Dpb): Gst.FlowReturn
            /**
             * Optional. Called to duplicate @picture when show_existing_frame flag is set
             * in the parsed vp9 frame header. Returned #GstVp9Picture from this method
             * should hold already decoded picture data corresponding to the @picture,
             * since the returned #GstVp9Picture from this method will be passed to
             * the output_picture method immediately without additional decoding process.
             *
             * If this method is not implemented by subclass, baseclass will drop
             * current #GstVideoCodecFrame without additional processing for the current
             * frame.
             * @since 1.18
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstVp9Picture to be duplicated
             * @returns a #GstVp9Picture or %NULL if failed to duplicate `picture`.
             */
            vfunc_duplicate_picture(frame: GstVideo.VideoCodecFrame, picture: Vp9Picture): Vp9Picture | null
            /**
             * Optional. Called per one #GstVp9Picture to notify subclass to finish
             * decoding process for the #GstVp9Picture
             * @since 1.18
             * @param picture a #GstVp9Picture
             */
            vfunc_end_picture(picture: Vp9Picture): Gst.FlowReturn
            /**
             * Optional. Retrieve the preferred output delay from child classes.
             * controls how many frames to delay when calling
             * GstVp9DecoderClass::output_picture
             * @since 1.20
             * @param is_live whether upstream is live or not
             * @returns the number of perferred delayed output frame
             */
            vfunc_get_preferred_output_delay(is_live: boolean): number
            /**
             * Optional. Called whenever new #GstVp9Picture is created.
             * Subclass can set implementation specific user data on the #GstVp9Picture
             * via gst_vp9_picture_set_user_data
             * @since 1.18
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstVp9Picture
             */
            vfunc_new_picture(frame: GstVideo.VideoCodecFrame, picture: Vp9Picture): Gst.FlowReturn
            /**
             * Notifies subclass of video sequence update such as resolution, bitdepth,
             * profile.
             * @since 1.18
             * @param frame_hdr a #GstVp9FrameHeader
             * @param max_dpb_size the size of dpb including preferred output delay
              by subclass reported via get_preferred_output_delay method.
             */
            vfunc_new_sequence(frame_hdr: Vp9FrameHeader, max_dpb_size: number): Gst.FlowReturn
            /**
             * Called to notify @picture is ready to be outputted.
             * @since 1.18
             * @param frame a #GstVideoCodecFrame
             * @param picture a #GstVp9Picture
             */
            vfunc_output_picture(frame: GstVideo.VideoCodecFrame, picture: Vp9Picture): Gst.FlowReturn
            /**
             * Optional. Called to notify subclass to prepare decoding process for
             * @picture
             * @since 1.18
             * @param picture a #GstVp9Picture
             */
            vfunc_start_picture(picture: Vp9Picture): Gst.FlowReturn
        }

        interface Vp9DecoderClass extends Omit<GstVideo.VideoDecoderClass, "new"> {
            readonly $gtype: GObject.GType<Vp9Decoder>
            readonly prototype: Vp9Decoder
            new (props?: Partial<GObject.ConstructorProps<Vp9Decoder>>): Vp9Decoder
        }

        const Vp9Decoder: Vp9DecoderClass
        none
        /**
         */
        abstract class AV1DecoderPrivate {
            static readonly $gtype: GObject.GType<AV1DecoderPrivate>

            
        }
        /**
         * @since 1.20
         */
        abstract class AV1Dpb {
            static readonly $gtype: GObject.GType<AV1Dpb>

            
            /**
             */
            pic_list: AV1Picture[]
            /**
             * Store the @picture
             * @since 1.20
             * @param picture a #GstAV1Picture
             */
            add(picture: AV1Picture): void
            /**
             * Clear all stored #GstAV1Picture
             * @since 1.20
             */
            clear(): void
            /**
             * Free the @dpb
             * @since 1.20
             */
            free(): void
        }
        /**
         * @since 1.20
         */
        abstract class AV1Picture {
            static readonly $gtype: GObject.GType<AV1Picture>

            
            /**
             * Create new #GstAV1Picture
             * @since 1.20
             * @returns a new #GstAV1Picture
             */
            static "new"(): AV1Picture
        }
        /**
         * @since 1.20
         */
        abstract class AV1Tile {
            static readonly $gtype: GObject.GType<AV1Tile>

            
        }
        /**
         * Base struct for coded picture representation
         * @since 1.24
         */
        abstract class CodecPicture {
            static readonly $gtype: GObject.GType<CodecPicture>

            
            /**
             * Gets private data set on the picture via
             * gst_codec_picture_set_user_data() previously.
             * @since 1.24
             * @returns The previously set user_data
             */
            get_user_data(): never | null
            /**
             * Sets @discont_state to @picture
             * @since 1.24
             * @param discont_state a #GstVideoCodecState
             */
            set_discont_state(discont_state: GstVideo.VideoCodecState | null): void
            /**
             * Sets @user_data on the picture and the #GDestroyNotify that will be called when
             * the picture is freed.
             *
             * If a @user_data was previously set, then the previous set @notify will be called
             * before the @user_data is replaced.
             * @since 1.24
             * @param notify a #GDestroyNotify
             */
            set_user_data(notify: GLib.DestroyNotify): void
        }
        none
        /**
         */
        abstract class H264DecoderPrivate {
            static readonly $gtype: GObject.GType<H264DecoderPrivate>

            
        }
        /**
         */
        abstract class H264Dpb {
            static readonly $gtype: GObject.GType<H264Dpb>

            
            /**
             * Store the @picture
             * @param picture a #GstH264Picture
             */
            add(picture: H264Picture): void
            /**
             * Perform bumping process as defined in C.4.5.3 "Bumping" process.
             * If @drain is %TRUE, @dpb will remove a #GstH264Picture from internal array
             * so that returned #GstH264Picture could hold the last reference of it
             * @since 1.20
             * @param drain whether draining or not
             * @returns a #GstH264Picture which is needed to be outputted
             */
            bump(drain: boolean): H264Picture | null
            /**
             * Clear all stored #GstH264Picture
             */
            clear(): void
            /**
             * Delete already outputted and not referenced all pictures from dpb
             */
            delete_unused(): void
            /**
             * Free the @dpb
             */
            free(): void
            /**
             * @since 1.20
             * @returns %TRUE if `dpb` is configured for interlaced stream
             */
            get_interlaced(): boolean
            /**
             * Find a long term reference picture which has matching long term picture number
             * @since 1.20
             * @param long_term_pic_num a long term picture number
             * @returns a #GstH264Picture
             */
            get_long_ref_by_long_term_pic_num(long_term_pic_num: number): H264Picture | null
            /**
             * Find a short term reference picture which has the lowest frame_num_wrap
             * @returns a #GstH264Picture
             */
            get_lowest_frame_num_short_ref(): H264Picture | null
            /**
             * @since 1.20
             * @returns the number of maximum frames
             */
            get_max_num_frames(): number
            /**
             * @since 1.22.2
             * @returns Maximum number of reorder frames
             */
            get_max_num_reorder_frames(): number
            /**
             * @since 1.18
             * @param system_frame_number
             * @returns the picture identified with the specified `system_frame_number`, or %NULL if DPB does not contain a #GstH264Picture corresponding to the `system_frame_number`
             */
            get_picture(system_frame_number: number): H264Picture | null
            /**
             * @returns a #GArray of   #GstH264Picture stored in `dpb`
             */
            get_pictures_all(): H264Picture[]
            /**
             * Retrieve all long-term reference pictures from @dpb. The picture will be
             * appended to the array.
             * @since 1.20
             * @param include_second_field %TRUE if the second field pictures need to be included
             * @returns , an array   of #GstH264Picture pointer
             */
            get_pictures_long_term_ref(include_second_field: boolean): H264Picture[]
            /**
             * Retrieve all short-term reference pictures from @dpb. The picture will be
             * appended to the array.
             * @since 1.20
             * @param include_non_existing %TRUE if non-existing pictures need to be included
             * @param include_second_field %TRUE if the second field pictures need to be included
             * @returns , an array   of #GstH264Picture pointers
             */
            get_pictures_short_term_ref(include_non_existing: boolean, include_second_field: boolean): H264Picture[]
            /**
             * Find a short term reference picture which has matching picture number
             * @param pic_num a picture number
             * @returns a #GstH264Picture
             */
            get_short_ref_by_pic_num(pic_num: number): H264Picture | null
            /**
             * @returns the length of stored dpb array
             */
            get_size(): number
            /**
             * @since 1.20
             * @returns %TRUE if `dpb` still has empty frame buffers.
             */
            has_empty_frame_buffer(): boolean
            /**
             * Mark all pictures are not referenced
             */
            mark_all_non_ref(): void
            /**
             * @since 1.20
             * @param to_insert the current #GstH264Picture to insert to dpb.
             * @param latency_mode The required #GstH264DpbBumpMode for bumping.
             * @returns %TRUE if bumping is required
             */
            needs_bump(to_insert: H264Picture, latency_mode: H264DpbBumpMode): boolean
            /**
             * @since 1.20
             * @returns The number of referenced frames
             */
            num_ref_frames(): number
            /**
             * @since 1.20
             * @param interlaced %TRUE if interlaced
             */
            set_interlaced(interlaced: boolean): void
            /**
             * Notify the DPB that @picture is output directly without storing
             * in the DPB.
             * @since 1.20
             * @param picture a #GstH264Picture of the last output.
             */
            set_last_output(picture: H264Picture): void
            /**
             * Set the number of maximum allowed frames to store
             * @since 1.20
             * @param max_num_frames the maximum number of picture
             */
            set_max_num_frames(max_num_frames: number): void
            /**
             * @since 1.20
             * @param max_num_reorder_frames the max number of reorder frames, which
            should not exceed the max size of DPB.
             */
            set_max_num_reorder_frames(max_num_reorder_frames: number): void
        }
        /**
         */
        abstract class H264Picture {
            static readonly $gtype: GObject.GType<H264Picture>

            
            /**
             * Create new #GstH264Picture
             * @returns a new #GstH264Picture
             */
            static "new"(): H264Picture
        }
        /**
         */
        abstract class H264Slice {
            static readonly $gtype: GObject.GType<H264Slice>

            
        }
        none
        /**
         */
        abstract class H265DecoderPrivate {
            static readonly $gtype: GObject.GType<H265DecoderPrivate>

            
        }
        /**
         */
        abstract class H265Dpb {
            static readonly $gtype: GObject.GType<H265Dpb>

            
            /**
             * Store the @picture and perform increase pic_latency_cnt as defined in
             * "C.5.2.3 Additional bumping" process
             * @param picture a #GstH265Picture
             */
            add(picture: H265Picture): void
            /**
             * Perform bumping process as defined in C.5.2.4 "Bumping" process.
             * If @drain is %TRUE, @dpb will remove a #GstH265Picture from internal array
             * so that returned #GstH265Picture could hold the last reference of it
             * @since 1.20
             * @param drain whether draining or not
             * @returns a #GstH265Picture which is needed to be outputted
             */
            bump(drain: boolean): H265Picture | null
            /**
             * Clear all stored #GstH265Picture
             */
            clear(): void
            /**
             * Delete not needed for output and not referenced all pictures from dpb
             */
            delete_unused(): void
            /**
             * Free the @dpb
             */
            free(): void
            /**
             * Find a long term reference picture which has matching poc
             * @param poc a picture order count
             * @returns a #GstH265Picture
             */
            get_long_ref_by_poc(poc: number): H265Picture | null
            /**
             * @returns the number of maximum pictures
             */
            get_max_num_pics(): number
            /**
             * @since 1.20
             * @param system_frame_number
             * @returns the picture identified with the specified `system_frame_number`, or %NULL if DPB does not contain a #GstH265Picture corresponding to the `system_frame_number`
             */
            get_picture(system_frame_number: number): H265Picture | null
            /**
             * @returns a #GArray of   #GstH265Picture stored in `dpb`
             */
            get_pictures_all(): H265Picture[]
            /**
             * Find a short or long term reference picture which has matching poc
             * @param poc a picture order count
             * @returns a #GstH265Picture
             */
            get_ref_by_poc(poc: number): H265Picture | null
            /**
             * Find a short or long term reference picture which has matching poc_lsb
             * @param poc_lsb a picture order count lsb
             * @returns a #GstH265Picture
             */
            get_ref_by_poc_lsb(poc_lsb: number): H265Picture | null
            /**
             * Find a short term reference picture which has matching poc
             * @param poc a picture order count
             * @returns a #GstH265Picture
             */
            get_short_ref_by_poc(poc: number): H265Picture | null
            /**
             * @returns the length of stored dpb array
             */
            get_size(): number
            /**
             * Mark all pictures are not referenced
             */
            mark_all_non_ref(): void
            /**
             * @since 1.20
             * @param max_num_reorder_pics sps_max_num_reorder_pics[HighestTid]
             * @param max_latency_increase SpsMaxLatencyPictures[HighestTid]
             * @param max_dec_pic_buffering sps_max_dec_pic_buffering_minus1[HighestTid ] + 1
              or zero if this shouldn't be used for bumping decision
             * @returns %TRUE if bumping is required
             */
            needs_bump(max_num_reorder_pics: number, max_latency_increase: number, max_dec_pic_buffering: number): boolean
            /**
             * @returns The number of referenced pictures
             */
            num_ref_pictures(): number
            /**
             * Set the number of maximum allowed pictures to store
             * @param max_num_pics the maximum number of picture
             */
            set_max_num_pics(max_num_pics: number): void
        }
        /**
         */
        abstract class H265Picture {
            static readonly $gtype: GObject.GType<H265Picture>

            
            /**
             * Create new #GstH265Picture
             * @returns a new #GstH265Picture
             */
            static "new"(): H265Picture
        }
        /**
         */
        abstract class H265Slice {
            static readonly $gtype: GObject.GType<H265Slice>

            
        }
        none
        /**
         */
        abstract class H266DecoderPrivate {
            static readonly $gtype: GObject.GType<H266DecoderPrivate>

            
        }
        /**
         * The #GstH266Dpb represents the dpb for decoding.
         * @since 1.26
         */
        abstract class H266Dpb {
            static readonly $gtype: GObject.GType<H266Dpb>

            
            /**
             * Store the @picture and perform increase pic_latency_cnt as defined in
             * "C.5.2.3 Additional bumping" process
             * @since 1.26
             * @param picture a #GstH266Picture
             */
            add(picture: H266Picture): void
            /**
             * Perform bumping process as defined in C.5.2.4 "Bumping" process.
             * If @drain is %TRUE, @dpb will remove a #GstH266Picture from internal array
             * so that returned #GstH266Picture could hold the last reference of it.
             * @since 1.26
             * @param drain whether draining or not
             * @returns a #GstH266Picture which is needed to be outputted
             */
            bump(drain: boolean): H266Picture | null
            /**
             * Clear all stored #GstH266Picture
             * @since 1.26
             */
            clear(): void
            /**
             * Delete unneeded pictures from dpb as defined in "C.5.2.2 Output and
             * removal of pictures from the DPB".
             * @since 1.26
             */
            delete_unused(): void
            /**
             * Free the @dpb
             * @since 1.26
             */
            free(): void
            /**
             * @since 1.26
             * @returns the number of maximum pictures
             */
            get_max_num_pics(): number
            /**
             * Find a picture which has matching poc
             * @since 1.26
             * @param poc a picture order count
             * @returns a #GstH266Picture
             */
            get_picture_by_poc(poc: number): H266Picture | null
            /**
             * Find a picture which has matching poc_lsb
             * @since 1.26
             * @param poc_lsb a picture order count lsb
             * @returns a #GstH266Picture
             */
            get_picture_by_poc_lsb(poc_lsb: number): H266Picture | null
            /**
             * @since 1.26
             * @returns a #GArray of   #GstH266Picture stored in `dpb`
             */
            get_pictures_all(): H266Picture[]
            /**
             * @since 1.26
             * @returns the length of stored dpb array
             */
            get_size(): number
            /**
             * Mark all pictures are no needed for output
             * @since 1.26
             */
            mark_all_non_output(): void
            /**
             * Mark all pictures are not referenced
             * @since 1.26
             */
            mark_all_non_ref(): void
            /**
             * @since 1.26
             * @param max_num_reorder_pics dpb_max_num_reorder_pics[HighestTid]
             * @param max_latency_increase MaxLatencyPictures[HighestTid]
             * @param max_dec_pic_buffering dpb_max_dec_pic_buffering_minus1[HighestTid] + 1
              or zero if this shouldn't be used for bumping decision.
             * @returns %TRUE if bumping is required
             */
            needs_bump(max_num_reorder_pics: number, max_latency_increase: number, max_dec_pic_buffering: number): boolean
            /**
             * @since 1.26
             * @returns The number of referenced pictures in dpb.
             */
            num_ref_pictures(): number
            /**
             * Set the number of maximum allowed pictures to store
             * @since 1.26
             * @param max_num_pics the maximum number of picture
             */
            set_max_num_pics(max_num_pics: number): void
        }
        /**
         * The #GstH266Picture represents a picture for decoding.
         * @since 1.26
         */
        abstract class H266Picture {
            static readonly $gtype: GObject.GType<H266Picture>

            
            /**
             * Create new #GstH266Picture
             * @since 1.26
             * @returns a new #GstH266Picture
             */
            static "new"(): H266Picture
        }
        /**
         * The #GstH266Slice represents a slice for decoding.
         * @since 1.26
         */
        abstract class H266Slice {
            static readonly $gtype: GObject.GType<H266Slice>

            
        }
        none
        /**
         */
        abstract class Mpeg2DecoderPrivate {
            static readonly $gtype: GObject.GType<Mpeg2DecoderPrivate>

            
        }
        /**
         * @since 1.20
         */
        abstract class Mpeg2Dpb {
            static readonly $gtype: GObject.GType<Mpeg2Dpb>

            
            /**
             * Store the @picture
             * @since 1.20
             * @param picture a #GstMpeg2Picture
             */
            add(picture: Mpeg2Picture): void
            /**
             * @since 1.20
             * @returns a #GstMpeg2Picture which is needed to be outputted
             */
            bump(): Mpeg2Picture | null
            /**
             * Clear all stored #GstMpeg2Picture
             * @since 1.20
             */
            clear(): void
            /**
             * Free the @dpb
             * @since 1.20
             */
            free(): void
            /**
             * Gets the neighbours #GstMpeg2Picture of @picture in @dpb.
             * @since 1.20
             * @param picture current #GstMpeg2Picture
             * @returns , previuous     #GstMpeg2Picture in `dpb`, next     #GstMpeg2Picture in `dpb`
             */
            get_neighbours(picture: Mpeg2Picture): [Mpeg2Picture | null, Mpeg2Picture | null]
            /**
             * Checks if @dbp has a new picture.
             * @since 1.20
             * @returns #TRUE if `dpb` needs to be bumped; otherwise, #FALSE
             */
            need_bump(): boolean
        }
        /**
         * @since 1.20
         */
        abstract class Mpeg2Picture {
            static readonly $gtype: GObject.GType<Mpeg2Picture>

            
            /**
             * Create new #GstMpeg2Picture
             * @since 1.20
             * @returns a new #GstMpeg2Picture
             */
            static "new"(): Mpeg2Picture
        }
        /**
         * @since 1.20
         */
        abstract class Mpeg2Slice {
            static readonly $gtype: GObject.GType<Mpeg2Slice>

            
        }
        none
        /**
         */
        abstract class Vp8DecoderPrivate {
            static readonly $gtype: GObject.GType<Vp8DecoderPrivate>

            
        }
        /**
         */
        abstract class Vp8Picture {
            static readonly $gtype: GObject.GType<Vp8Picture>

            
            /**
             * Create new #GstVp8Picture
             * @returns a new #GstVp8Picture
             */
            static "new"(): Vp8Picture
        }
        none
        /**
         */
        abstract class Vp9DecoderPrivate {
            static readonly $gtype: GObject.GType<Vp9DecoderPrivate>

            
        }
        /**
         * Stores probabilities updates. This is from the spec
         * and can be used as a binary.
         * @since 1.20
         */
        abstract class Vp9DeltaProbabilities {
            static readonly $gtype: GObject.GType<Vp9DeltaProbabilities>

            
        }
        /**
         */
        abstract class Vp9Dpb {
            static readonly $gtype: GObject.GType<Vp9Dpb>

            
            /**
             */
            pic_list: Vp9Picture[]
            /**
             * Store the @picture
             * @param picture a #GstVp9Picture
             */
            add(picture: Vp9Picture): void
            /**
             * Clear all stored #GstVp9Picture
             */
            clear(): void
            /**
             * Free the @dpb
             */
            free(): void
        }
        /**
         * @since 1.20
         */
        abstract class Vp9FrameHeader {
            static readonly $gtype: GObject.GType<Vp9FrameHeader>

            
            /**
             * encoded profile
             */
            profile: number
            /**
             * encoded bit depth
             */
            bit_depth: number
            /**
             * specify the chroma subsampling format for x coordinate
             */
            subsampling_x: number
            /**
             * specify the chroma subsampling format for y coordinate
             */
            subsampling_y: number
            /**
             * specifies the color space of the stream
             */
            color_space: number
            /**
             * specifies the black level and range of the luma and chroma
             *   signals
             */
            color_range: number
            /**
             * equal to 1, indicates the frame indexed by
             *   frame_to_show_map_idx is to be displayed
             */
            show_existing_frame: number
            /**
             * specifies the frame to be displayed.
             *   It is only available if show_existing_frame is 1
             */
            frame_to_show_map_idx: number
            /**
             * equal to 0 indicates that the current frame is a key frame
             */
            frame_type: number
            /**
             * indicate whether it is a displayable frame or not
             */
            show_frame: number
            /**
             * equal to 1 indicates that error resilient mode is
             *   enabled
             */
            error_resilient_mode: number
            /**
             * coded frame width
             */
            width: number
            /**
             * coded frame height
             */
            height: number
            /**
             * equal to 0 means that the render width and
             *   height are inferred from the frame width and height
             */
            render_and_frame_size_different: number
            /**
             * render width of the frame
             */
            render_width: number
            /**
             * render width of the frame
             */
            render_height: number
            /**
             * equal to 1 indicates that the frame is an intra-only frame
             */
            intra_only: number
            /**
             * specifies whether the frame context should be reset to
             *   default values
             */
            reset_frame_context: number
            /**
             * contains a bitmask that specifies which reference frame
             *   slots will be updated with the current frame after it is decoded
             */
            refresh_frame_flags: number
            /**
             * specifies which reference frames are used by inter frames
             */
            ref_frame_idx: Uint8Array
            /**
             * specifies the intended direction of the motion vector
             *   in time for each reference frame. A sign bias equal to 0 indicates that
             *   the reference frame is a backwards reference
             */
            ref_frame_sign_bias: Uint8Array
            /**
             * equal to 0 specifies that motion vectors are
             *   specified to quarter pel precision
             */
            allow_high_precision_mv: number
            /**
             * specifies the filter selection used for performing
             *   inter prediction
             */
            interpolation_filter: number
            /**
             * equal to 1 indicates that the probabilities computed
             *   for this frame
             */
            refresh_frame_context: number
            /**
             * equal to 1 indicates that parallel decoding
             *   mode is enabled
             */
            frame_parallel_decoding_mode: number
            /**
             * indicates the frame context to use
             */
            frame_context_idx: number
            /**
             * a #GstVp9LoopFilterParams
             */
            loop_filter_params: Vp9LoopFilterParams
            /**
             * a #GstVp9QuantizationParams
             */
            quantization_params: Vp9QuantizationParams
            /**
             * a #GstVp9SegmentationParams
             */
            segmentation_params: Vp9SegmentationParams
            /**
             * specifies the base 2 logarithm of the width of each tile
             */
            tile_cols_log2: number
            /**
             * specifies the base 2 logarithm of the height of each tile
             */
            tile_rows_log2: number
            /**
             */
            header_size_in_bytes: number
            /**
             * Specifies how the transform size is determined.
             * @since 1.20
             */
            tx_mode: Vp9TxMode
            /**
             * Is a derived syntax element that specifies the type of
             * inter prediction to be used.
             * @since 1.20
             */
            reference_mode: Vp9ReferenceMode
            /**
             * Modification to the probabilities encoded in the bitstream.
             * @since 1.20
             */
            delta_probabilities: Vp9DeltaProbabilities
            /**
             * lossless mode decode
             */
            lossless_flag: number
            /**
             * length of uncompressed header
             */
            frame_header_length_in_bytes: number
        }
        /**
         * Loop filter params. See "6.2.8 Loop filter params syntax" and
         * "7.2.8 Loop filter semantics".
         *
         * If syntax elements for @update_ref_delta
         * and/or @loop_filter_mode_deltas are not present in bitstream,
         * parser will fill @loop_filter_ref_deltas and @loop_filter_mode_deltas values
         * by using previously parsed values.
         * @since 1.20
         */
        abstract class Vp9LoopFilterParams {
            static readonly $gtype: GObject.GType<Vp9LoopFilterParams>

            
            /**
             * indicates the loop filter strength
             */
            loop_filter_level: number
            /**
             * indicates the sharpness level
             */
            loop_filter_sharpness: number
            /**
             * equal to 1 means that the filter level depends
             *   on the mode and reference frame used to predict a block
             */
            loop_filter_delta_enabled: number
            /**
             * equal to 1 means that the bitstream contains
             *   additional syntax elements that specify which mode and reference frame
             *   deltas are to be updated
             */
            loop_filter_delta_update: number
            /**
             * equal to 1 means that the bitstream contains the syntax
             *   element loop_filter_ref_delta
             */
            update_ref_delta: Uint8Array
            /**
             * contains the adjustment needed for the filter level
             *   based on the chosen reference frame
             */
            loop_filter_ref_deltas: Uint8Array
            /**
             * equal to 1 means that the bitstream contains the syntax
             *   element loop_filter_mode_deltas
             */
            update_mode_delta: Uint8Array
            /**
             * contains the adjustment needed for the filter level
             *   based on the chosen mode
             */
            loop_filter_mode_deltas: Uint8Array
        }
        /**
         * Stores motion vectors probabilities updates. This is from the spec
         * and can be used as a binary.
         * @since 1.20
         */
        abstract class Vp9MvDeltaProbs {
            static readonly $gtype: GObject.GType<Vp9MvDeltaProbs>

            
        }
        /**
         */
        abstract class Vp9Picture {
            static readonly $gtype: GObject.GType<Vp9Picture>

            
            /**
             * Create new #GstVp9Picture
             * @returns a new #GstVp9Picture
             */
            static "new"(): Vp9Picture
        }
        /**
         * @since 1.20
         */
        abstract class Vp9QuantizationParams {
            static readonly $gtype: GObject.GType<Vp9QuantizationParams>

            
            /**
             * indicates the base frame qindex. This is used for Y AC
             *   coefficients and as the base value for the other quantizers
             */
            base_q_idx: number
            /**
             * indicates the Y DC quantizer relative to base_q_idx
             */
            delta_q_y_dc: number
            /**
             * indicates the UV DC quantizer relative to base_q_idx
             */
            delta_q_uv_dc: number
            /**
             * indicates the UV AC quantizer relative to base_q_idx
             */
            delta_q_uv_ac: number
        }
        /**
         * See "6.2.11 Segmentation params syntax" and
         * "7.2.10 Segmentation params syntax". When @segmentation_update_data is equal
         * to zero, parser will fill @feature_enabled and by @feature_data
         * using previously parsed values.
         * @since 1.20
         */
        abstract class Vp9SegmentationParams {
            static readonly $gtype: GObject.GType<Vp9SegmentationParams>

            
            /**
             * equal to 1 indicates that this frame makes use of the
             *   segmentation tool
             */
            segmentation_enabled: number
            /**
             * equal to 1 indicates that the segmentation map
             *   should be updated during the decoding of this frame
             */
            segmentation_update_map: number
            /**
             * specify the probability values to be used when
             *   decoding segment_id
             */
            segmentation_tree_probs: Uint8Array
            /**
             * specify the probability values to be used when
             *    decoding seg_id_predicted
             */
            segmentation_pred_prob: Uint8Array
            /**
             * equal to 1 indicates that the updates to
             *   the segmentation map are coded relative to the existing segmentation map
             */
            segmentation_temporal_update: number
            /**
             * equal to 1 indicates that new parameters are
             *   about to be specified for each segment
             */
            segmentation_update_data: number
            /**
             * equal to 0 indicates that the segmentation
             *   parameters represent adjustments relative to the standard values.
             *   equal to 1 indicates that the segmentation parameters represent the actual
             *   values to be used
             */
            segmentation_abs_or_delta_update: number
            /**
             * indicates whether feature is enabled or not
             */
            feature_enabled: Uint8Array
            /**
             * segmentation feature data
             */
            feature_data: number[]
        }
        /**
         * This object is used to parse VP9 bitstream header.
         * @since 1.20
         */
        abstract class Vp9StatefulParser {
            static readonly $gtype: GObject.GType<Vp9StatefulParser>

            
            /**
             */
            reference: never[]
            /**
             * Frees @parser.
             * @since 1.20
             */
            free(): void
        }
        none
        none
        none
        none
        none
        none
        /**
         * An implementation of "ac_q" function specified in
         * "8.6.1 Dequantization functions"
         * @since 1.20
         * @param qindex the quantizer index
         * @param delta_q_ac a delta_q_ac value
         * @param bit_depth coded bit depth
         * @returns the quantizer value for the ac coefficient
         */
        function vp9_get_ac_quant(qindex: number, delta_q_ac: number, bit_depth: number): number
        /**
         * An implementation of "dc_q" function specified in
         * "8.6.1 Dequantization functions"
         * @since 1.20
         * @param qindex the quantizer index
         * @param delta_q_dc a delta_q_dc value
         * @param bit_depth coded bit depth
         * @returns the quantizer value for the dc coefficient
         */
        function vp9_get_dc_quant(qindex: number, delta_q_dc: number, bit_depth: number): number
        /**
         * An implementation of "get_qindex" function specfied in
         * "8.6.1 Dequantization functions"
         * @since 1.20
         * @param segmentation_params a #GstVp9SegmentationParams
         * @param quantization_params a #GstVp9QuantizationParams
         * @param segment_id a segment id
         * @returns the quantizer index
         */
        function vp9_get_qindex(segmentation_params: Vp9SegmentationParams, quantization_params: Vp9QuantizationParams, segment_id: number): number
        /**
         * An implementation of "seg_feature_active" function specified in
         * "6.4.9 Segmentation feature active syntax"
         * @since 1.20
         * @param params a #GstVp9SegmentationParams
         * @param segment_id a segment id
         * @param feature a segmentation feature
         * @returns %TRUE if feature is active
         */
        function vp9_seg_feature_active(params: Vp9SegmentationParams, segment_id: number, feature: number): boolean
        const H264_DPB_MAX_SIZE: 16
        const H265_DPB_MAX_SIZE: 16
        const VP9_BLOCK_SIZE_GROUPS: 4
        const VP9_CLASS0_SIZE: 2
        const VP9_COMP_MODE_CONTEXTS: 5
        const VP9_INTERP_FILTER_CONTEXTS: 4
        const VP9_INTER_MODES: 4
        const VP9_INTER_MODE_CONTEXTS: 7
        const VP9_INTRA_MODES: 10
        const VP9_IS_INTER_CONTEXTS: 4
        const VP9_MV_CLASSES: 11
        const VP9_MV_FR_SIZE: 4
        const VP9_MV_JOINTS: 4
        const VP9_MV_OFFSET_BITS: 10
        const VP9_PARTITION_CONTEXTS: 16
        const VP9_PARTITION_TYPES: 4
        const VP9_REF_CONTEXTS: 5
        const VP9_SEG_LVL_ALT_L: 1
        const VP9_SEG_LVL_ALT_Q: 0
        const VP9_SEG_LVL_MAX: 4
        const VP9_SEG_LVL_REF_FRAME: 2
        const VP9_SEG_SEG_LVL_SKIP: 3
        const VP9_SKIP_CONTEXTS: 3
        const VP9_SWITCHABLE_FILTERS: 3
        const VP9_TX_MODES: 5
        const VP9_TX_SIZES: 4
        const VP9_TX_SIZE_CONTEXTS: 2
        
        namespace H264DecoderCompliance {
            const $gtype: GObject.GType<H264DecoderCompliance>
        }

        /**
         * @since 1.20
         */
        enum H264DecoderCompliance {
            /**
             * The decoder behavior is
             *     automatically choosen.
             */
            "AUTO" = 0,
            /**
             * The decoder behavior strictly
             *     conforms to the SPEC. All the decoder behaviors conform to the
             *     SPEC, not including any nonstandard behavior which is not
             *     mentioned in the SPEC.
             */
            "STRICT" = 1,
            /**
             * The decoder behavior normally
             *     conforms to the SPEC. Most behaviors conform to the SPEC but
             *     including some nonstandard features which are widely used or
             *     often used in the industry practice. This meets the request of
             *     real streams and usages, but may not 100% conform to the
             *     SPEC. It has very low risk. E.g., we will output pictures
             *     without waiting DPB being full for the lower latency, which may
             *     cause B frame disorder when there are reference frames with
             *     smaller POC after it in decoder order. And the baseline profile
             *     may be mapped to the constrained-baseline profile, but it may
             *     have problems when a real baseline stream comes with FMO or
             *     ASO.
             */
            "NORMAL" = 2,
            /**
             * The decoder behavior
             *     flexibly conforms to the SPEC. It uses the nonstandard features
             *     more aggressively in order to get better performance(for
             *     example, lower latency). It may change the result of the
             *     decoder and should be used carefully. Besides including all
             *     risks in *normal* mode, it has more risks, such as frames
             *     disorder when reference frames POC decrease in decoder order.
             */
            "FLEXIBLE" = 3,
        }
        
        namespace H264DpbBumpMode {
            const $gtype: GObject.GType<H264DpbBumpMode>
        }

        /**
         * @since 1.20
         */
        enum H264DpbBumpMode {
            /**
             * No latency requirement for DBP bumping.
             */
            "NORMAL_LATENCY" = 0,
            /**
             * Low-latency requirement for DBP bumping.
             */
            "LOW_LATENCY" = 1,
            /**
             * Very low-latency requirement for DBP bumping.
             */
            "VERY_LOW_LATENCY" = 2,
        }
        
        namespace H264PictureField {
            const $gtype: GObject.GType<H264PictureField>
        }

        /**
         */
        enum H264PictureField {
            /**
             */
            "FRAME" = 0,
            /**
             */
            "TOP_FIELD" = 1,
            /**
             */
            "BOTTOM_FIELD" = 2,
        }
        
        namespace H264PictureReference {
            const $gtype: GObject.GType<H264PictureReference>
        }

        /**
         * @since 1.20
         */
        enum H264PictureReference {
            /**
             * Not used for reference picture
             */
            "NONE" = 0,
            /**
             * Used for short-term reference picture
             */
            "SHORT_TERM" = 1,
            /**
             * Used for long-term reference picture
             */
            "LONG_TERM" = 2,
        }
        
        namespace Vp9ReferenceMode {
            const $gtype: GObject.GType<Vp9ReferenceMode>
        }

        /**
         * Reference modes: Specify the type of inter prediction to be used
         * @since 1.20
         */
        enum Vp9ReferenceMode {
            /**
             * Indicates that all the inter blocks use only a single reference frame
             */
            "SINGLE_REFERENCE" = 0,
            /**
             * Requires all the inter blocks to use compound mode
             */
            "COMPOUND_REFERENCE" = 1,
            /**
             * Allows each individual inter block to select between single and compound prediction modes
             */
            "SELECT" = 2,
        }
        
        namespace Vp9TxMode {
            const $gtype: GObject.GType<Vp9TxMode>
        }

        /**
         * TxMode: Specifies how the transform size is determined
         * @since 1.20
         */
        enum Vp9TxMode {
            /**
             * Only 4x4
             */
            "ONLY_4X4" = 0,
            /**
             * Allow 8x8
             */
            "ALLOW_8X8" = 1,
            /**
             * Allow 16x16
             */
            "ALLOW_16X16" = 2,
            /**
             * Allow 32x32
             */
            "ALLOW_32X32" = 3,
            /**
             * The choice is specified explicitly for each block
             */
            "SELECT" = 4,
        }
        
        namespace Vp9TxSize {
            const $gtype: GObject.GType<Vp9TxSize>
        }

        /**
         * TxSize: Specifies the transform size
         * @since 1.20
         */
        enum Vp9TxSize {
            /**
             * 4x4
             */
            "4X4" = 0,
            /**
             * 8x8
             */
            "8X8" = 1,
            /**
             * 16x16
             */
            "16X16" = 2,
            /**
             * 32x32
             */
            "32X32" = 3,
        }
    }

    export default GstCodecs
}