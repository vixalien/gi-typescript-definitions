
/// <reference path="./GLib-2.0.d.ts" />
/// <reference path="./GModule-2.0.d.ts" />
/// <reference path="./GObject-2.0.d.ts" />
/// <reference path="./Gst-1.0.d.ts" />
/// <reference path="./GstBase-1.0.d.ts" />

/**
 * Type Definitions for GJS (https://gjs.guide/), generated by [GirGen](https://github.com/aylur/girgen)
 * If you found a bug, create a bug report on [GirGen's Repository](https://github.com/aylur/girgen/issues/new)
 */
declare module "gi://GstAudio?version=1.0" {
    import type GLib from "gi://GLib?version=2.0"
    import type GModule from "gi://GModule?version=2.0"
    import type GObject from "gi://GObject?version=2.0"
    import type Gst from "gi://Gst?version=1.0"
    import type GstBase from "gi://GstBase?version=1.0"

    


    namespace GstAudio {
        const __name__: "GstAudio"
        const __version: "1.0"
        

        namespace StreamVolume {
            interface SignalSignatures extends GObject.Object.SignalSignatures {
            }

            interface ReadableProperties extends GObject.Object.ReadableProperties {
                "mute": boolean
                "volume": number
            }

            interface WritableProperties extends GObject.Object.WritableProperties {
                "mute": boolean
                "volume": number
            }

            interface ConstructOnlyProperties extends GObject.Object.ConstructOnlyProperties {
            }

            interface Interface extends GObject.Object {
            }
        }

        /**
         * This interface is implemented by elements that provide a stream volume. Examples for
         * such elements are #volume and #playbin.
         *
         * Applications can use this interface to get or set the current stream volume. For this
         * the "volume" #GObject property can be used or the helper functions gst_stream_volume_set_volume()
         * and gst_stream_volume_get_volume(). This volume is always a linear factor, i.e. 0.0 is muted
         * 1.0 is 100%. For showing the volume in a GUI it might make sense to convert it to
         * a different format by using gst_stream_volume_convert_volume(). Volume sliders should usually
         * use a cubic volume.
         *
         * Separate from the volume the stream can also be muted by the "mute" #GObject property or
         * gst_stream_volume_set_mute() and gst_stream_volume_get_mute().
         *
         * Elements that provide some kind of stream volume should implement the "volume" and
         * "mute" #GObject properties and handle setting and getting of them properly.
         * The volume property is defined to be a linear volume factor.
         */
        interface StreamVolume extends GObject.Object, StreamVolume.Interface {
            readonly $signals: StreamVolume.SignalSignatures
            readonly $readableProperties: StreamVolume.ReadableProperties
            readonly $writableProperties: StreamVolume.WritableProperties
            readonly $constructOnlyProperties: StreamVolume.ConstructOnlyProperties
            /**
             * @default FALSE
             */
            get mute(): boolean
            set mute(value: boolean)
            /**
             * @default 1.000000
             */
            get volume(): number
            set volume(value: number)
            /**
             * @returns Returns %TRUE if the stream is muted
             */
            get_mute(): boolean
            /**
             * @param format #GstStreamVolumeFormat which should be returned
             * @returns The current stream volume as linear factor
             */
            get_volume(format: StreamVolumeFormat): number
            /**
             * @param mute Mute state that should be set
             */
            set_mute(mute: boolean): void
            /**
             * @param format #GstStreamVolumeFormat of @val
             * @param val Linear volume factor that should be set
             */
            set_volume(format: StreamVolumeFormat, val: number): void
        }


        interface StreamVolumeInterface {
            readonly $gtype: GObject.GType<StreamVolume>
            readonly prototype: StreamVolume
            /**
             * @param from #GstStreamVolumeFormat to convert from
             * @param to #GstStreamVolumeFormat to convert to
             * @param val Volume in @from format that should be converted
             * @returns the converted volume
             */
            convert_volume(from: StreamVolumeFormat, to: StreamVolumeFormat, val: number): number

            [Symbol.hasInstance](instance: unknown): instance is StreamVolume
        }

        const StreamVolume: StreamVolumeInterface
        

        namespace AudioAggregator {
            interface SignalSignatures extends GstBase.Aggregator.SignalSignatures {
            }

            interface ReadableProperties extends GstBase.Aggregator.ReadableProperties {
                "alignment-threshold": number
                "discont-wait": number
                "force-live": boolean
                "ignore-inactive-pads": boolean
                "output-buffer-duration": number
                "output-buffer-duration-fraction": Gst.Fraction
            }

            interface WritableProperties extends GstBase.Aggregator.WritableProperties {
                "alignment-threshold": number
                "discont-wait": number
                "force-live": boolean
                "ignore-inactive-pads": boolean
                "output-buffer-duration": number
                "output-buffer-duration-fraction": Gst.Fraction
            }

            interface ConstructOnlyProperties extends GstBase.Aggregator.ConstructOnlyProperties {
            }
        }

        /**
         * Subclasses must use (a subclass of) #GstAudioAggregatorPad for both
         * their source and sink pads,
         * gst_element_class_add_static_pad_template_with_gtype() is a convenient
         * helper.
         *
         * #GstAudioAggregator can perform conversion on the data arriving
         * on its sink pads, based on the format expected downstream: in order
         * to enable that behaviour, the GType of the sink pads must either be
         * a (subclass of) #GstAudioAggregatorConvertPad to use the default
         * #GstAudioConverter implementation, or a subclass of #GstAudioAggregatorPad
         * implementing #GstAudioAggregatorPadClass.convert_buffer.
         *
         * To allow for the output caps to change, the mechanism is the same as
         * above, with the GType of the source pad.
         *
         * See #GstAudioMixer for an example.
         *
         * When conversion is enabled, #GstAudioAggregator will accept
         * any type of raw audio caps and perform conversion
         * on the data arriving on its sink pads, with whatever downstream
         * expects as the target format.
         *
         * In case downstream caps are not fully fixated, it will use
         * the first configured sink pad to finish fixating its source pad
         * caps.
         *
         * A notable exception for now is the sample rate, sink pads must
         * have the same sample rate as either the downstream requirement,
         * or the first configured pad, or a combination of both (when
         * downstream specifies a range or a set of acceptable rates).
         *
         * The #GstAggregator::samples-selected signal is provided with some
         * additional information about the output buffer:
         * - "offset"  G_TYPE_UINT64   Offset in samples since segment start
         *   for the position that is next to be filled in the output buffer.
         * - "frames"  G_TYPE_UINT   Number of frames per output buffer.
         *
         * In addition the gst_aggregator_peek_next_sample() function returns
         * additional information in the info #GstStructure of the returned sample:
         * - "output-offset"  G_TYPE_UINT64   Sample offset in output segment relative to
         *   the output segment's start where the current position of this input
         *   buffer would be placed
         * - "position"  G_TYPE_UINT   current position in the input buffer in samples
         * - "size"  G_TYPE_UINT   size of the input buffer in samples
         * @since 1.14
         */
        interface AudioAggregator extends GstBase.Aggregator {
            readonly $signals: AudioAggregator.SignalSignatures
            readonly $readableProperties: AudioAggregator.ReadableProperties
            readonly $writableProperties: AudioAggregator.WritableProperties
            readonly $constructOnlyProperties: AudioAggregator.ConstructOnlyProperties
            /**
             * @default 40000000
             */
            get alignmentThreshold(): number
            set alignmentThreshold(value: number)
            /**
             * @default 1000000000
             */
            get discontWait(): number
            set discontWait(value: number)
            /**
             * Causes the element to aggregate on a timeout even when no live source is
             * connected to its sinks. See #GstAggregator:min-upstream-latency for a
             * companion property: in the vast majority of cases where you plan to plug in
             * live sources with a non-zero latency, you should set it to a non-zero value.
             * @since 1.22
             * @default FALSE
             */
            get forceLive(): boolean
            set forceLive(value: boolean)
            /**
             * Don't wait for inactive pads when live. An inactive pad
             * is a pad that hasn't yet received a buffer, but that has
             * been waited on at least once.
             *
             * The purpose of this property is to avoid aggregating on
             * timeout when new pads are requested in advance of receiving
             * data flow, for example the user may decide to connect it later,
             * but wants to configure it already.
             * @since 1.20
             * @default FALSE
             */
            get ignoreInactivePads(): boolean
            set ignoreInactivePads(value: boolean)
            /**
             * @default 10000000
             */
            get outputBufferDuration(): number
            set outputBufferDuration(value: number)
            /**
             * Output block size in nanoseconds, expressed as a fraction.
             * @since 1.18
             * @default 1/100
             */
            get outputBufferDurationFraction(): Gst.Fraction
            set outputBufferDurationFraction(value: Gst.Fraction)
            /**
             * @param pad
             * @param caps
             */
            set_sink_caps(pad: AudioAggregatorPad, caps: Gst.Caps): void
            /**
             * Aggregates one input buffer to the output
             *  buffer.  The in_offset and out_offset are in "frames", which is
             *  the size of a sample times the number of channels. Returns TRUE if
             *  any non-silence was added to the buffer
             * @param pad
             * @param inbuf
             * @param in_offset
             * @param outbuf
             * @param out_offset
             * @param num_frames
             */
            vfunc_aggregate_one_buffer(pad: AudioAggregatorPad, inbuf: Gst.Buffer, in_offset: number, outbuf: Gst.Buffer, out_offset: number, num_frames: number): boolean
            /**
             * Create a new output buffer contains num_frames frames.
             * @param num_frames
             */
            vfunc_create_output_buffer(num_frames: number): Gst.Buffer
        }

        interface AudioAggregatorClass extends Omit<GstBase.AggregatorClass, "new"> {
            readonly $gtype: GObject.GType<AudioAggregator>
            readonly prototype: AudioAggregator
            new (props?: Partial<GObject.ConstructorProps<AudioAggregator>>): AudioAggregator
        }

        const AudioAggregator: AudioAggregatorClass
        

        namespace AudioAggregatorConvertPad {
            interface SignalSignatures extends AudioAggregatorPad.SignalSignatures {
            }

            interface ReadableProperties extends AudioAggregatorPad.ReadableProperties {
                "converter-config": Gst.Structure
            }

            interface WritableProperties extends AudioAggregatorPad.WritableProperties {
                "converter-config": Gst.Structure
            }

            interface ConstructOnlyProperties extends AudioAggregatorPad.ConstructOnlyProperties {
            }
        }

        /**
         * An implementation of GstPad that can be used with #GstAudioAggregator.
         *
         * See #GstAudioAggregator for more details.
         * @since 1.14
         */
        interface AudioAggregatorConvertPad extends AudioAggregatorPad {
            readonly $signals: AudioAggregatorConvertPad.SignalSignatures
            readonly $readableProperties: AudioAggregatorConvertPad.ReadableProperties
            readonly $writableProperties: AudioAggregatorConvertPad.WritableProperties
            readonly $constructOnlyProperties: AudioAggregatorConvertPad.ConstructOnlyProperties
            /**
             */
            get converterConfig(): Gst.Structure
            set converterConfig(value: Gst.Structure)
        }

        interface AudioAggregatorConvertPadClass extends Omit<AudioAggregatorPadClass, "new"> {
            readonly $gtype: GObject.GType<AudioAggregatorConvertPad>
            readonly prototype: AudioAggregatorConvertPad
            new (props?: Partial<GObject.ConstructorProps<AudioAggregatorConvertPad>>): AudioAggregatorConvertPad
        }

        const AudioAggregatorConvertPad: AudioAggregatorConvertPadClass
        

        namespace AudioAggregatorPad {
            interface SignalSignatures extends GstBase.AggregatorPad.SignalSignatures {
            }

            interface ReadableProperties extends GstBase.AggregatorPad.ReadableProperties {
                "qos-messages": boolean
            }

            interface WritableProperties extends GstBase.AggregatorPad.WritableProperties {
                "qos-messages": boolean
            }

            interface ConstructOnlyProperties extends GstBase.AggregatorPad.ConstructOnlyProperties {
            }
        }

        /**
         * The default implementation of GstPad used with #GstAudioAggregator
         * @since 1.14
         */
        interface AudioAggregatorPad extends GstBase.AggregatorPad {
            readonly $signals: AudioAggregatorPad.SignalSignatures
            readonly $readableProperties: AudioAggregatorPad.ReadableProperties
            readonly $writableProperties: AudioAggregatorPad.WritableProperties
            readonly $constructOnlyProperties: AudioAggregatorPad.ConstructOnlyProperties
            /**
             * Emit QoS messages when dropping buffers.
             * @since 1.20
             * @default FALSE
             */
            get qosMessages(): boolean
            set qosMessages(value: boolean)
            /**
             * Convert a buffer from one format to another.
             * @param in_info
             * @param out_info
             * @param buffer
             */
            vfunc_convert_buffer(in_info: AudioInfo, out_info: AudioInfo, buffer: Gst.Buffer): Gst.Buffer
            /**
             * Called when either the input or output
             *  formats have changed.
             */
            vfunc_update_conversion_info(): void
        }

        interface AudioAggregatorPadClass extends Omit<GstBase.AggregatorPadClass, "new"> {
            readonly $gtype: GObject.GType<AudioAggregatorPad>
            readonly prototype: AudioAggregatorPad
            new (props?: Partial<GObject.ConstructorProps<AudioAggregatorPad>>): AudioAggregatorPad
        }

        const AudioAggregatorPad: AudioAggregatorPadClass
        

        namespace AudioBaseSink {
            interface SignalSignatures extends GstBase.BaseSink.SignalSignatures {
            }

            interface ReadableProperties extends GstBase.BaseSink.ReadableProperties {
                "alignment-threshold": number
                "buffer-time": number
                "can-activate-pull": boolean
                "discont-wait": number
                "drift-tolerance": number
                "latency-time": number
                "provide-clock": boolean
                "slave-method": AudioBaseSinkSlaveMethod
            }

            interface WritableProperties extends GstBase.BaseSink.WritableProperties {
                "alignment-threshold": number
                "buffer-time": number
                "can-activate-pull": boolean
                "discont-wait": number
                "drift-tolerance": number
                "latency-time": number
                "provide-clock": boolean
                "slave-method": AudioBaseSinkSlaveMethod
            }

            interface ConstructOnlyProperties extends GstBase.BaseSink.ConstructOnlyProperties {
            }
        }

        /**
         * This is the base class for audio sinks. Subclasses need to implement the
         * ::create_ringbuffer vmethod. This base class will then take care of
         * writing samples to the ringbuffer, synchronisation, clipping and flushing.
         */
        interface AudioBaseSink extends GstBase.BaseSink {
            readonly $signals: AudioBaseSink.SignalSignatures
            readonly $readableProperties: AudioBaseSink.ReadableProperties
            readonly $writableProperties: AudioBaseSink.WritableProperties
            readonly $constructOnlyProperties: AudioBaseSink.ConstructOnlyProperties
            /**
             * @default 40000000
             */
            get alignmentThreshold(): number
            set alignmentThreshold(value: number)
            /**
             * @default 200000
             */
            get bufferTime(): number
            set bufferTime(value: number)
            /**
             * @default FALSE
             */
            get canActivatePull(): boolean
            set canActivatePull(value: boolean)
            /**
             * A window of time in nanoseconds to wait before creating a discontinuity as
             * a result of breaching the drift-tolerance.
             * @default 1000000000
             */
            get discontWait(): number
            set discontWait(value: number)
            /**
             * Controls the amount of time in microseconds that clocks are allowed
             * to drift before resynchronisation happens.
             * @default 40000
             */
            get driftTolerance(): number
            set driftTolerance(value: number)
            /**
             * @default 10000
             */
            get latencyTime(): number
            set latencyTime(value: number)
            /**
             * @default TRUE
             */
            get provideClock(): boolean
            set provideClock(value: boolean)
            /**
             * @default GST_AUDIO_BASE_SINK_SLAVE_SKEW
             */
            get slaveMethod(): AudioBaseSinkSlaveMethod
            set slaveMethod(value: AudioBaseSinkSlaveMethod)
            /**
             * Create and return the #GstAudioRingBuffer for @sink. This function will
             * call the ::create_ringbuffer vmethod and will set @sink as the parent of
             * the returned buffer (see gst_object_set_parent()).
             * @returns The new ringbuffer of `sink`.
             */
            create_ringbuffer(): AudioRingBuffer | null
            /**
             * Get the current alignment threshold, in nanoseconds, used by @sink.
             * @returns The current alignment threshold used by `sink`.
             */
            get_alignment_threshold(): Gst.ClockTime
            /**
             * Get the current discont wait, in nanoseconds, used by @sink.
             * @returns The current discont wait used by `sink`.
             */
            get_discont_wait(): Gst.ClockTime
            /**
             * Get the current drift tolerance, in microseconds, used by @sink.
             * @returns The current drift tolerance used by `sink`.
             */
            get_drift_tolerance(): number
            /**
             * Queries whether @sink will provide a clock or not. See also
             * gst_audio_base_sink_set_provide_clock.
             * @returns %TRUE if `sink` will provide a clock.
             */
            get_provide_clock(): boolean
            /**
             * Get the current slave method used by @sink.
             * @returns The current slave method used by `sink`.
             */
            get_slave_method(): AudioBaseSinkSlaveMethod
            /**
             * Informs this base class that the audio output device has failed for
             * some reason, causing a discontinuity (for example, because the device
             * recovered from the error, but lost all contents of its ring buffer).
             * This function is typically called by derived classes, and is useful
             * for the custom slave method.
             * @since 1.6
             */
            report_device_failure(): void
            /**
             * Controls the sink's alignment threshold.
             * @param alignment_threshold the new alignment threshold in nanoseconds
             */
            set_alignment_threshold(alignment_threshold: Gst.ClockTime): void
            /**
             * Sets the custom slaving callback. This callback will
             * be invoked if the slave-method property is set to
             * GST_AUDIO_BASE_SINK_SLAVE_CUSTOM and the audio sink
             * receives and plays samples.
             *
             * Setting the callback to NULL causes the sink to
             * behave as if the GST_AUDIO_BASE_SINK_SLAVE_NONE
             * method were used.
             * @since 1.6
             * @param callback a #GstAudioBaseSinkCustomSlavingCallback
             */
            set_custom_slaving_callback(callback: AudioBaseSinkCustomSlavingCallback): void
            /**
             * Controls how long the sink will wait before creating a discontinuity.
             * @param discont_wait the new discont wait in nanoseconds
             */
            set_discont_wait(discont_wait: Gst.ClockTime): void
            /**
             * Controls the sink's drift tolerance.
             * @param drift_tolerance the new drift tolerance in microseconds
             */
            set_drift_tolerance(drift_tolerance: number): void
            /**
             * Controls whether @sink will provide a clock or not. If @provide is %TRUE,
             * gst_element_provide_clock() will return a clock that reflects the datarate
             * of @sink. If @provide is %FALSE, gst_element_provide_clock() will return
             * NULL.
             * @param provide new state
             */
            set_provide_clock(provide: boolean): void
            /**
             * Controls how clock slaving will be performed in @sink.
             * @param method the new slave method
             */
            set_slave_method(method: AudioBaseSinkSlaveMethod): void
            /**
             * Create and return the #GstAudioRingBuffer for @sink. This function will
             * call the ::create_ringbuffer vmethod and will set @sink as the parent of
             * the returned buffer (see gst_object_set_parent()).
             * @returns The new ringbuffer of `sink`.
             */
            vfunc_create_ringbuffer(): AudioRingBuffer | null
            /**
             * payload data in a format suitable to write to the sink. If no
             *           payloading is required, returns a reffed copy of the original
             *           buffer, else returns the payloaded buffer with all other metadata
             *           copied.
             * @param buffer
             */
            vfunc_payload(buffer: Gst.Buffer): Gst.Buffer
        }

        interface AudioBaseSinkClass extends Omit<GstBase.BaseSinkClass, "new"> {
            readonly $gtype: GObject.GType<AudioBaseSink>
            readonly prototype: AudioBaseSink
            new (props?: Partial<GObject.ConstructorProps<AudioBaseSink>>): AudioBaseSink
        }

        const AudioBaseSink: AudioBaseSinkClass
        

        namespace AudioBaseSrc {
            interface SignalSignatures extends GstBase.PushSrc.SignalSignatures {
            }

            interface ReadableProperties extends GstBase.PushSrc.ReadableProperties {
                "actual-buffer-time": number
                "actual-latency-time": number
                "buffer-time": number
                "latency-time": number
                "provide-clock": boolean
                "slave-method": AudioBaseSrcSlaveMethod
            }

            interface WritableProperties extends GstBase.PushSrc.WritableProperties {
                "actual-buffer-time": number
                "actual-latency-time": number
                "buffer-time": number
                "latency-time": number
                "provide-clock": boolean
                "slave-method": AudioBaseSrcSlaveMethod
            }

            interface ConstructOnlyProperties extends GstBase.PushSrc.ConstructOnlyProperties {
            }
        }

        /**
         * This is the base class for audio sources. Subclasses need to implement the
         * ::create_ringbuffer vmethod. This base class will then take care of
         * reading samples from the ringbuffer, synchronisation and flushing.
         */
        interface AudioBaseSrc extends GstBase.PushSrc {
            readonly $signals: AudioBaseSrc.SignalSignatures
            readonly $readableProperties: AudioBaseSrc.ReadableProperties
            readonly $writableProperties: AudioBaseSrc.WritableProperties
            readonly $constructOnlyProperties: AudioBaseSrc.ConstructOnlyProperties
            /**
             * Actual configured size of audio buffer in microseconds.
             * @default -1
             */
            get actualBufferTime(): number
            set actualBufferTime(value: number)
            /**
             * Actual configured audio latency in microseconds.
             * @default -1
             */
            get actualLatencyTime(): number
            set actualLatencyTime(value: number)
            /**
             * @default 200000
             */
            get bufferTime(): number
            set bufferTime(value: number)
            /**
             * @default 10000
             */
            get latencyTime(): number
            set latencyTime(value: number)
            /**
             * @default TRUE
             */
            get provideClock(): boolean
            set provideClock(value: boolean)
            /**
             * @default GST_AUDIO_BASE_SRC_SLAVE_SKEW
             */
            get slaveMethod(): AudioBaseSrcSlaveMethod
            set slaveMethod(value: AudioBaseSrcSlaveMethod)
            /**
             * Create and return the #GstAudioRingBuffer for @src. This function will call
             * the ::create_ringbuffer vmethod and will set @src as the parent of the
             * returned buffer (see gst_object_set_parent()).
             * @returns The new ringbuffer of `src`.
             */
            create_ringbuffer(): AudioRingBuffer | null
            /**
             * Queries whether @src will provide a clock or not. See also
             * gst_audio_base_src_set_provide_clock.
             * @returns %TRUE if `src` will provide a clock.
             */
            get_provide_clock(): boolean
            /**
             * Get the current slave method used by @src.
             * @returns The current slave method used by `src`.
             */
            get_slave_method(): AudioBaseSrcSlaveMethod
            /**
             * Controls whether @src will provide a clock or not. If @provide is %TRUE,
             * gst_element_provide_clock() will return a clock that reflects the datarate
             * of @src. If @provide is %FALSE, gst_element_provide_clock() will return NULL.
             * @param provide new state
             */
            set_provide_clock(provide: boolean): void
            /**
             * Controls how clock slaving will be performed in @src.
             * @param method the new slave method
             */
            set_slave_method(method: AudioBaseSrcSlaveMethod): void
            /**
             * Create and return the #GstAudioRingBuffer for @src. This function will call
             * the ::create_ringbuffer vmethod and will set @src as the parent of the
             * returned buffer (see gst_object_set_parent()).
             * @returns The new ringbuffer of `src`.
             */
            vfunc_create_ringbuffer(): AudioRingBuffer | null
        }

        interface AudioBaseSrcClass extends Omit<GstBase.PushSrcClass, "new"> {
            readonly $gtype: GObject.GType<AudioBaseSrc>
            readonly prototype: AudioBaseSrc
            new (props?: Partial<GObject.ConstructorProps<AudioBaseSrc>>): AudioBaseSrc
        }

        const AudioBaseSrc: AudioBaseSrcClass
        

        namespace AudioCdSrc {
            interface SignalSignatures extends GstBase.PushSrc.SignalSignatures, Gst.URIHandler.SignalSignatures {
            }

            interface ReadableProperties extends GstBase.PushSrc.ReadableProperties, Gst.URIHandler.ReadableProperties {
                "device": string
                "mode": AudioCdSrcMode
                "track": number
            }

            interface WritableProperties extends GstBase.PushSrc.WritableProperties, Gst.URIHandler.WritableProperties {
                "device": string
                "mode": AudioCdSrcMode
                "track": number
            }

            interface ConstructOnlyProperties extends GstBase.PushSrc.ConstructOnlyProperties, Gst.URIHandler.ConstructOnlyProperties {
            }
        }

        /**
         * s of its own, namely
         * the "track" format and the "sector" format. Applications will usually
         * only find the "track" format interesting. You can retrieve that #GstFormat
         * for use in seek events or queries with gst_format_get_by_nick("track").
         *
         * In order to query the number of tracks, for example, an application would
         * set the CDDA source element to READY or PAUSED state and then query the
         * the number of tracks via gst_element_query_duration() using the track
         * format acquired above. Applications can query the currently playing track
         * in the same way.
         *
         * Alternatively, applications may retrieve the currently playing track and
         * the total number of tracks from the taglist that will posted on the bus
         * whenever the CD is opened or the currently playing track changes. The
         * taglist will contain GST_TAG_TRACK_NUMBER and GST_TAG_TRACK_COUNT tags.
         *
         * Applications playing back CD audio using playbin and cdda://n URIs should
         * issue a seek command in track format to change between tracks, rather than
         * setting a new cdda://n+1 URI on playbin (as setting a new URI on playbin
         * involves closing and re-opening the CD device, which is much much slower).
         *
         * ## Tags and meta-information
         *
         * CDDA sources will automatically emit a number of tags, details about which
         * can be found in the libgsttag documentation. Those tags are:
         * #GST_TAG_CDDA_CDDB_DISCID, #GST_TAG_CDDA_CDDB_DISCID_FULL,
         * #GST_TAG_CDDA_MUSICBRAINZ_DISCID, #GST_TAG_CDDA_MUSICBRAINZ_DISCID_FULL,
         * among others.
         *
         * ## Tracks and Table of Contents (TOC)
         *
         * Applications will be informed of the available tracks via a TOC message
         * on the pipeline's #GstBus. The #GstToc will contain a #GstTocEntry for
         * each track, with information about each track. The duration for each
         * track can be retrieved via the #GST_TAG_DURATION tag from each entry's
         * tag list, or calculated via gst_toc_entry_get_start_stop_times().
         * The track entries in the TOC will be sorted by track number.
         */
        interface AudioCdSrc extends GstBase.PushSrc, Gst.URIHandler {
            readonly $signals: AudioCdSrc.SignalSignatures
            readonly $readableProperties: AudioCdSrc.ReadableProperties
            readonly $writableProperties: AudioCdSrc.WritableProperties
            readonly $constructOnlyProperties: AudioCdSrc.ConstructOnlyProperties
            /**
             * @default NULL
             */
            get device(): string
            set device(value: string)
            /**
             * @default GST_AUDIO_CD_SRC_MODE_NORMAL
             */
            get mode(): AudioCdSrcMode
            set mode(value: AudioCdSrcMode)
            /**
             * @default 1
             */
            get track(): number
            set track(value: number)
            /**
             * CDDA sources use this function from their start vfunc to announce the
             * available data and audio tracks to the base source class. The caller
             * should allocate @track on the stack, the base source will do a shallow
             * copy of the structure (and take ownership of the taglist if there is one).
             * @param track address of #GstAudioCdSrcTrack to add
             * @returns FALSE on error, otherwise TRUE.
             */
            add_track(track: AudioCdSrcTrack): boolean
            /**
             * closing the device
             */
            vfunc_close(): void
            /**
             * opening the device
             * @param device
             */
            vfunc_open(device: string): boolean
            /**
             * reading a sector
             * @param sector
             */
            vfunc_read_sector(sector: number): Gst.Buffer
        }

        interface AudioCdSrcClass extends Omit<GstBase.PushSrcClass, "new"> {
            readonly $gtype: GObject.GType<AudioCdSrc>
            readonly prototype: AudioCdSrc
            new (props?: Partial<GObject.ConstructorProps<AudioCdSrc>>): AudioCdSrc
        }

        const AudioCdSrc: AudioCdSrcClass
        

        namespace AudioClock {
            interface SignalSignatures extends Gst.SystemClock.SignalSignatures {
            }

            interface ReadableProperties extends Gst.SystemClock.ReadableProperties {
            }

            interface WritableProperties extends Gst.SystemClock.WritableProperties {
            }

            interface ConstructOnlyProperties extends Gst.SystemClock.ConstructOnlyProperties {
            }
        }

        /**
         * #GstAudioClock makes it easy for elements to implement a #GstClock, they
         * simply need to provide a function that returns the current clock time.
         *
         * This object is internally used to implement the clock in #GstAudioBaseSink.
         */
        interface AudioClock extends Gst.SystemClock {
            readonly $signals: AudioClock.SignalSignatures
            readonly $readableProperties: AudioClock.ReadableProperties
            readonly $writableProperties: AudioClock.WritableProperties
            readonly $constructOnlyProperties: AudioClock.ConstructOnlyProperties
            /**
             * Adjust @time with the internal offset of the audio clock.
             * @param time a #GstClockTime
             * @returns  `time` adjusted with the internal offset.
             */
            adjust(time: Gst.ClockTime): Gst.ClockTime
            /**
             * Report the time as returned by the #GstAudioClockGetTimeFunc without applying
             * any offsets.
             * @returns the time as reported by the time function of the audio clock
             */
            get_time(): Gst.ClockTime
            /**
             * Invalidate the clock function. Call this function when the provided
             * #GstAudioClockGetTimeFunc cannot be called anymore, for example, when the
             * user_data becomes invalid.
             *
             * After calling this function, @clock will return the last returned time for
             * the rest of its lifetime.
             */
            invalidate(): void
            /**
             * Inform @clock that future calls to #GstAudioClockGetTimeFunc will return values
             * starting from @time. The clock will update an internal offset to make sure that
             * future calls to internal_time will return an increasing result as required by
             * the #GstClock object.
             * @param time a #GstClockTime
             */
            reset(time: Gst.ClockTime): void
        }

        interface AudioClockClass extends Omit<Gst.SystemClockClass, "new"> {
            readonly $gtype: GObject.GType<AudioClock>
            readonly prototype: AudioClock
            new (props?: Partial<GObject.ConstructorProps<AudioClock>>): AudioClock
            /**
             * Create a new #GstAudioClock instance. Whenever the clock time should be
             * calculated it will call @func with @user_data. When @func returns
             * #GST_CLOCK_TIME_NONE, the clock will return the last reported time.
             * @param name the name of the clock
             * @param func a function
             * @returns a new #GstAudioClock casted to a #GstClock.
             */
            "new"(name: string, func: AudioClockGetTimeFunc): AudioClock
        }

        const AudioClock: AudioClockClass
        

        namespace AudioDecoder {
            interface SignalSignatures extends Gst.Element.SignalSignatures {
            }

            interface ReadableProperties extends Gst.Element.ReadableProperties {
                "max-errors": number
                "min-latency": number
                "plc": boolean
                "tolerance": number
            }

            interface WritableProperties extends Gst.Element.WritableProperties {
                "max-errors": number
                "min-latency": number
                "plc": boolean
                "tolerance": number
            }

            interface ConstructOnlyProperties extends Gst.Element.ConstructOnlyProperties {
            }
        }

        /**
         * This base class is for audio decoders turning encoded data into
         * raw audio samples.
         *
         * GstAudioDecoder and subclass should cooperate as follows.
         *
         * ## Configuration
         *
         *   * Initially, GstAudioDecoder calls @start when the decoder element
         *     is activated, which allows subclass to perform any global setup.
         *     Base class (context) parameters can already be set according to subclass
         *     capabilities (or possibly upon receive more information in subsequent
         *     @set_format).
         *   * GstAudioDecoder calls @set_format to inform subclass of the format
         *     of input audio data that it is about to receive.
         *     While unlikely, it might be called more than once, if changing input
         *     parameters require reconfiguration.
         *   * GstAudioDecoder calls @stop at end of all processing.
         *
         * As of configuration stage, and throughout processing, GstAudioDecoder
         * provides various (context) parameters, e.g. describing the format of
         * output audio data (valid when output caps have been set) or current parsing state.
         * Conversely, subclass can and should configure context to inform
         * base class of its expectation w.r.t. buffer handling.
         *
         * ## Data processing
         *     * Base class gathers input data, and optionally allows subclass
         *       to parse this into subsequently manageable (as defined by subclass)
         *       chunks.  Such chunks are subsequently referred to as 'frames',
         *       though they may or may not correspond to 1 (or more) audio format frame.
         *     * Input frame is provided to subclass' @handle_frame.
         *     * If codec processing results in decoded data, subclass should call
         *       @gst_audio_decoder_finish_frame to have decoded data pushed
         *       downstream.
         *     * Just prior to actually pushing a buffer downstream,
         *       it is passed to @pre_push.  Subclass should either use this callback
         *       to arrange for additional downstream pushing or otherwise ensure such
         *       custom pushing occurs after at least a method call has finished since
         *       setting src pad caps.
         *     * During the parsing process GstAudioDecoderClass will handle both
         *       srcpad and sinkpad events. Sink events will be passed to subclass
         *       if @event callback has been provided.
         *
         * ## Shutdown phase
         *
         *   * GstAudioDecoder class calls @stop to inform the subclass that data
         *     parsing will be stopped.
         *
         * Subclass is responsible for providing pad template caps for
         * source and sink pads. The pads need to be named "sink" and "src". It also
         * needs to set the fixed caps on srcpad, when the format is ensured.  This
         * is typically when base class calls subclass' @set_format function, though
         * it might be delayed until calling @gst_audio_decoder_finish_frame.
         *
         * In summary, above process should have subclass concentrating on
         * codec data processing while leaving other matters to base class,
         * such as most notably timestamp handling.  While it may exert more control
         * in this area (see e.g. @pre_push), it is very much not recommended.
         *
         * In particular, base class will try to arrange for perfect output timestamps
         * as much as possible while tracking upstream timestamps.
         * To this end, if deviation between the next ideal expected perfect timestamp
         * and upstream exceeds #GstAudioDecoder:tolerance, then resync to upstream
         * occurs (which would happen always if the tolerance mechanism is disabled).
         *
         * In non-live pipelines, baseclass can also (configurably) arrange for
         * output buffer aggregation which may help to redue large(r) numbers of
         * small(er) buffers being pushed and processed downstream. Note that this
         * feature is only available if the buffer layout is interleaved. For planar
         * buffers, the decoder implementation is fully responsible for the output
         * buffer size.
         *
         * On the other hand, it should be noted that baseclass only provides limited
         * seeking support (upon explicit subclass request), as full-fledged support
         * should rather be left to upstream demuxer, parser or alike.  This simple
         * approach caters for seeking and duration reporting using estimated input
         * bitrates.
         *
         * Things that subclass need to take care of:
         *
         *   * Provide pad templates
         *   * Set source pad caps when appropriate
         *   * Set user-configurable properties to sane defaults for format and
         *      implementing codec at hand, and convey some subclass capabilities and
         *      expectations in context.
         *
         *   * Accept data in @handle_frame and provide encoded results to
         *      @gst_audio_decoder_finish_frame.  If it is prepared to perform
         *      PLC, it should also accept NULL data in @handle_frame and provide for
         *      data for indicated duration.
         */
        interface AudioDecoder extends Gst.Element {
            readonly $signals: AudioDecoder.SignalSignatures
            readonly $readableProperties: AudioDecoder.ReadableProperties
            readonly $writableProperties: AudioDecoder.WritableProperties
            readonly $constructOnlyProperties: AudioDecoder.ConstructOnlyProperties
            /**
             * Maximum number of tolerated consecutive decode errors. See
             * gst_audio_decoder_set_max_errors() for more details.
             * @since 1.18
             * @default -1
             */
            get maxErrors(): number
            set maxErrors(value: number)
            /**
             * @default 0
             */
            get minLatency(): number
            set minLatency(value: number)
            /**
             * @default FALSE
             */
            get plc(): boolean
            set plc(value: boolean)
            /**
             * @default 0
             */
            get tolerance(): number
            set tolerance(value: number)
            /**
             * Helper function that allocates a buffer to hold an audio frame
             * for @dec's current output format.
             * @param size size of the buffer
             * @returns allocated buffer
             */
            allocate_output_buffer(size: number): Gst.Buffer
            /**
             * Collects decoded data and pushes it downstream.
             *
             * @buf may be NULL in which case the indicated number of frames
             * are discarded and considered to have produced no output
             * (e.g. lead-in or setup frames).
             * Otherwise, source pad caps must be set when it is called with valid
             * data in @buf.
             *
             * Note that a frame received in #GstAudioDecoderClass.handle_frame() may be
             * invalidated by a call to this function.
             * @param buf decoded data
             * @param frames number of decoded frames represented by decoded data
             * @returns a #GstFlowReturn that should be escalated to caller (of caller)
             */
            finish_frame(buf: Gst.Buffer | null, frames: number): Gst.FlowReturn
            /**
             * Collects decoded data and pushes it downstream. This function may be called
             * multiple times for a given input frame.
             *
             * @buf may be NULL in which case it is assumed that the current input frame is
             * finished. This is equivalent to calling gst_audio_decoder_finish_subframe()
             * with a NULL buffer and frames=1 after having pushed out all decoded audio
             * subframes using this function.
             *
             * When called with valid data in @buf the source pad caps must have been set
             * already.
             *
             * Note that a frame received in #GstAudioDecoderClass.handle_frame() may be
             * invalidated by a call to this function.
             * @since 1.16
             * @param buf decoded data
             * @returns a #GstFlowReturn that should be escalated to caller (of caller)
             */
            finish_subframe(buf: Gst.Buffer | null): Gst.FlowReturn
            /**
             * Lets #GstAudioDecoder sub-classes to know the memory @allocator
             * used by the base class and its @params.
             *
             * Unref the @allocator after use it.
             * @returns , the #GstAllocator used, the #GstAllocationParams of `allocator`
             */
            get_allocator(): void
            /**
             * @returns a #GstAudioInfo describing the input audio format
             */
            get_audio_info(): AudioInfo
            /**
             * @returns currently configured decoder delay
             */
            get_delay(): number
            /**
             * Queries decoder drain handling.
             * @returns TRUE if drainable handling is enabled.  MT safe.
             */
            get_drainable(): boolean
            /**
             * @returns currently configured byte to time conversion setting
             */
            get_estimate_rate(): number
            /**
             * Sets the variables pointed to by @min and @max to the currently configured
             * latency.
             * @returns , a pointer to storage to hold minimum latency, a pointer to storage to hold maximum latency
             */
            get_latency(): void
            /**
             * @returns currently configured decoder tolerated error count.
             */
            get_max_errors(): number
            /**
             * Queries decoder's latency aggregation.
             * @returns aggregation latency.  MT safe.
             */
            get_min_latency(): Gst.ClockTime
            /**
             * Queries decoder required format handling.
             * @returns TRUE if required format handling is enabled.  MT safe.
             */
            get_needs_format(): boolean
            /**
             * Return current parsing (sync and eos) state.
             * @returns , a pointer to a variable to hold the current sync state, a pointer to a variable to hold the current eos state
             */
            get_parse_state(): void
            /**
             * Queries decoder packet loss concealment handling.
             * @returns TRUE if packet loss concealment is enabled.  MT safe.
             */
            get_plc(): boolean
            /**
             * @returns currently configured plc handling
             */
            get_plc_aware(): number
            /**
             * Queries current audio jitter tolerance threshold.
             * @returns decoder audio jitter tolerance threshold.  MT safe.
             */
            get_tolerance(): Gst.ClockTime
            /**
             * Sets the audio decoder tags and how they should be merged with any
             * upstream stream tags. This will override any tags previously-set
             * with gst_audio_decoder_merge_tags().
             *
             * Note that this is provided for convenience, and the subclass is
             * not required to use this and can still do tag handling on its own.
             * @param tags a #GstTagList to merge, or NULL
             * @param mode the #GstTagMergeMode to use, usually #GST_TAG_MERGE_REPLACE
             */
            merge_tags(tags: Gst.TagList | null, mode: Gst.TagMergeMode): void
            /**
             * Negotiate with downstream elements to currently configured #GstAudioInfo.
             * Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
             * negotiate fails.
             * @returns %TRUE if the negotiation succeeded, else %FALSE.
             */
            negotiate(): boolean
            /**
             * Returns caps that express @caps (or sink template caps if @caps == NULL)
             * restricted to rate/channels/... combinations supported by downstream
             * elements.
             * @since 1.6
             * @param caps initial caps
             * @param filter filter caps
             * @returns a #GstCaps owned by caller
             */
            proxy_getcaps(caps: Gst.Caps | null, filter: Gst.Caps | null): Gst.Caps
            /**
             * Sets a caps in allocation query which are different from the set
             * pad's caps. Use this function before calling
             * gst_audio_decoder_negotiate(). Setting to %NULL the allocation
             * query will use the caps from the pad.
             * @since 1.10
             * @param allocation_caps a #GstCaps or %NULL
             */
            set_allocation_caps(allocation_caps: Gst.Caps | null): void
            /**
             * Configures decoder drain handling.  If drainable, subclass might
             * be handed a NULL buffer to have it return any leftover decoded data.
             * Otherwise, it is not considered so capable and will only ever be passed
             * real data.
             *
             * MT safe.
             * @param enabled new state
             */
            set_drainable(enabled: boolean): void
            /**
             * Allows baseclass to perform byte to time estimated conversion.
             * @param enabled whether to enable byte to time conversion
             */
            set_estimate_rate(enabled: boolean): void
            /**
             * Sets decoder latency. If the provided values changed from
             * previously provided ones, this will also post a LATENCY message on the bus
             * so the pipeline can reconfigure its global latency.
             * @param min minimum latency
             * @param max maximum latency
             */
            set_latency(min: Gst.ClockTime, max: Gst.ClockTime): void
            /**
             * Sets numbers of tolerated decoder errors, where a tolerated one is then only
             * warned about, but more than tolerated will lead to fatal error. You can set
             * -1 for never returning fatal errors. Default is set to
             * GST_AUDIO_DECODER_MAX_ERRORS.
             * @param num max tolerated errors
             */
            set_max_errors(num: number): void
            /**
             * Sets decoder minimum aggregation latency.
             *
             * MT safe.
             * @param num new minimum latency
             */
            set_min_latency(num: Gst.ClockTime): void
            /**
             * Configures decoder format needs.  If enabled, subclass needs to be
             * negotiated with format caps before it can process any data.  It will then
             * never be handed any data before it has been configured.
             * Otherwise, it might be handed data without having been configured and
             * is then expected being able to do so either by default
             * or based on the input data.
             *
             * MT safe.
             * @param enabled new state
             */
            set_needs_format(enabled: boolean): void
            /**
             * Configure output caps on the srcpad of @dec. Similar to
             * gst_audio_decoder_set_output_format(), but allows subclasses to specify
             * output caps that can't be expressed via #GstAudioInfo e.g. caps that have
             * caps features.
             * @since 1.16
             * @param caps (fixed) #GstCaps
             * @returns %TRUE on success.
             */
            set_output_caps(caps: Gst.Caps): boolean
            /**
             * Configure output info on the srcpad of @dec.
             * @param info #GstAudioInfo
             * @returns %TRUE on success.
             */
            set_output_format(info: AudioInfo): boolean
            /**
             * Enable or disable decoder packet loss concealment, provided subclass
             * and codec are capable and allow handling plc.
             *
             * MT safe.
             * @param enabled new state
             */
            set_plc(enabled: boolean): void
            /**
             * Indicates whether or not subclass handles packet loss concealment (plc).
             * @param plc new plc state
             */
            set_plc_aware(plc: boolean): void
            /**
             * Configures decoder audio jitter tolerance threshold.
             *
             * MT safe.
             * @param tolerance new tolerance
             */
            set_tolerance(tolerance: Gst.ClockTime): void
            /**
             * Lets #GstAudioDecoder sub-classes decide if they want the sink pad
             * to use the default pad query handler to reply to accept-caps queries.
             *
             * By setting this to true it is possible to further customize the default
             * handler with %GST_PAD_SET_ACCEPT_INTERSECT and
             * %GST_PAD_SET_ACCEPT_TEMPLATE
             * @since 1.6
             * @param use if the default pad accept-caps query handling should be used
             */
            set_use_default_pad_acceptcaps(use: boolean): void
            /**
             * Optional.
             *                  Called when the element changes to GST_STATE_NULL.
             *                  Allows closing external resources.
             */
            vfunc_close(): boolean
            /**
             * Optional.
             *                     Setup the allocation parameters for allocating output
             *                     buffers. The passed in query contains the result of the
             *                     downstream allocation query.
             *                     Subclasses should chain up to the parent implementation to
             *                     invoke the default handler.
             * @param query
             */
            vfunc_decide_allocation(query: Gst.Query): boolean
            /**
             * Optional.
             *                  Instructs subclass to clear any codec caches and discard
             *                  any pending samples and not yet returned decoded data.
             *                  @hard indicates whether a FLUSH is being processed,
             *                  or otherwise a DISCONT (or conceptually similar).
             * @param hard
             */
            vfunc_flush(hard: boolean): void
            /**
             * Optional.
             *                  Allows for a custom sink getcaps implementation.
             *                  If not implemented,
             *                  default returns gst_audio_decoder_proxy_getcaps
             *                  applied to sink template caps.
             * @param filter
             */
            vfunc_getcaps(filter: Gst.Caps): Gst.Caps
            /**
             * Provides input data (or NULL to clear any remaining data)
             *                  to subclass.  Input data ref management is performed by
             *                  base class, subclass should not care or intervene,
             *                  and input data is only valid until next call to base class,
             *                  most notably a call to gst_audio_decoder_finish_frame().
             * @param buffer
             */
            vfunc_handle_frame(buffer: Gst.Buffer): Gst.FlowReturn
            /**
             * Negotiate with downstream elements to currently configured #GstAudioInfo.
             * Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
             * negotiate fails.
             * @returns %TRUE if the negotiation succeeded, else %FALSE.
             */
            vfunc_negotiate(): boolean
            /**
             * Optional.
             *                  Called when the element changes to GST_STATE_READY.
             *                  Allows opening external resources.
             */
            vfunc_open(): boolean
            /**
             * @param adapter
             * @returns , , 
             */
            vfunc_parse(adapter: GstBase.Adapter): [Gst.FlowReturn, number, number]
            /**
             * Optional.
             *                  Called just prior to pushing (encoded data) buffer downstream.
             *                  Subclass has full discretionary access to buffer,
             *                  and a not OK flow return will abort downstream pushing.
             * @param buffer
             */
            vfunc_pre_push(buffer: Gst.Buffer): Gst.FlowReturn
            /**
             * Optional.
             *                      Propose buffer allocation parameters for upstream elements.
             *                      Subclasses should chain up to the parent implementation to
             *                      invoke the default handler.
             * @param query
             */
            vfunc_propose_allocation(query: Gst.Query): boolean
            /**
             * Notifies subclass of incoming data format (caps).
             * @param caps
             */
            vfunc_set_format(caps: Gst.Caps): boolean
            /**
             * Optional.
             *                  Event handler on the sink pad. Subclasses should chain up to
             *                  the parent implementation to invoke the default handler.
             * @param event
             */
            vfunc_sink_event(event: Gst.Event): boolean
            /**
             * Optional.
             *                  Query handler on the sink pad. This function should
             *                  return TRUE if the query could be performed. Subclasses
             *                  should chain up to the parent implementation to invoke the
             *                  default handler. Since: 1.6
             * @param query
             */
            vfunc_sink_query(query: Gst.Query): boolean
            /**
             * Optional.
             *                  Event handler on the src pad. Subclasses should chain up to
             *                  the parent implementation to invoke the default handler.
             * @param event
             */
            vfunc_src_event(event: Gst.Event): boolean
            /**
             * Optional.
             *                  Query handler on the source pad. This function should
             *                  return TRUE if the query could be performed. Subclasses
             *                  should chain up to the parent implementation to invoke the
             *                  default handler. Since: 1.6
             * @param query
             */
            vfunc_src_query(query: Gst.Query): boolean
            /**
             * Optional.
             *                  Called when the element starts processing.
             *                  Allows opening external resources.
             */
            vfunc_start(): boolean
            /**
             * Optional.
             *                  Called when the element stops processing.
             *                  Allows closing external resources.
             */
            vfunc_stop(): boolean
            /**
             * Optional. Transform the metadata on the input buffer to the
             *                  output buffer. By default this method copies all meta without
             *                  tags and meta with only the "audio" tag. subclasses can
             *                  implement this method and return %TRUE if the metadata is to be
             *                  copied. Since: 1.6
             * @param outbuf
             * @param meta
             * @param inbuf
             */
            vfunc_transform_meta(outbuf: Gst.Buffer, meta: Gst.Meta, inbuf: Gst.Buffer): boolean
        }

        interface AudioDecoderClass extends Omit<Gst.ElementClass, "new"> {
            readonly $gtype: GObject.GType<AudioDecoder>
            readonly prototype: AudioDecoder
            new (props?: Partial<GObject.ConstructorProps<AudioDecoder>>): AudioDecoder
        }

        const AudioDecoder: AudioDecoderClass
        

        namespace AudioEncoder {
            interface SignalSignatures extends Gst.Element.SignalSignatures, Gst.Preset.SignalSignatures {
            }

            interface ReadableProperties extends Gst.Element.ReadableProperties, Gst.Preset.ReadableProperties {
                "hard-resync": boolean
                "mark-granule": boolean
                "perfect-timestamp": boolean
                "tolerance": number
            }

            interface WritableProperties extends Gst.Element.WritableProperties, Gst.Preset.WritableProperties {
                "hard-resync": boolean
                "mark-granule": boolean
                "perfect-timestamp": boolean
                "tolerance": number
            }

            interface ConstructOnlyProperties extends Gst.Element.ConstructOnlyProperties, Gst.Preset.ConstructOnlyProperties {
            }
        }

        /**
         * This base class is for audio encoders turning raw audio samples into
         * encoded audio data.
         *
         * GstAudioEncoder and subclass should cooperate as follows.
         *
         * ## Configuration
         *
         *   * Initially, GstAudioEncoder calls @start when the encoder element
         *     is activated, which allows subclass to perform any global setup.
         *
         *   * GstAudioEncoder calls @set_format to inform subclass of the format
         *     of input audio data that it is about to receive.  Subclass should
         *     setup for encoding and configure various base class parameters
         *     appropriately, notably those directing desired input data handling.
         *     While unlikely, it might be called more than once, if changing input
         *     parameters require reconfiguration.
         *
         *   * GstAudioEncoder calls @stop at end of all processing.
         *
         * As of configuration stage, and throughout processing, GstAudioEncoder
         * maintains various parameters that provide required context,
         * e.g. describing the format of input audio data.
         * Conversely, subclass can and should configure these context parameters
         * to inform base class of its expectation w.r.t. buffer handling.
         *
         * ## Data processing
         *
         *     * Base class gathers input sample data (as directed by the context's
         *       frame_samples and frame_max) and provides this to subclass' @handle_frame.
         *     * If codec processing results in encoded data, subclass should call
         *       gst_audio_encoder_finish_frame() to have encoded data pushed
         *       downstream. Alternatively, it might also call
         *       gst_audio_encoder_finish_frame() (with a NULL buffer and some number of
         *       dropped samples) to indicate dropped (non-encoded) samples.
         *     * Just prior to actually pushing a buffer downstream,
         *       it is passed to @pre_push.
         *     * During the parsing process GstAudioEncoderClass will handle both
         *       srcpad and sinkpad events. Sink events will be passed to subclass
         *       if @event callback has been provided.
         *
         * ## Shutdown phase
         *
         *   * GstAudioEncoder class calls @stop to inform the subclass that data
         *     parsing will be stopped.
         *
         * Subclass is responsible for providing pad template caps for
         * source and sink pads. The pads need to be named "sink" and "src". It also
         * needs to set the fixed caps on srcpad, when the format is ensured.  This
         * is typically when base class calls subclass' @set_format function, though
         * it might be delayed until calling @gst_audio_encoder_finish_frame.
         *
         * In summary, above process should have subclass concentrating on
         * codec data processing while leaving other matters to base class,
         * such as most notably timestamp handling.  While it may exert more control
         * in this area (see e.g. @pre_push), it is very much not recommended.
         *
         * In particular, base class will either favor tracking upstream timestamps
         * (at the possible expense of jitter) or aim to arrange for a perfect stream of
         * output timestamps, depending on #GstAudioEncoder:perfect-timestamp.
         * However, in the latter case, the input may not be so perfect or ideal, which
         * is handled as follows.  An input timestamp is compared with the expected
         * timestamp as dictated by input sample stream and if the deviation is less
         * than #GstAudioEncoder:tolerance, the deviation is discarded.
         * Otherwise, it is considered a discontuinity and subsequent output timestamp
         * is resynced to the new position after performing configured discontinuity
         * processing.  In the non-perfect-timestamp case, an upstream variation
         * exceeding tolerance only leads to marking DISCONT on subsequent outgoing
         * (while timestamps are adjusted to upstream regardless of variation).
         * While DISCONT is also marked in the perfect-timestamp case, this one
         * optionally (see #GstAudioEncoder:hard-resync)
         * performs some additional steps, such as clipping of (early) input samples
         * or draining all currently remaining input data, depending on the direction
         * of the discontuinity.
         *
         * If perfect timestamps are arranged, it is also possible to request baseclass
         * (usually set by subclass) to provide additional buffer metadata (in OFFSET
         * and OFFSET_END) fields according to granule defined semantics currently
         * needed by oggmux.  Specifically, OFFSET is set to granulepos (= sample count
         * including buffer) and OFFSET_END to corresponding timestamp (as determined
         * by same sample count and sample rate).
         *
         * Things that subclass need to take care of:
         *
         *   * Provide pad templates
         *   * Set source pad caps when appropriate
         *   * Inform base class of buffer processing needs using context's
         *      frame_samples and frame_bytes.
         *   * Set user-configurable properties to sane defaults for format and
         *      implementing codec at hand, e.g. those controlling timestamp behaviour
         *      and discontinuity processing.
         *   * Accept data in @handle_frame and provide encoded results to
         *      gst_audio_encoder_finish_frame().
         */
        interface AudioEncoder extends Gst.Element, Gst.Preset {
            readonly $signals: AudioEncoder.SignalSignatures
            readonly $readableProperties: AudioEncoder.ReadableProperties
            readonly $writableProperties: AudioEncoder.WritableProperties
            readonly $constructOnlyProperties: AudioEncoder.ConstructOnlyProperties
            /**
             * @default FALSE
             */
            get hardResync(): boolean
            set hardResync(value: boolean)
            /**
             * @default FALSE
             */
            get markGranule(): boolean
            set markGranule(value: boolean)
            /**
             * @default FALSE
             */
            get perfectTimestamp(): boolean
            set perfectTimestamp(value: boolean)
            /**
             * @default 40000000
             */
            get tolerance(): number
            set tolerance(value: number)
            /**
             * Helper function that allocates a buffer to hold an encoded audio frame
             * for @enc's current output format.
             * @param size size of the buffer
             * @returns allocated buffer
             */
            allocate_output_buffer(size: number): Gst.Buffer
            /**
             *  0, then best estimate is all samples provided to encoder
             * (subclass) so far.  @buf may be NULL, in which case next number of @samples
             * are considered discarded, e.g. as a result of discontinuous transmission,
             * and a discontinuity is marked.
             *
             * Note that samples received in #GstAudioEncoderClass.handle_frame()
             * may be invalidated by a call to this function.
             * @param buffer encoded data
             * @param samples number of samples (per channel) represented by encoded data
             * @returns a #GstFlowReturn that should be escalated to caller (of caller)
             */
            finish_frame(buffer: Gst.Buffer | null, samples: number): Gst.FlowReturn
            /**
             * Lets #GstAudioEncoder sub-classes to know the memory @allocator
             * used by the base class and its @params.
             *
             * Unref the @allocator after use it.
             * @returns , the #GstAllocator used, the #GstAllocationParams of `allocator`
             */
            get_allocator(): void
            /**
             * @returns a #GstAudioInfo describing the input audio format
             */
            get_audio_info(): AudioInfo
            /**
             * Queries encoder drain handling.
             * @returns TRUE if drainable handling is enabled.  MT safe.
             */
            get_drainable(): boolean
            /**
             * @returns currently configured maximum handled frames
             */
            get_frame_max(): number
            /**
             * @returns currently maximum requested samples per frame
             */
            get_frame_samples_max(): number
            /**
             * @returns currently minimum requested samples per frame
             */
            get_frame_samples_min(): number
            /**
             * Queries encoder hard minimum handling.
             * @returns TRUE if hard minimum handling is enabled.  MT safe.
             */
            get_hard_min(): boolean
            /**
             */
            get_hard_resync(): boolean
            /**
             * Sets the variables pointed to by @min and @max to the currently configured
             * latency.
             * @returns , a pointer to storage to hold minimum latency, a pointer to storage to hold maximum latency
             */
            get_latency(): void
            /**
             * @returns currently configured encoder lookahead
             */
            get_lookahead(): number
            /**
             * Queries if the encoder will handle granule marking.
             * @returns TRUE if granule marking is enabled.  MT safe.
             */
            get_mark_granule(): boolean
            /**
             * Queries encoder perfect timestamp behaviour.
             * @returns TRUE if perfect timestamp setting enabled.  MT safe.
             */
            get_perfect_timestamp(): boolean
            /**
             * Queries current audio jitter tolerance threshold.
             * @returns encoder audio jitter tolerance threshold.  MT safe.
             */
            get_tolerance(): Gst.ClockTime
            /**
             * Sets the audio encoder tags and how they should be merged with any
             * upstream stream tags. This will override any tags previously-set
             * with gst_audio_encoder_merge_tags().
             *
             * Note that this is provided for convenience, and the subclass is
             * not required to use this and can still do tag handling on its own.
             *
             * MT safe.
             * @param tags a #GstTagList to merge, or NULL to unset
                previously-set tags
             * @param mode the #GstTagMergeMode to use, usually #GST_TAG_MERGE_REPLACE
             */
            merge_tags(tags: Gst.TagList | null, mode: Gst.TagMergeMode): void
            /**
             * Negotiate with downstream elements to currently configured #GstCaps.
             * Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
             * negotiate fails.
             * @returns %TRUE if the negotiation succeeded, else %FALSE.
             */
            negotiate(): boolean
            /**
             * Returns caps that express @caps (or sink template caps if @caps == NULL)
             * restricted to channel/rate combinations supported by downstream elements
             * (e.g. muxers).
             * @param caps initial caps
             * @param filter filter caps
             * @returns a #GstCaps owned by caller
             */
            proxy_getcaps(caps: Gst.Caps | null, filter: Gst.Caps | null): Gst.Caps
            /**
             * Sets a caps in allocation query which are different from the set
             * pad's caps. Use this function before calling
             * gst_audio_encoder_negotiate(). Setting to %NULL the allocation
             * query will use the caps from the pad.
             * @since 1.10
             * @param allocation_caps a #GstCaps or %NULL
             */
            set_allocation_caps(allocation_caps: Gst.Caps | null): void
            /**
             * Configures encoder drain handling.  If drainable, subclass might
             * be handed a NULL buffer to have it return any leftover encoded data.
             * Otherwise, it is not considered so capable and will only ever be passed
             * real data.
             *
             * MT safe.
             * @param enabled new state
             */
            set_drainable(enabled: boolean): void
            /**
             * Sets max number of frames accepted at once (assumed minimally 1).
             * Requires @frame_samples_min and @frame_samples_max to be the equal.
             *
             * Note: This value will be reset to 0 every time before
             * #GstAudioEncoderClass.set_format() is called.
             * @param num number of frames
             */
            set_frame_max(num: number): void
            /**
             * Sets number of samples (per channel) subclass needs to be handed,
             * at most or will be handed all available if 0.
             *
             * If an exact number of samples is required, gst_audio_encoder_set_frame_samples_min()
             * must be called with the same number.
             *
             * Note: This value will be reset to 0 every time before
             * #GstAudioEncoderClass.set_format() is called.
             * @param num number of samples per frame
             */
            set_frame_samples_max(num: number): void
            /**
             * Sets number of samples (per channel) subclass needs to be handed,
             * at least or will be handed all available if 0.
             *
             * If an exact number of samples is required, gst_audio_encoder_set_frame_samples_max()
             * must be called with the same number.
             *
             * Note: This value will be reset to 0 every time before
             * #GstAudioEncoderClass.set_format() is called.
             * @param num number of samples per frame
             */
            set_frame_samples_min(num: number): void
            /**
             * Configures encoder hard minimum handling.  If enabled, subclass
             * will never be handed less samples than it configured, which otherwise
             * might occur near end-of-data handling.  Instead, the leftover samples
             * will simply be discarded.
             *
             * MT safe.
             * @param enabled new state
             */
            set_hard_min(enabled: boolean): void
            /**
             * @param enabled
             */
            set_hard_resync(enabled: boolean): void
            /**
             * Set the codec headers to be sent downstream whenever requested.
             * @param headers a list of
              #GstBuffer containing the codec header
             */
            set_headers(headers: Gst.Buffer[]): void
            /**
             * Sets encoder latency. If the provided values changed from
             * previously provided ones, this will also post a LATENCY message on the bus
             * so the pipeline can reconfigure its global latency.
             * @param min minimum latency
             * @param max maximum latency
             */
            set_latency(min: Gst.ClockTime, max: Gst.ClockTime): void
            /**
             * Sets encoder lookahead (in units of input rate samples)
             *
             * Note: This value will be reset to 0 every time before
             * #GstAudioEncoderClass.set_format() is called.
             * @param num lookahead
             */
            set_lookahead(num: number): void
            /**
             * Enable or disable encoder granule handling.
             *
             * MT safe.
             * @param enabled new state
             */
            set_mark_granule(enabled: boolean): void
            /**
             * Configure output caps on the srcpad of @enc.
             * @param caps #GstCaps
             * @returns %TRUE on success.
             */
            set_output_format(caps: Gst.Caps): boolean
            /**
             * Enable or disable encoder perfect output timestamp preference.
             *
             * MT safe.
             * @param enabled new state
             */
            set_perfect_timestamp(enabled: boolean): void
            /**
             * Configures encoder audio jitter tolerance threshold.
             *
             * MT safe.
             * @param tolerance new tolerance
             */
            set_tolerance(tolerance: Gst.ClockTime): void
            /**
             * Optional.
             *                  Called when the element changes to GST_STATE_NULL.
             *                  Allows closing external resources.
             */
            vfunc_close(): boolean
            /**
             * Optional.
             *                     Setup the allocation parameters for allocating output
             *                     buffers. The passed in query contains the result of the
             *                     downstream allocation query.
             *                     Subclasses should chain up to the parent implementation to
             *                     invoke the default handler.
             * @param query
             */
            vfunc_decide_allocation(query: Gst.Query): boolean
            /**
             * Optional.
             *                  Instructs subclass to clear any codec caches and discard
             *                  any pending samples and not yet returned encoded data.
             */
            vfunc_flush(): void
            /**
             * Optional.
             *                  Allows for a custom sink getcaps implementation (e.g.
             *                  for multichannel input specification).  If not implemented,
             *                  default returns gst_audio_encoder_proxy_getcaps
             *                  applied to sink template caps.
             * @param filter
             */
            vfunc_getcaps(filter: Gst.Caps): Gst.Caps
            /**
             * Provides input samples (or NULL to clear any remaining data)
             *                  according to directions as configured by the subclass
             *                  using the API.  Input data ref management is performed
             *                  by base class, subclass should not care or intervene,
             *                  and input data is only valid until next call to base class,
             *                  most notably a call to gst_audio_encoder_finish_frame().
             * @param buffer
             */
            vfunc_handle_frame(buffer: Gst.Buffer): Gst.FlowReturn
            /**
             * Negotiate with downstream elements to currently configured #GstCaps.
             * Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
             * negotiate fails.
             * @returns %TRUE if the negotiation succeeded, else %FALSE.
             */
            vfunc_negotiate(): boolean
            /**
             * Optional.
             *                  Called when the element changes to GST_STATE_READY.
             *                  Allows opening external resources.
             */
            vfunc_open(): boolean
            /**
             * Optional.
             *                  Called just prior to pushing (encoded data) buffer downstream.
             *                  Subclass has full discretionary access to buffer,
             *                  and a not OK flow return will abort downstream pushing.
             * @param buffer
             */
            vfunc_pre_push(buffer: Gst.Buffer): Gst.FlowReturn
            /**
             * Optional.
             *                      Propose buffer allocation parameters for upstream elements.
             *                      Subclasses should chain up to the parent implementation to
             *                      invoke the default handler.
             * @param query
             */
            vfunc_propose_allocation(query: Gst.Query): boolean
            /**
             * Notifies subclass of incoming data format.
             *                  GstAudioInfo contains the format according to provided caps.
             * @param info
             */
            vfunc_set_format(info: AudioInfo): boolean
            /**
             * Optional.
             *                  Event handler on the sink pad. Subclasses should chain up to
             *                  the parent implementation to invoke the default handler.
             * @param event
             */
            vfunc_sink_event(event: Gst.Event): boolean
            /**
             * Optional.
             *                  Query handler on the sink pad. This function should
             *                  return TRUE if the query could be performed. Subclasses
             *                  should chain up to the parent implementation to invoke the
             *                  default handler. Since: 1.6
             * @param query
             */
            vfunc_sink_query(query: Gst.Query): boolean
            /**
             * Optional.
             *                  Event handler on the src pad. Subclasses should chain up to
             *                  the parent implementation to invoke the default handler.
             * @param event
             */
            vfunc_src_event(event: Gst.Event): boolean
            /**
             * Optional.
             *                  Query handler on the source pad. This function should
             *                  return TRUE if the query could be performed. Subclasses
             *                  should chain up to the parent implementation to invoke the
             *                  default handler. Since: 1.6
             * @param query
             */
            vfunc_src_query(query: Gst.Query): boolean
            /**
             * Optional.
             *                  Called when the element starts processing.
             *                  Allows opening external resources.
             */
            vfunc_start(): boolean
            /**
             * Optional.
             *                  Called when the element stops processing.
             *                  Allows closing external resources.
             */
            vfunc_stop(): boolean
            /**
             * Optional. Transform the metadata on the input buffer to the
             *                  output buffer. By default this method copies all meta without
             *                  tags and meta with only the "audio" tag. subclasses can
             *                  implement this method and return %TRUE if the metadata is to be
             *                  copied. Since: 1.6
             * @param outbuf
             * @param meta
             * @param inbuf
             */
            vfunc_transform_meta(outbuf: Gst.Buffer, meta: Gst.Meta, inbuf: Gst.Buffer): boolean
        }

        interface AudioEncoderClass extends Omit<Gst.ElementClass, "new"> {
            readonly $gtype: GObject.GType<AudioEncoder>
            readonly prototype: AudioEncoder
            new (props?: Partial<GObject.ConstructorProps<AudioEncoder>>): AudioEncoder
        }

        const AudioEncoder: AudioEncoderClass
        

        namespace AudioFilter {
            interface SignalSignatures extends GstBase.BaseTransform.SignalSignatures {
            }

            interface ReadableProperties extends GstBase.BaseTransform.ReadableProperties {
            }

            interface WritableProperties extends GstBase.BaseTransform.WritableProperties {
            }

            interface ConstructOnlyProperties extends GstBase.BaseTransform.ConstructOnlyProperties {
            }
        }

        /**
         * -derived base class for simple audio
         * filters, ie. those that output the same format that they get as input.
         *
         * #GstAudioFilter will parse the input format for you (with error checking)
         * before calling your setup function. Also, elements deriving from
         * #GstAudioFilter may use gst_audio_filter_class_add_pad_templates() from
         * their class_init function to easily configure the set of caps/formats that
         * the element is able to handle.
         *
         * Derived classes should override the #GstAudioFilterClass.setup() and
         * #GstBaseTransformClass.transform_ip() and/or
         * #GstBaseTransformClass.transform()
         * virtual functions in their class_init function.
         */
        interface AudioFilter extends GstBase.BaseTransform {
            readonly $signals: AudioFilter.SignalSignatures
            readonly $readableProperties: AudioFilter.ReadableProperties
            readonly $writableProperties: AudioFilter.WritableProperties
            readonly $constructOnlyProperties: AudioFilter.ConstructOnlyProperties
            /**
             * virtual function called whenever the format changes
             * @param info
             */
            vfunc_setup(info: AudioInfo): boolean
        }

        interface AudioFilterClass extends Omit<GstBase.BaseTransformClass, "new"> {
            readonly $gtype: GObject.GType<AudioFilter>
            readonly prototype: AudioFilter
            new (props?: Partial<GObject.ConstructorProps<AudioFilter>>): AudioFilter
            /**
             * Convenience function to add pad templates to this element class, with
             * @allowed_caps as the caps that can be handled.
             *
             * This function is usually used from within a GObject class_init function.
             * @param allowed_caps what formats the filter can handle, as #GstCaps
             */
            add_pad_templates(allowed_caps: Gst.Caps): void
        }

        const AudioFilter: AudioFilterClass
        

        namespace AudioRingBuffer {
            interface SignalSignatures extends Gst.Object.SignalSignatures {
            }

            interface ReadableProperties extends Gst.Object.ReadableProperties {
            }

            interface WritableProperties extends Gst.Object.WritableProperties {
            }

            interface ConstructOnlyProperties extends Gst.Object.ConstructOnlyProperties {
            }
        }

        /**
         * This object is the base class for audio ringbuffers used by the base
         * audio source and sink classes.
         *
         * The ringbuffer abstracts a circular buffer of data. One reader and
         * one writer can operate on the data from different threads in a lockfree
         * manner. The base class is sufficiently flexible to be used as an
         * abstraction for DMA based ringbuffers as well as a pure software
         * implementations.
         */
        interface AudioRingBuffer extends Gst.Object {
            readonly $signals: AudioRingBuffer.SignalSignatures
            readonly $readableProperties: AudioRingBuffer.ReadableProperties
            readonly $writableProperties: AudioRingBuffer.WritableProperties
            readonly $constructOnlyProperties: AudioRingBuffer.ConstructOnlyProperties
            /**
             * Allocate the resources for the ringbuffer. This function fills
             * in the data pointer of the ring buffer with a valid #GstBuffer
             * to which samples can be written.
             * @param spec the specs of the buffer
             * @returns TRUE if the device could be acquired, FALSE on error.  MT safe.
             */
            acquire(spec: AudioRingBufferSpec): boolean
            /**
             * Activate @buf to start or stop pulling data.
             *
             * MT safe.
             * @param active the new mode
             * @returns TRUE if the device could be activated in the requested mode, FALSE on error.
             */
            activate(active: boolean): boolean
            /**
             * Subclasses should call this function to notify the fact that
             * @advance segments are now processed by the device.
             *
             * MT safe.
             * @param advance the number of segments written
             */
            advance(advance: number): void
            /**
             * Clear the given segment of the buffer with silence samples.
             * This function is used by subclasses.
             *
             * MT safe.
             * @param segment the segment to clear
             */
            clear(segment: number): void
            /**
             * Clear all samples from the ringbuffer.
             *
             * MT safe.
             */
            clear_all(): void
            /**
             * Close the audio device associated with the ring buffer. The ring buffer
             * should already have been released via gst_audio_ring_buffer_release().
             * @returns TRUE if the device could be closed, FALSE on error.  MT safe.
             */
            close_device(): boolean
            /**
             * Commit @in_samples samples pointed to by @data to the ringbuffer @buf.
             *
             * @in_samples and @out_samples define the rate conversion to perform on the
             * samples in @data. For negative rates, @out_samples must be negative and
             * @in_samples positive.
             *
             * When @out_samples is positive, the first sample will be written at position @sample
             * in the ringbuffer. When @out_samples is negative, the last sample will be written to
             * @sample in reverse order.
             *
             * @out_samples does not need to be a multiple of the segment size of the ringbuffer
             * although it is recommended for optimal performance.
             *
             * @accum will hold a temporary accumulator used in rate conversion and should be
             * set to 0 when this function is first called. In case the commit operation is
             * interrupted, one can resume the processing by passing the previously returned
             * @accum value back to this function.
             *
             * MT safe.
             * @param data the data to commit
             * @param out_samples the number of samples to write to the ringbuffer
             * @returns The number of samples written to the ringbuffer or -1 on error. The number of samples written can be less than `out_samples` when `buf` was interrupted with a flush or stop., the sample position of the data, accumulator for rate conversion.
             */
            commit(data: Uint8Array, out_samples: number): [number, number, number]
            /**
             * Convert @src_val in @src_fmt to the equivalent value in @dest_fmt. The result
             * will be put in @dest_val.
             * @param src_fmt the source format
             * @param src_val the source value
             * @param dest_fmt the destination format
             * @returns TRUE if the conversion succeeded., a location to store the converted value
             */
            convert(src_fmt: Gst.Format, src_val: number, dest_fmt: Gst.Format): [boolean, number]
            /**
             * Get the number of samples queued in the audio device. This is
             * usually less than the segment size but can be bigger when the
             * implementation uses another internal buffer between the audio
             * device.
             *
             * For playback ringbuffers this is the amount of samples transferred from the
             * ringbuffer to the device but still not played.
             *
             * For capture ringbuffers this is the amount of samples in the device that are
             * not yet transferred to the ringbuffer.
             * @returns The number of samples queued in the audio device.  MT safe.
             */
            delay(): number
            /**
             * Checks the status of the device associated with the ring buffer.
             * @returns TRUE if the device was open, FALSE if it was closed.  MT safe.
             */
            device_is_open(): boolean
            /**
             * Gets the current segment base number of the ringbuffer.
             *
             * MT safe.
             * @since 1.26
             * @returns Current segment base number of the ringbuffer.
             */
            get_segbase(): number
            /**
             * Gets the current segment number of the ringbuffer.
             *
             * MT safe.
             * @since 1.26
             * @returns Current segment number of the ringbuffer.
             */
            get_segdone(): number
            /**
             * Check if the ringbuffer is acquired and ready to use.
             * @returns TRUE if the ringbuffer is acquired, FALSE on error.  MT safe.
             */
            is_acquired(): boolean
            /**
             * Check if @buf is activated.
             *
             * MT safe.
             * @returns TRUE if the device is active.
             */
            is_active(): boolean
            /**
             * Check if @buf is flushing.
             *
             * MT safe.
             * @returns TRUE if the device is flushing.
             */
            is_flushing(): boolean
            /**
             * Tell the ringbuffer that it is allowed to start playback when
             * the ringbuffer is filled with samples.
             *
             * MT safe.
             * @param allowed the new value
             */
            may_start(allowed: boolean): void
            /**
             * Open the audio device associated with the ring buffer. Does not perform any
             * setup on the device. You must open the device before acquiring the ring
             * buffer.
             * @returns TRUE if the device could be opened, FALSE on error.  MT safe.
             */
            open_device(): boolean
            /**
             * Pause processing samples from the ringbuffer.
             * @returns TRUE if the device could be paused, FALSE on error.  MT safe.
             */
            pause(): boolean
            /**
             * Returns a pointer to memory where the data from segment @segment
             * can be found. This function is mostly used by subclasses.
             * @returns FALSE if the buffer is not started.  MT safe., the segment to read,      the pointer to the memory where samples can be read
             */
            prepare_read(): [boolean, number, Uint8Array]
            /**
             * Read @len samples from the ringbuffer into the memory pointed
             * to by @data.
             * The first sample should be read from position @sample in
             * the ringbuffer.
             *
             * @len should not be a multiple of the segment size of the ringbuffer
             * although it is recommended.
             *
             * @timestamp will return the timestamp associated with the data returned.
             * @param sample the sample position of the data
             * @param data where the data should be read
             * @returns The number of samples read from the ringbuffer or -1 on error.  MT safe., where the timestamp is returned
             */
            read(sample: number, data: Uint8Array): [number, Gst.ClockTime]
            /**
             * Free the resources of the ringbuffer.
             * @returns TRUE if the device could be released, FALSE on error.  MT safe.
             */
            release(): boolean
            /**
             * Get the number of samples that were processed by the ringbuffer
             * since it was last started. This does not include the number of samples not
             * yet processed (see gst_audio_ring_buffer_delay()).
             * @returns The number of samples processed by the ringbuffer.  MT safe.
             */
            samples_done(): number
            /**
             * Sets the given callback function on the buffer. This function
             * will be called every time a segment has been written to a device.
             *
             * MT safe.
             * @since 1.12
             * @param cb the callback to set
             */
            set_callback(cb: AudioRingBufferCallback | null): void
            /**
             * Tell the ringbuffer about the device's channel positions. This must
             * be called in when the ringbuffer is acquired.
             * @param position the device channel positions
             */
            set_channel_positions(position: AudioChannelPosition[]): void
            /**
             * Mark the ringbuffer as errored after it has started.
             *
             * MT safe.
             * @since 1.24
             */
            set_errored(): void
            /**
             * Set the ringbuffer to flushing mode or normal mode.
             *
             * MT safe.
             * @param flushing the new mode
             */
            set_flushing(flushing: boolean): void
            /**
             * Make sure that the next sample written to the device is
             * accounted for as being the @sample sample written to the
             * device. This value will be used in reporting the current
             * sample position of the ringbuffer.
             *
             * This function will also clear the buffer with silence.
             *
             * MT safe.
             * @param sample the sample number to set
             */
            set_sample(sample: number): void
            /**
             * Sets the current segment number of the ringbuffer.
             *
             * MT safe.
             * @since 1.26
             * @param segdone the segment number to set
             */
            set_segdone(segdone: number): void
            /**
             * @param readseg
             * @param timestamp
             */
            set_timestamp(readseg: number, timestamp: Gst.ClockTime): void
            /**
             * Start processing samples from the ringbuffer.
             * @returns TRUE if the device could be started, FALSE on error.  MT safe.
             */
            start(): boolean
            /**
             * Stop processing samples from the ringbuffer.
             * @returns TRUE if the device could be stopped, FALSE on error.  MT safe.
             */
            stop(): boolean
            /**
             * Allocate the resources for the ringbuffer. This function fills
             * in the data pointer of the ring buffer with a valid #GstBuffer
             * to which samples can be written.
             * @param spec the specs of the buffer
             * @returns TRUE if the device could be acquired, FALSE on error.  MT safe.
             */
            vfunc_acquire(spec: AudioRingBufferSpec): boolean
            /**
             * Activate @buf to start or stop pulling data.
             *
             * MT safe.
             * @param active the new mode
             * @returns TRUE if the device could be activated in the requested mode, FALSE on error.
             */
            vfunc_activate(active: boolean): boolean
            /**
             * Clear all samples from the ringbuffer.
             *
             * MT safe.
             */
            vfunc_clear_all(): void
            /**
             * Close the audio device associated with the ring buffer. The ring buffer
             * should already have been released via gst_audio_ring_buffer_release().
             * @returns TRUE if the device could be closed, FALSE on error.  MT safe.
             */
            vfunc_close_device(): boolean
            /**
             * Commit @in_samples samples pointed to by @data to the ringbuffer @buf.
             *
             * @in_samples and @out_samples define the rate conversion to perform on the
             * samples in @data. For negative rates, @out_samples must be negative and
             * @in_samples positive.
             *
             * When @out_samples is positive, the first sample will be written at position @sample
             * in the ringbuffer. When @out_samples is negative, the last sample will be written to
             * @sample in reverse order.
             *
             * @out_samples does not need to be a multiple of the segment size of the ringbuffer
             * although it is recommended for optimal performance.
             *
             * @accum will hold a temporary accumulator used in rate conversion and should be
             * set to 0 when this function is first called. In case the commit operation is
             * interrupted, one can resume the processing by passing the previously returned
             * @accum value back to this function.
             *
             * MT safe.
             * @param data the data to commit
             * @param out_samples the number of samples to write to the ringbuffer
             * @returns The number of samples written to the ringbuffer or -1 on error. The number of samples written can be less than `out_samples` when `buf` was interrupted with a flush or stop., the sample position of the data, accumulator for rate conversion.
             */
            vfunc_commit(data: Uint8Array, out_samples: number): [number, number, number]
            /**
             * Get the number of samples queued in the audio device. This is
             * usually less than the segment size but can be bigger when the
             * implementation uses another internal buffer between the audio
             * device.
             *
             * For playback ringbuffers this is the amount of samples transferred from the
             * ringbuffer to the device but still not played.
             *
             * For capture ringbuffers this is the amount of samples in the device that are
             * not yet transferred to the ringbuffer.
             * @returns The number of samples queued in the audio device.  MT safe.
             */
            vfunc_delay(): number
            /**
             * Open the audio device associated with the ring buffer. Does not perform any
             * setup on the device. You must open the device before acquiring the ring
             * buffer.
             * @returns TRUE if the device could be opened, FALSE on error.  MT safe.
             */
            vfunc_open_device(): boolean
            /**
             * Pause processing samples from the ringbuffer.
             * @returns TRUE if the device could be paused, FALSE on error.  MT safe.
             */
            vfunc_pause(): boolean
            /**
             * Free the resources of the ringbuffer.
             * @returns TRUE if the device could be released, FALSE on error.  MT safe.
             */
            vfunc_release(): boolean
            /**
             * resume processing of samples after pause
             */
            vfunc_resume(): boolean
            /**
             * Start processing samples from the ringbuffer.
             * @returns TRUE if the device could be started, FALSE on error.  MT safe.
             */
            vfunc_start(): boolean
            /**
             * Stop processing samples from the ringbuffer.
             * @returns TRUE if the device could be stopped, FALSE on error.  MT safe.
             */
            vfunc_stop(): boolean
        }

        interface AudioRingBufferClass extends Omit<Gst.ObjectClass, "new"> {
            readonly $gtype: GObject.GType<AudioRingBuffer>
            readonly prototype: AudioRingBuffer
            new (props?: Partial<GObject.ConstructorProps<AudioRingBuffer>>): AudioRingBuffer
            /**
             * Print debug info about the buffer sized in @spec to the debug log.
             * @param spec the spec to debug
             */
            debug_spec_buff(spec: AudioRingBufferSpec): void
            /**
             * Print debug info about the parsed caps in @spec to the debug log.
             * @param spec the spec to debug
             */
            debug_spec_caps(spec: AudioRingBufferSpec): void
            /**
             * Parse @caps into @spec.
             * @param spec a spec
             * @param caps a #GstCaps
             * @returns TRUE if the caps could be parsed.
             */
            parse_caps(spec: AudioRingBufferSpec, caps: Gst.Caps): boolean
        }

        const AudioRingBuffer: AudioRingBufferClass
        

        namespace AudioSink {
            interface SignalSignatures extends AudioBaseSink.SignalSignatures {
            }

            interface ReadableProperties extends AudioBaseSink.ReadableProperties {
            }

            interface WritableProperties extends AudioBaseSink.WritableProperties {
            }

            interface ConstructOnlyProperties extends AudioBaseSink.ConstructOnlyProperties {
            }
        }

        /**
         * This is the most simple base class for audio sinks that only requires
         * subclasses to implement a set of simple functions:
         *
         * * `open()` :Open the device.
         *
         * * `prepare()` :Configure the device with the specified format.
         *
         * * `write()` :Write samples to the device.
         *
         * * `reset()` :Unblock writes and flush the device.
         *
         * * `delay()` :Get the number of samples written but not yet played
         * by the device.
         *
         * * `unprepare()` :Undo operations done by prepare.
         *
         * * `close()` :Close the device.
         *
         * All scheduling of samples and timestamps is done in this base class
         * together with #GstAudioBaseSink using a default implementation of a
         * #GstAudioRingBuffer that uses threads.
         */
        interface AudioSink extends AudioBaseSink {
            readonly $signals: AudioSink.SignalSignatures
            readonly $readableProperties: AudioSink.ReadableProperties
            readonly $writableProperties: AudioSink.WritableProperties
            readonly $constructOnlyProperties: AudioSink.ConstructOnlyProperties
            /**
             * Close the device.
             */
            vfunc_close(): boolean
            /**
             * Return how many frames are still in the device. Participates in
             *         computing the time for audio clocks and drives the synchronisation.
             */
            vfunc_delay(): number
            /**
             * Open the device. No configuration needs to be done at this point.
             *        This function is also used to check if the device is available.
             */
            vfunc_open(): boolean
            /**
             * Pause the device and unblock write as fast as possible.
             *         For retro compatibility, the audio sink will fallback
             *         to calling reset if this vmethod is not provided. Since: 1.18
             */
            vfunc_pause(): void
            /**
             * Prepare the device to operate with the specified parameters.
             * @param spec
             */
            vfunc_prepare(spec: AudioRingBufferSpec): boolean
            /**
             * Returns as quickly as possible from a write and flush any pending
             *         samples from the device.
             *         This vmethod is deprecated. Please provide pause and stop instead.
             */
            vfunc_reset(): void
            /**
             * Resume the device. Since: 1.18
             */
            vfunc_resume(): void
            /**
             * Stop the device and unblock write as fast as possible.
             *        Pending samples are flushed from the device.
             *        For retro compatibility, the audio sink will fallback
             *        to calling reset if this vmethod is not provided. Since: 1.18
             */
            vfunc_stop(): void
            /**
             * Undo operations done in prepare.
             */
            vfunc_unprepare(): boolean
            /**
             * Write samples to the device.
             * @param data the sample data
             */
            vfunc_write(data: Uint8Array): number
        }

        interface AudioSinkClass extends Omit<AudioBaseSinkClass, "new"> {
            readonly $gtype: GObject.GType<AudioSink>
            readonly prototype: AudioSink
            new (props?: Partial<GObject.ConstructorProps<AudioSink>>): AudioSink
        }

        const AudioSink: AudioSinkClass
        

        namespace AudioSrc {
            interface SignalSignatures extends AudioBaseSrc.SignalSignatures {
            }

            interface ReadableProperties extends AudioBaseSrc.ReadableProperties {
            }

            interface WritableProperties extends AudioBaseSrc.WritableProperties {
            }

            interface ConstructOnlyProperties extends AudioBaseSrc.ConstructOnlyProperties {
            }
        }

        /**
         * This is the most simple base class for audio sources that only requires
         * subclasses to implement a set of simple functions:
         *
         * * `open()` :Open the device.
         * * `prepare()` :Configure the device with the specified format.
         * * `read()` :Read samples from the device.
         * * `reset()` :Unblock reads and flush the device.
         * * `delay()` :Get the number of samples in the device but not yet read.
         * * `unprepare()` :Undo operations done by prepare.
         * * `close()` :Close the device.
         *
         * All scheduling of samples and timestamps is done in this base class
         * together with #GstAudioBaseSrc using a default implementation of a
         * #GstAudioRingBuffer that uses threads.
         */
        interface AudioSrc extends AudioBaseSrc {
            readonly $signals: AudioSrc.SignalSignatures
            readonly $readableProperties: AudioSrc.ReadableProperties
            readonly $writableProperties: AudioSrc.WritableProperties
            readonly $constructOnlyProperties: AudioSrc.ConstructOnlyProperties
            /**
             * close the device
             */
            vfunc_close(): boolean
            /**
             * the number of frames queued in the device
             */
            vfunc_delay(): number
            /**
             * open the device with the specified caps
             */
            vfunc_open(): boolean
            /**
             * configure device with format
             * @param spec
             */
            vfunc_prepare(spec: AudioRingBufferSpec): boolean
            /**
             * Read samples from the device.
             * @param data the sample data
             * @returns , a #GstClockTime
             */
            vfunc_read(data: Uint8Array): [number, Gst.ClockTime]
            /**
             * unblock a read to the device and reset.
             */
            vfunc_reset(): void
            /**
             * undo the configuration
             */
            vfunc_unprepare(): boolean
        }

        interface AudioSrcClass extends Omit<AudioBaseSrcClass, "new"> {
            readonly $gtype: GObject.GType<AudioSrc>
            readonly prototype: AudioSrc
            new (props?: Partial<GObject.ConstructorProps<AudioSrc>>): AudioSrc
        }

        const AudioSrc: AudioSrcClass
        none
        none
        /**
         */
        abstract class AudioAggregatorConvertPadPrivate {
            static readonly $gtype: GObject.GType<AudioAggregatorConvertPadPrivate>

            
        }
        none
        /**
         */
        abstract class AudioAggregatorPadPrivate {
            static readonly $gtype: GObject.GType<AudioAggregatorPadPrivate>

            
        }
        /**
         */
        abstract class AudioAggregatorPrivate {
            static readonly $gtype: GObject.GType<AudioAggregatorPrivate>

            
        }
        none
        /**
         */
        abstract class AudioBaseSinkPrivate {
            static readonly $gtype: GObject.GType<AudioBaseSinkPrivate>

            
        }
        none
        /**
         */
        abstract class AudioBaseSrcPrivate {
            static readonly $gtype: GObject.GType<AudioBaseSrcPrivate>

            
        }
        /**
         * A structure containing the result of an audio buffer map operation,
         * which is executed with gst_audio_buffer_map(). For non-interleaved (planar)
         * buffers, the beginning of each channel in the buffer has its own pointer in
         * the @planes array. For interleaved buffers, the @planes array only contains
         * one item, which is the pointer to the beginning of the buffer, and @n_planes
         * equals 1.
         *
         * The different channels in @planes are always in the GStreamer channel order.
         * @since 1.16
         */
        abstract class AudioBuffer {
            static readonly $gtype: GObject.GType<AudioBuffer>

            
            /**
             * Clip the buffer to the given %GstSegment.
             *
             * After calling this function the caller does not own a reference to
             * @buffer anymore.
             * @param buffer The buffer to clip.
             * @param segment Segment in %GST_FORMAT_TIME or %GST_FORMAT_DEFAULT to which
                      the buffer should be clipped.
             * @param rate sample rate.
             * @param bpf size of one audio frame in bytes. This is the size of one sample *
            number of channels.
             * @returns %NULL if the buffer is completely outside the configured segment, otherwise the clipped buffer is returned.  If the buffer has no timestamp, it is assumed to be inside the segment and is not clipped
             */
            static clip(buffer: Gst.Buffer, segment: Gst.Segment, rate: number, bpf: number): Gst.Buffer | null
            /**
             * Maps an audio @gstbuffer so that it can be read or written and stores the
             * result of the map operation in @buffer.
             *
             * This is especially useful when the @gstbuffer is in non-interleaved (planar)
             * layout, in which case this function will use the information in the
             * @gstbuffer's attached #GstAudioMeta in order to map each channel in a
             * separate "plane" in #GstAudioBuffer. If a #GstAudioMeta is not attached
             * on the @gstbuffer, then it must be in interleaved layout.
             *
             * If a #GstAudioMeta is attached, then the #GstAudioInfo on the meta is checked
             * against @info. Normally, they should be equal, but in case they are not,
             * a g_critical will be printed and the #GstAudioInfo from the meta will be
             * used.
             *
             * In non-interleaved buffers, it is possible to have each channel on a separate
             * #GstMemory. In this case, each memory will be mapped separately to avoid
             * copying their contents in a larger memory area. Do note though that it is
             * not supported to have a single channel spanning over two or more different
             * #GstMemory objects. Although the map operation will likely succeed in this
             * case, it will be highly sub-optimal and it is recommended to merge all the
             * memories in the buffer before calling this function.
             *
             * Note: The actual #GstBuffer is not ref'ed, but it is required to stay valid
             * as long as it's mapped.
             * @since 1.16
             * @param info the audio properties of the buffer
             * @param gstbuffer the #GstBuffer to be mapped
             * @param flags the access mode for the memory
             * @returns %TRUE if the map operation succeeded or %FALSE on failure, pointer to a #GstAudioBuffer
             */
            static map(info: AudioInfo, gstbuffer: Gst.Buffer, flags: Gst.MapFlags): [boolean, AudioBuffer]
            /**
             * Reorders @buffer from the channel positions @from to the channel
             * positions @to. @from and @to must contain the same number of
             * positions and the same positions, only in a different order.
             * @buffer must be writable.
             * @param buffer The buffer to reorder.
             * @param format The %GstAudioFormat of the buffer.
             * @param from The channel positions in the buffer.
             * @param to The channel positions to convert to.
             * @returns %TRUE if the reordering was possible.
             */
            static reorder_channels(buffer: Gst.Buffer, format: AudioFormat, from: AudioChannelPosition[], to: AudioChannelPosition[]): boolean
            /**
             * Truncate the buffer to finally have @samples number of samples, removing
             * the necessary amount of samples from the end and @trim number of samples
             * from the beginning.
             *
             * This function does not know the audio rate, therefore the caller is
             * responsible for re-setting the correct timestamp and duration to the
             * buffer. However, timestamp will be preserved if trim == 0, and duration
             * will also be preserved if there is no trimming to be done. Offset and
             * offset end will be preserved / updated.
             *
             * After calling this function the caller does not own a reference to
             * @buffer anymore.
             * @since 1.16
             * @param buffer The buffer to truncate.
             * @param bpf size of one audio frame in bytes. This is the size of one sample *
            number of channels.
             * @param trim the number of samples to remove from the beginning of the buffer
             * @param samples the final number of samples that should exist in this buffer or -1
            to use all the remaining samples if you are only removing samples from the
            beginning.
             * @returns the truncated buffer
             */
            static truncate(buffer: Gst.Buffer, bpf: number, trim: number, samples: number): Gst.Buffer
            /**
             * a #GstAudioInfo describing the audio properties of this buffer
             */
            info: AudioInfo
            /**
             * the size of the buffer in samples
             */
            n_samples: number
            /**
             * the number of planes available
             */
            n_planes: number
            /**
             * an array of @n_planes pointers pointing to the start of each
             *   plane in the mapped buffer
             */
            planes: never
            /**
             * the mapped buffer
             */
            buffer: Gst.Buffer
            /**
             * Unmaps an audio buffer that was previously mapped with
             * gst_audio_buffer_map().
             * @since 1.16
             */
            unmap(): void
        }
        none
        /**
         */
        abstract class AudioCdSrcPrivate {
            static readonly $gtype: GObject.GType<AudioCdSrcPrivate>

            
        }
        /**
         * CD track abstraction to communicate TOC entries to the base class.
         *
         * This structure is only for use by sub-classed in connection with
         * gst_audio_cd_src_add_track().
         *
         * Applications will be informed of the available tracks via a TOC message
         * on the pipeline's #GstBus instead.
         */
        abstract class AudioCdSrcTrack {
            static readonly $gtype: GObject.GType<AudioCdSrcTrack>

            
            /**
             * Whether this is an audio track
             */
            is_audio: boolean
            /**
             * Track number in TOC (usually starts from 1, but not always)
             */
            num: number
            /**
             * The first sector of this track (LBA)
             */
            start: number
            /**
             * The last sector of this track (LBA)
             */
            end: number
            /**
             * Track-specific tags (e.g. from cd-text information), or NULL
             */
            tags: Gst.TagList
        }
        /**
         */
        abstract class AudioChannelMixer {
            static readonly $gtype: GObject.GType<AudioChannelMixer>

            
            /**
             * Free memory allocated by @mix.
             */
            free(): void
            /**
             * Check if @mix is in passthrough.
             *
             * Only N x N mix identity matrices are considered passthrough,
             * this is determined by comparing the contents of the matrix
             * with 0.0 and 1.0.
             *
             * As this is floating point comparisons, if the values have been
             * generated, they should be rounded up or down by explicit
             * assignment of 0.0 or 1.0 to values within a user-defined
             * epsilon, this code doesn't make assumptions as to what may
             * constitute an appropriate epsilon.
             * @returns %TRUE is `mix` is passthrough.
             */
            is_passthrough(): boolean
            /**
             * In case the samples are interleaved, @in and @out must point to an
             * array with a single element pointing to a block of interleaved samples.
             *
             * If non-interleaved samples are used, @in and @out must point to an
             * array with pointers to memory blocks, one for each channel.
             *
             * Perform channel mixing on @in_data and write the result to @out_data.
             * @in_data and @out_data need to be in @format and @layout.
             * @param in input samples
             * @param out output samples
             * @param samples number of samples
             */
            samples(in_: never | null, out: never | null, samples: number): void
        }
        /**
         * Extra buffer metadata describing how much audio has to be clipped from
         * the start or end of a buffer. This is used for compressed formats, where
         * the first frame usually has some additional samples due to encoder and
         * decoder delays, and the last frame usually has some additional samples to
         * be able to fill the complete last frame.
         *
         * This is used to ensure that decoded data in the end has the same amount of
         * samples, and multiply decoded streams can be gaplessly concatenated.
         *
         * Note: If clipping of the start is done by adjusting the segment, this meta
         * has to be dropped from buffers as otherwise clipping could happen twice.
         * @since 1.8
         */
        abstract class AudioClippingMeta {
            static readonly $gtype: GObject.GType<AudioClippingMeta>

            
            /**
             */
            static get_info(): Gst.MetaInfo
            /**
             * parent #GstMeta
             */
            meta: Gst.Meta
            /**
             * GstFormat of @start and @stop, GST_FORMAT_DEFAULT is samples
             */
            format: Gst.Format
            /**
             * Amount of audio to clip from start of buffer
             */
            start: number
            /**
             * Amount of  to clip from end of buffer
             */
            end: number
        }
        none
        /**
         * This object is used to convert audio samples from one format to another.
         * The object can perform conversion of:
         *
         *  * audio format with optional dithering and noise shaping
         *
         *  * audio samplerate
         *
         *  * audio channels and channel layout
         * @since 1.8
         */
        abstract class AudioConverter {
            static readonly $gtype: GObject.GType<AudioConverter>

            
            /**
             * Create a new #GstAudioConverter that is able to convert between @in and @out
             * audio formats.
             *
             * @config contains extra configuration options, see `GST_AUDIO_CONVERTER_OPT_*`
             * parameters for details about the options and values.
             * @param flags extra #GstAudioConverterFlags
             * @param in_info a source #GstAudioInfo
             * @param out_info a destination #GstAudioInfo
             * @param config a #GstStructure with configuration options
             * @returns a #GstAudioConverter or %NULL if conversion is not possible.
             */
            static "new"(flags: AudioConverterFlags, in_info: AudioInfo, out_info: AudioInfo, config: Gst.Structure | null): AudioConverter | null
            /**
             * Convenience wrapper around gst_audio_converter_samples(), which will
             * perform allocation of the output buffer based on the result from
             * gst_audio_converter_get_out_frames().
             * @since 1.14
             * @param flags extra #GstAudioConverterFlags
             * @param in input data
             * @returns %TRUE is the conversion could be performed., a pointer where  the output data will be written
             */
            convert(flags: AudioConverterFlags, in_: Uint8Array): [boolean, Uint8Array]
            /**
             * Free a previously allocated @convert instance.
             */
            free(): void
            /**
             * Get the current configuration of @convert.
             * @returns    a #GstStructure that remains valid for as long as `convert` is valid   or until gst_audio_converter_update_config() is called., result input rate, result output rate
             */
            get_config(): Gst.Structure
            /**
             * Calculate how many input frames are currently needed by @convert to produce
             * @out_frames of output frames.
             * @param out_frames number of output frames
             * @returns the number of input frames
             */
            get_in_frames(out_frames: number): number
            /**
             * Get the maximum number of input frames that the converter would
             * need before producing output.
             * @returns the latency of `convert` as expressed in the number of frames.
             */
            get_max_latency(): number
            /**
             * Calculate how many output frames can be produced when @in_frames input
             * frames are given to @convert.
             * @param in_frames number of input frames
             * @returns the number of output frames
             */
            get_out_frames(in_frames: number): number
            /**
             * Returns whether the audio converter will operate in passthrough mode.
             * The return value would be typically input to gst_base_transform_set_passthrough()
             * @since 1.16
             * @returns %TRUE when no conversion will actually occur.
             */
            is_passthrough(): boolean
            /**
             * Reset @convert to the state it was when it was first created, clearing
             * any history it might currently have.
             */
            reset(): void
            /**
             * Perform the conversion with @in_frames in @in to @out_frames in @out
             * using @convert.
             *
             * In case the samples are interleaved, @in and @out must point to an
             * array with a single element pointing to a block of interleaved samples.
             *
             * If non-interleaved samples are used, @in and @out must point to an
             * array with pointers to memory blocks, one for each channel.
             *
             * @in may be %NULL, in which case @in_frames of silence samples are processed
             * by the converter.
             *
             * This function always produces @out_frames of output and consumes @in_frames of
             * input. Use gst_audio_converter_get_out_frames() and
             * gst_audio_converter_get_in_frames() to make sure @in_frames and @out_frames
             * are matching and @in and @out point to enough memory.
             * @param flags extra #GstAudioConverterFlags
             * @param in input frames
             * @param in_frames number of input frames
             * @param out output frames
             * @param out_frames number of output frames
             * @returns %TRUE is the conversion could be performed.
             */
            samples(flags: AudioConverterFlags, in_: never | null, in_frames: number, out: never | null, out_frames: number): boolean
            /**
             * Returns whether the audio converter can perform the conversion in-place.
             * The return value would be typically input to gst_base_transform_set_in_place()
             * @since 1.12
             * @returns %TRUE when the conversion can be done in place.
             */
            supports_inplace(): boolean
            /**
             * Set @in_rate, @out_rate and @config as extra configuration for @convert.
             *
             * @in_rate and @out_rate specify the new sample rates of input and output
             * formats. A value of 0 leaves the sample rate unchanged.
             *
             * @config can be %NULL, in which case, the current configuration is not
             * changed.
             *
             * If the parameters in @config can not be set exactly, this function returns
             * %FALSE and will try to update as much state as possible. The new state can
             * then be retrieved and refined with gst_audio_converter_get_config().
             *
             * Look at the `GST_AUDIO_CONVERTER_OPT_*` fields to check valid configuration
             * option and values.
             * @param in_rate input rate
             * @param out_rate output rate
             * @param config a #GstStructure or %NULL
             * @returns %TRUE when the new parameters could be set
             */
            update_config(in_rate: number, out_rate: number, config: Gst.Structure | null): boolean
        }
        none
        /**
         */
        abstract class AudioDecoderPrivate {
            static readonly $gtype: GObject.GType<AudioDecoderPrivate>

            
        }
        /**
         * Extra buffer metadata describing audio downmixing matrix. This metadata is
         * attached to audio buffers and contains a matrix to downmix the buffer number
         * of channels to @channels.
         *
         * @matrix is an two-dimensional array of @to_channels times @from_channels
         * coefficients, i.e. the i-th output channels is constructed by multiplicating
         * the input channels with the coefficients in @matrix[i] and taking the sum
         * of the results.
         */
        abstract class AudioDownmixMeta {
            static readonly $gtype: GObject.GType<AudioDownmixMeta>

            
            /**
             */
            static get_info(): Gst.MetaInfo
            /**
             * parent #GstMeta
             */
            meta: Gst.Meta
            /**
             * the channel positions of the source
             */
            from_position: AudioChannelPosition
            /**
             * the channel positions of the destination
             */
            to_position: AudioChannelPosition
            /**
             * the number of channels of the source
             */
            from_channels: number
            /**
             * the number of channels of the destination
             */
            to_channels: number
            /**
             * the matrix coefficients.
             */
            matrix: number
        }
        none
        /**
         */
        abstract class AudioEncoderPrivate {
            static readonly $gtype: GObject.GType<AudioEncoderPrivate>

            
        }
        none
        /**
         * Information for an audio format.
         */
        abstract class AudioFormatInfo {
            static readonly $gtype: GObject.GType<AudioFormatInfo>

            
            /**
             * #GstAudioFormat
             */
            format: AudioFormat
            /**
             * string representation of the format
             */
            name: string
            /**
             * user readable description of the format
             */
            description: string
            /**
             * #GstAudioFormatFlags
             */
            flags: AudioFormatFlags
            /**
             * the endianness
             */
            endianness: number
            /**
             * amount of bits used for one sample
             */
            width: number
            /**
             * amount of valid bits in @width
             */
            depth: number
            /**
             * @width/8 bytes with 1 silent sample
             */
            silence: Uint8Array
            /**
             * the format of the unpacked samples
             */
            unpack_format: AudioFormat
            /**
             * function to unpack samples
             */
            unpack_func: AudioFormatUnpack
            /**
             * function to pack samples
             */
            pack_func: AudioFormatPack
            /**
             * Fill @length bytes in @dest with silence samples for @info.
             * @since 1.20
             * @param dest a destination
              to fill
             */
            fill_silence(dest: Uint8Array): void
        }
        /**
         * Information describing audio properties. This information can be filled
         * in from GstCaps with gst_audio_info_from_caps().
         *
         * Use the provided macros to access the info in this structure.
         */
        abstract class AudioInfo {
            static readonly $gtype: GObject.GType<AudioInfo>

            
            /**
             * Allocate a new #GstAudioInfo that is also initialized with
             * gst_audio_info_init().
             * @returns a new #GstAudioInfo. free with gst_audio_info_free().
             */
            static "new"(): AudioInfo
            /**
             * Parse @caps to generate a #GstAudioInfo.
             * @since 1.20
             * @param caps a #GstCaps
             * @returns A #GstAudioInfo, or %NULL if `caps` couldn't be parsed
             */
            static new_from_caps(caps: Gst.Caps): AudioInfo | null
            /**
             * Parse @caps and update @info.
             * @param caps a #GstCaps
             * @returns TRUE if `caps` could be parsed, a #GstAudioInfo
             */
            static from_caps(caps: Gst.Caps): [boolean, AudioInfo]
            /**
             * Initialize @info with default values.
             * @returns , a #GstAudioInfo
             */
            static init(): AudioInfo
            /**
             * the format info of the audio
             */
            finfo: AudioFormatInfo
            /**
             * additional audio flags
             */
            flags: AudioFlags
            /**
             * audio layout
             */
            layout: AudioLayout
            /**
             * the audio sample rate
             */
            rate: number
            /**
             * the number of channels
             */
            channels: number
            /**
             * the number of bytes for one frame, this is the size of one
             *         sample * @channels
             */
            bpf: number
            /**
             * the positions for each channel
             */
            position: AudioChannelPosition[]
            /**
             * Converts among various #GstFormat types.  This function handles
             * GST_FORMAT_BYTES, GST_FORMAT_TIME, and GST_FORMAT_DEFAULT.  For
             * raw audio, GST_FORMAT_DEFAULT corresponds to audio frames.  This
             * function can be used to handle pad queries of the type GST_QUERY_CONVERT.
             * @param src_fmt #GstFormat of the @src_val
             * @param src_val value to convert
             * @param dest_fmt #GstFormat of the @dest_val
             * @returns TRUE if the conversion was successful., pointer to destination value
             */
            convert(src_fmt: Gst.Format, src_val: number, dest_fmt: Gst.Format): [boolean, number]
            /**
             * Copy a GstAudioInfo structure.
             * @returns a new #GstAudioInfo. free with gst_audio_info_free.
             */
            copy(): AudioInfo
            /**
             * Free a GstAudioInfo structure previously allocated with gst_audio_info_new()
             * or gst_audio_info_copy().
             */
            free(): void
            /**
             * Compares two #GstAudioInfo and returns whether they are equal or not
             * @since 1.2
             * @param other a #GstAudioInfo
             * @returns %TRUE if `info` and `other` are equal, else %FALSE.
             */
            is_equal(other: AudioInfo): boolean
            /**
             * Set the default info for the audio info of @format and @rate and @channels.
             *
             * Note: This initializes @info first, no values are preserved.
             * @param format the format
             * @param rate the samplerate
             * @param channels the number of channels
             * @param position the channel positions
             */
            set_format(format: AudioFormat, rate: number, channels: number, position: AudioChannelPosition[] | null): void
            /**
             * Convert the values of @info into a #GstCaps.
             * @returns the new #GstCaps containing the          info of `info`.
             */
            to_caps(): Gst.Caps
        }
        /**
         * Meta containing Audio Level Indication: https://tools.ietf.org/html/rfc6464
         * @since 1.20
         */
        abstract class AudioLevelMeta {
            static readonly $gtype: GObject.GType<AudioLevelMeta>

            
            /**
             * Return the #GstMetaInfo associated with #GstAudioLevelMeta.
             * @since 1.20
             * @returns a #GstMetaInfo
             */
            static get_info(): Gst.MetaInfo
            /**
             * parent #GstMeta
             */
            meta: Gst.Meta
            /**
             * the -dBov from 0-127 (127 is silence).
             */
            level: number
            /**
             * whether the buffer contains voice activity
             */
            voice_activity: boolean
        }
        /**
         * #GstAudioDownmixMeta defines an audio downmix matrix to be send along with
         * audio buffers. These functions in this module help to create and attach the
         * meta as well as extracting it.
         * @since 1.16
         */
        abstract class AudioMeta {
            static readonly $gtype: GObject.GType<AudioMeta>

            
            /**
             */
            static get_info(): Gst.MetaInfo
            /**
             * parent #GstMeta
             */
            meta: Gst.Meta
            /**
             * the audio properties of the buffer
             */
            info: AudioInfo
            /**
             * the number of valid samples in the buffer
             */
            samples: number
            /**
             * the offsets (in bytes) where each channel plane starts in the
             *   buffer or %NULL if the buffer has interleaved layout; if not %NULL, this
             *   is guaranteed to be an array of @info.channels elements
             */
            offsets: number
        }
        /**
         */
        abstract class AudioQuantize {
            static readonly $gtype: GObject.GType<AudioQuantize>

            
            /**
             * Free a #GstAudioQuantize.
             */
            free(): void
            /**
             * Reset @quant to the state is was when created, clearing any
             * history it might have.
             */
            reset(): void
            /**
             * Perform quantization on @samples in @in and write the result to @out.
             *
             * In case the samples are interleaved, @in and @out must point to an
             * array with a single element pointing to a block of interleaved samples.
             *
             * If non-interleaved samples are used, @in and @out must point to an
             * array with pointers to memory blocks, one for each channel.
             *
             * @in and @out may point to the same memory location, in which case samples will be
             * modified in-place.
             * @param in input samples
             * @param out output samples
             * @param samples number of samples
             */
            samples(in_: never | null, out: never | null, samples: number): void
        }
        /**
         * #GstAudioResampler is a structure which holds the information
         * required to perform various kinds of resampling filtering.
         * @since 1.10
         */
        abstract class AudioResampler {
            static readonly $gtype: GObject.GType<AudioResampler>

            
            /**
             * Make a new resampler.
             * @param method a #GstAudioResamplerMethod
             * @param flags #GstAudioResamplerFlags
             * @param format the #GstAudioFormat
             * @param channels the number of channels
             * @param in_rate input rate
             * @param out_rate output rate
             * @param options extra options
             * @returns The new #GstAudioResampler.
             */
            static "new"(method: AudioResamplerMethod, flags: AudioResamplerFlags, format: AudioFormat, channels: number, in_rate: number, out_rate: number, options: Gst.Structure): AudioResampler
            /**
             * Set the parameters for resampling from @in_rate to @out_rate using @method
             * for @quality in @options.
             * @param method a #GstAudioResamplerMethod
             * @param quality the quality
             * @param in_rate the input rate
             * @param out_rate the output rate
             * @param options a #GstStructure
             */
            static options_set_quality(method: AudioResamplerMethod, quality: number, in_rate: number, out_rate: number, options: Gst.Structure): void
            /**
             * Free a previously allocated #GstAudioResampler @resampler.
             */
            free(): void
            /**
             * Get the number of input frames that would currently be needed
             * to produce @out_frames from @resampler.
             * @param out_frames number of input frames
             * @returns The number of input frames needed for producing `out_frames` of data from `resampler`.
             */
            get_in_frames(out_frames: number): number
            /**
             * Get the maximum number of input samples that the resampler would
             * need before producing output.
             * @returns the latency of `resampler` as expressed in the number of frames.
             */
            get_max_latency(): number
            /**
             * Get the number of output frames that would be currently available when
             * @in_frames are given to @resampler.
             * @param in_frames number of input frames
             * @returns The number of frames that would be available after giving `in_frames` as input to `resampler`.
             */
            get_out_frames(in_frames: number): number
            /**
             * Perform resampling on @in_frames frames in @in and write @out_frames to @out.
             *
             * In case the samples are interleaved, @in and @out must point to an
             * array with a single element pointing to a block of interleaved samples.
             *
             * If non-interleaved samples are used, @in and @out must point to an
             * array with pointers to memory blocks, one for each channel.
             *
             * @in may be %NULL, in which case @in_frames of silence samples are pushed
             * into the resampler.
             *
             * This function always produces @out_frames of output and consumes @in_frames of
             * input. Use gst_audio_resampler_get_out_frames() and
             * gst_audio_resampler_get_in_frames() to make sure @in_frames and @out_frames
             * are matching and @in and @out point to enough memory.
             * @param in input samples
             * @param in_frames number of input frames
             * @param out output samples
             * @param out_frames number of output frames
             */
            resample(in_: never | null, in_frames: number, out: never | null, out_frames: number): void
            /**
             * Reset @resampler to the state it was when it was first created, discarding
             * all sample history.
             */
            reset(): void
            /**
             * Update the resampler parameters for @resampler. This function should
             * not be called concurrently with any other function on @resampler.
             *
             * When @in_rate or @out_rate is 0, its value is unchanged.
             *
             * When @options is %NULL, the previously configured options are reused.
             * @param in_rate new input rate
             * @param out_rate new output rate
             * @param options new options or %NULL
             * @returns %TRUE if the new parameters could be set
             */
            update(in_rate: number, out_rate: number, options: Gst.Structure): boolean
        }
        none
        /**
         */
        abstract class AudioRingBufferPrivate {
            static readonly $gtype: GObject.GType<AudioRingBufferPrivate>

            
        }
        /**
         * The structure containing the format specification of the ringbuffer.
         *
         * When @type is GST_AUDIO_RING_BUFFER_FORMAT_TYPE_DSD, the @dsd_format
         * is valid (otherwise it is unused). Also, when DSD is the sample type,
         * only the rate, channels, position, and bpf fields in @info are populated.
         */
        abstract class AudioRingBufferSpec {
            static readonly $gtype: GObject.GType<AudioRingBufferSpec>

            
            /**
             * The caps that generated the Spec.
             */
            caps: Gst.Caps
            /**
             * the sample type
             */
            type: AudioRingBufferFormatType
            /**
             * the #GstAudioInfo
             */
            info: AudioInfo
            /**
             * the latency in microseconds
             */
            latency_time: number
            /**
             * the total buffer size in microseconds
             */
            buffer_time: number
            /**
             * the size of one segment in bytes
             */
            segsize: number
            /**
             * the total number of segments
             */
            segtotal: number
            /**
             * number of segments queued in the lower level device,
             *  defaults to segtotal
             */
            seglatency: number
        }
        none
        /**
         */
        abstract class AudioSinkClassExtension {
            static readonly $gtype: GObject.GType<AudioSinkClassExtension>

            
        }
        none
        /**
         * #GstAudioStreamAlign provides a helper object that helps tracking audio
         * stream alignment and discontinuities, and detects discontinuities if
         * possible.
         *
         * See gst_audio_stream_align_new() for a description of its parameters and
         * gst_audio_stream_align_process() for the details of the processing.
         * @since 1.14
         */
        abstract class AudioStreamAlign {
            static readonly $gtype: GObject.GType<AudioStreamAlign>

            
            /**
             * Allocate a new #GstAudioStreamAlign with the given configuration. All
             * processing happens according to sample rate @rate, until
             * gst_audio_stream_align_set_rate() is called with a new @rate.
             * A negative rate can be used for reverse playback.
             *
             * @alignment_threshold gives the tolerance in nanoseconds after which a
             * timestamp difference is considered a discontinuity. Once detected,
             * @discont_wait nanoseconds have to pass without going below the threshold
             * again until the output buffer is marked as a discontinuity. These can later
             * be re-configured with gst_audio_stream_align_set_alignment_threshold() and
             * gst_audio_stream_align_set_discont_wait().
             * @since 1.14
             * @param rate a sample rate
             * @param alignment_threshold a alignment threshold in nanoseconds
             * @param discont_wait discont wait in nanoseconds
             * @returns a new #GstAudioStreamAlign. free with gst_audio_stream_align_free().
             */
            static "new"(rate: number, alignment_threshold: Gst.ClockTime, discont_wait: Gst.ClockTime): AudioStreamAlign
            /**
             * Copy a GstAudioStreamAlign structure.
             * @since 1.14
             * @returns a new #GstAudioStreamAlign. free with gst_audio_stream_align_free.
             */
            copy(): AudioStreamAlign
            /**
             * Free a GstAudioStreamAlign structure previously allocated with gst_audio_stream_align_new()
             * or gst_audio_stream_align_copy().
             * @since 1.14
             */
            free(): void
            /**
             * Gets the currently configured alignment threshold.
             * @since 1.14
             * @returns The currently configured alignment threshold
             */
            get_alignment_threshold(): Gst.ClockTime
            /**
             * Gets the currently configured discont wait.
             * @since 1.14
             * @returns The currently configured discont wait
             */
            get_discont_wait(): Gst.ClockTime
            /**
             * Gets the currently configured sample rate.
             * @since 1.14
             * @returns The currently configured sample rate
             */
            get_rate(): number
            /**
             * Returns the number of samples that were processed since the last
             * discontinuity was detected.
             * @since 1.14
             * @returns The number of samples processed since the last discontinuity.
             */
            get_samples_since_discont(): number
            /**
             * Timestamp that was passed when a discontinuity was detected, i.e. the first
             * timestamp after the discontinuity.
             * @since 1.14
             * @returns The last timestamp at when a discontinuity was detected
             */
            get_timestamp_at_discont(): Gst.ClockTime
            /**
             * Marks the next buffer as discontinuous and resets timestamp tracking.
             * @since 1.14
             */
            mark_discont(): void
            /**
             * Processes data with @timestamp and @n_samples, and returns the output
             * timestamp, duration and sample position together with a boolean to signal
             * whether a discontinuity was detected or not. All non-discontinuous data
             * will have perfect timestamps and durations.
             *
             * A discontinuity is detected once the difference between the actual
             * timestamp and the timestamp calculated from the sample count since the last
             * discontinuity differs by more than the alignment threshold for a duration
             * longer than discont wait.
             *
             * Note: In reverse playback, every buffer is considered discontinuous in the
             * context of buffer flags because the last sample of the previous buffer is
             * discontinuous with the first sample of the current one. However for this
             * function they are only considered discontinuous in reverse playback if the
             * first sample of the previous buffer is discontinuous with the last sample
             * of the current one.
             * @since 1.14
             * @param discont if this data is considered to be discontinuous
             * @param timestamp a #GstClockTime of the start of the data
             * @param n_samples number of samples to process
             * @returns %TRUE if a discontinuity was detected, %FALSE otherwise., output timestamp of the data, output duration of the data, output sample position of the start of the data
             */
            process(discont: boolean, timestamp: Gst.ClockTime, n_samples: number): [boolean, Gst.ClockTime, Gst.ClockTime, number]
            /**
             * Sets @alignment_treshold as new alignment threshold for the following processing.
             * @since 1.14
             * @param alignment_threshold a new alignment threshold
             */
            set_alignment_threshold(alignment_threshold: Gst.ClockTime): void
            /**
             * Sets @alignment_treshold as new discont wait for the following processing.
             * @since 1.14
             * @param discont_wait a new discont wait
             */
            set_discont_wait(discont_wait: Gst.ClockTime): void
            /**
             * Sets @rate as new sample rate for the following processing. If the sample
             * rate differs this implicitly marks the next data as discontinuous.
             * @since 1.14
             * @param rate a new sample rate
             */
            set_rate(rate: number): void
        }
        /**
         * Information describing DSD audio properties.
         *
         * In DSD, the "sample format" is the bit. Unlike PCM, there are no further
         * "sample formats" in DSD. However, in software, DSD bits are grouped into
         * bytes (since dealing with individual bits is impractical), and these bytes
         * in turn are grouped into words. This becomes relevant when interleaving
         * channels and transmitting DSD data through audio APIs. The different
         * types of grouping DSD bytes are referred to as the "DSD grouping forma"
         * or just "DSD format". #GstDsdFormat has a list of valid ways of grouping
         * DSD bytes into words.
         *
         * DSD rates are equivalent to PCM sample rates, except that they specify
         * how many DSD bytes are consumed per second. This refers to the bytes per
         * second _per channel_; the rate does not change when the number of channel
         * changes. (Strictly speaking, it would be more correct to measure the
         * *bits* per second, since the bit is the DSD "sample format", but it is
         * more practical to use bytes.) In DSD, bit rates are always an integer
         * multiple of the CD audio rate (44100) or the DAT rate (48000). DSD64-44x
         * is 44100 * 64 = 2822400 bits per second, or 352800 bytes per second
         * (the latter would be used in this info structure). DSD64-48x is
         * 48000 * 64 = 3072000 bits per second, or 384000 bytes per second.
         * #GST_DSD_MAKE_DSD_RATE_44x can be used for specifying DSD-44x rates,
         * *and #GST_DSD_MAKE_DSD_RATE_48x can be used for specifying DSD-48x ones.
         * Also, since DSD-48x is less well known, when the multiplier is given
         * without the 44x/48x specifier, 44x is typically implied.
         *
         * It is important to know that in DSD, different format widths correspond
         * to different playtimes. That is, a word with 32 DSD bits covers two times
         * as much playtime as a word with 16 DSD bits. This is in contrast to PCM,
         * where one word (= one PCM sample) always covers a time period of 1/samplerate,
         * no matter how many bits a PCM sample is made of. For this reason, DSD
         * and PCM widths and strides cannot be used the same way.
         *
         * Multiple channels are arranged in DSD data either interleaved or non-
         * interleaved. This is similar to PCM. Interleaved layouts rotate between
         * channels and words. First, word 0 of channel 0 is present. Then word
         * 0 of channel 1 follows. Then word 0 of channel 2 etc. until all
         * channels are through, then comes word 1 of channel 0 etc.
         *
         * Non-interleaved data is planar. First, all words of channel 0 are
         * present, then all words of channel 1 etc. Unlike interleaved data,
         * non-interleaved data can be sparse, that is, there can be space in
         * between the planes. the @positions array specifies the plane offsets.
         *
         * In uncommon cases, the DSD bits in the data bytes can be stored in reverse
         * order. For example, normally, in DSDU8, the first byte contains DSD bits
         * 0 to 7, and the most significant bit of that byte is DSD bit 0. If this
         * order is reversed, then bit 7 is the first one instead. In that ase,
         * @reversed_bytes is set to TRUE.
         *
         * Use the provided macros to access the info in this structure.
         * @since 1.24
         */
        abstract class DsdInfo {
            static readonly $gtype: GObject.GType<DsdInfo>

            
            /**
             * Allocate a new #GstDsdInfo that is also initialized with
             * gst_dsd_info_init().
             * @since 1.24
             * @returns a new #GstDsdInfo. free with gst_dsd_info_free().
             */
            static "new"(): DsdInfo
            /**
             * Parse @caps to generate a #GstDsdInfo.
             * @since 1.24
             * @param caps a #GstCaps
             * @returns A #GstDsdInfo, or %NULL if `caps` couldn't be parsed
             */
            static new_from_caps(caps: Gst.Caps): DsdInfo
            /**
             * Parse @caps and update @info.
             * @since 1.24
             * @param caps a #GstCaps
             * @returns TRUE if `caps` could be parsed, a #GstDsdInfo
             */
            static from_caps(caps: Gst.Caps): [boolean, DsdInfo]
            /**
             * Initialize @info with default values.
             * @since 1.24
             * @returns , a #GstDsdInfo
             */
            static init(): DsdInfo
            /**
             * DSD grouping format
             */
            format: DsdFormat
            /**
             * DSD rate
             */
            rate: number
            /**
             * number of channels (must be at least 1)
             */
            channels: number
            /**
             * audio layout
             */
            layout: AudioLayout
            /**
             * true if the DSD bits in the data bytes are reversed,
             *   that is, the least significant bit comes first
             */
            reversed_bytes: boolean
            /**
             * positions for each channel
             */
            positions: AudioChannelPosition[]
            /**
             */
            flags: AudioFlags
            /**
             * Copy a GstDsdInfo structure.
             * @since 1.24
             * @returns a new #GstDsdInfo. free with gst_dsd_info_free.
             */
            copy(): DsdInfo
            /**
             * Free a GstDsdInfo structure previously allocated with gst_dsd_info_new()
             * or gst_dsd_info_copy().
             * @since 1.24
             */
            free(): void
            /**
             * Compares two #GstDsdInfo and returns whether they are equal or not
             * @since 1.24
             * @param other a #GstDsdInfo
             * @returns %TRUE if `info` and `other` are equal, else %FALSE.
             */
            is_equal(other: DsdInfo): boolean
            /**
             * Set the default info for the DSD info of @format and @rate and @channels.
             *
             * Note: This initializes @info first, no values are preserved.
             * @since 1.24
             * @param format the format
             * @param rate the DSD rate
             * @param channels the number of channels
             * @param positions the channel positions
             */
            set_format(format: DsdFormat, rate: number, channels: number, positions: AudioChannelPosition[] | null): void
            /**
             * Convert the values of @info into a #GstCaps.
             * @since 1.24
             * @returns the new #GstCaps containing the          info of `info`.
             */
            to_caps(): Gst.Caps
        }
        /**
         * Buffer metadata describing planar DSD contents in the buffer. This is not needed
         * for interleaved DSD data, and is required for non-interleaved (= planar) data.
         *
         * The different channels in @offsets are always in the GStreamer channel order.
         * Zero-copy channel reordering can be implemented by swapping the values in
         * @offsets.
         *
         * It is not allowed for channels to overlap in memory,
         * i.e. for each i in [0, channels), the range
         * [@offsets[i], @offsets[i] + @num_bytes_per_channel) must not overlap
         * with any other such range.
         *
         * It is, however, allowed to have parts of the buffer memory unused, by using
         * @offsets and @num_bytes_per_channel in such a way that leave gaps on it.
         * This is used to implement zero-copy clipping in non-interleaved buffers.
         *
         * Obviously, due to the above, it is not safe to infer the
         * number of valid bytes from the size of the buffer. You should always
         * use the @num_bytes_per_channel variable of this metadata.
         * @since 1.24
         */
        abstract class DsdPlaneOffsetMeta {
            static readonly $gtype: GObject.GType<DsdPlaneOffsetMeta>

            
            /**
             */
            static get_info(): Gst.MetaInfo
            /**
             * parent #GstMeta
             */
            meta: Gst.Meta
            /**
             * number of channels in the DSD data
             */
            num_channels: number
            /**
             * the number of valid bytes per channel in the buffer
             */
            num_bytes_per_channel: number
            /**
             * the offsets (in bytes) where each channel plane starts in the buffer
             */
            offsets: number
        }
        none
        /**
         * Clip the buffer to the given %GstSegment.
         *
         * After calling this function the caller does not own a reference to
         * @buffer anymore.
         * @param buffer The buffer to clip.
         * @param segment Segment in %GST_FORMAT_TIME or %GST_FORMAT_DEFAULT to which
                  the buffer should be clipped.
         * @param rate sample rate.
         * @param bpf size of one audio frame in bytes. This is the size of one sample *
        number of channels.
         * @returns %NULL if the buffer is completely outside the configured segment, otherwise the clipped buffer is returned.  If the buffer has no timestamp, it is assumed to be inside the segment and is not clipped
         */
        function audio_buffer_clip(buffer: Gst.Buffer, segment: Gst.Segment, rate: number, bpf: number): Gst.Buffer | null
        /**
         * Maps an audio @gstbuffer so that it can be read or written and stores the
         * result of the map operation in @buffer.
         *
         * This is especially useful when the @gstbuffer is in non-interleaved (planar)
         * layout, in which case this function will use the information in the
         * @gstbuffer's attached #GstAudioMeta in order to map each channel in a
         * separate "plane" in #GstAudioBuffer. If a #GstAudioMeta is not attached
         * on the @gstbuffer, then it must be in interleaved layout.
         *
         * If a #GstAudioMeta is attached, then the #GstAudioInfo on the meta is checked
         * against @info. Normally, they should be equal, but in case they are not,
         * a g_critical will be printed and the #GstAudioInfo from the meta will be
         * used.
         *
         * In non-interleaved buffers, it is possible to have each channel on a separate
         * #GstMemory. In this case, each memory will be mapped separately to avoid
         * copying their contents in a larger memory area. Do note though that it is
         * not supported to have a single channel spanning over two or more different
         * #GstMemory objects. Although the map operation will likely succeed in this
         * case, it will be highly sub-optimal and it is recommended to merge all the
         * memories in the buffer before calling this function.
         *
         * Note: The actual #GstBuffer is not ref'ed, but it is required to stay valid
         * as long as it's mapped.
         * @since 1.16
         * @param info the audio properties of the buffer
         * @param gstbuffer the #GstBuffer to be mapped
         * @param flags the access mode for the memory
         * @returns %TRUE if the map operation succeeded or %FALSE on failure, pointer to a #GstAudioBuffer
         */
        function audio_buffer_map(info: AudioInfo, gstbuffer: Gst.Buffer, flags: Gst.MapFlags): [boolean, AudioBuffer]
        /**
         * Reorders @buffer from the channel positions @from to the channel
         * positions @to. @from and @to must contain the same number of
         * positions and the same positions, only in a different order.
         * @buffer must be writable.
         * @param buffer The buffer to reorder.
         * @param format The %GstAudioFormat of the buffer.
         * @param from The channel positions in the buffer.
         * @param to The channel positions to convert to.
         * @returns %TRUE if the reordering was possible.
         */
        function audio_buffer_reorder_channels(buffer: Gst.Buffer, format: AudioFormat, from: AudioChannelPosition[], to: AudioChannelPosition[]): boolean
        /**
         * Truncate the buffer to finally have @samples number of samples, removing
         * the necessary amount of samples from the end and @trim number of samples
         * from the beginning.
         *
         * This function does not know the audio rate, therefore the caller is
         * responsible for re-setting the correct timestamp and duration to the
         * buffer. However, timestamp will be preserved if trim == 0, and duration
         * will also be preserved if there is no trimming to be done. Offset and
         * offset end will be preserved / updated.
         *
         * After calling this function the caller does not own a reference to
         * @buffer anymore.
         * @since 1.16
         * @param buffer The buffer to truncate.
         * @param bpf size of one audio frame in bytes. This is the size of one sample *
        number of channels.
         * @param trim the number of samples to remove from the beginning of the buffer
         * @param samples the final number of samples that should exist in this buffer or -1
        to use all the remaining samples if you are only removing samples from the
        beginning.
         * @returns the truncated buffer
         */
        function audio_buffer_truncate(buffer: Gst.Buffer, bpf: number, trim: number, samples: number): Gst.Buffer
        /**
         * Get the fallback channel-mask for the given number of channels.
         *
         * This function returns a reasonable fallback channel-mask and should be
         * called as a last resort when the specific channel map is unknown.
         * @since 1.8
         * @param channels the number of channels
         * @returns a fallback channel-mask for `channels` or 0 when there is no mask and mono.
         */
        function audio_channel_get_fallback_mask(channels: number): number
        none
        none
        /**
         * Convert the @channels present in @channel_mask to a @position array
         * (which should have at least @channels entries ensured by caller).
         * If @channel_mask is set to 0, it is considered as 'not present' for purpose
         * of conversion.
         * A partially valid @channel_mask with less bits set than the number
         * of channels is considered valid.
         * @param channel_mask The input channel_mask
         * @param position s
         * @returns %TRUE if channel and channel mask are valid and could be converted
         */
        function audio_channel_positions_from_mask(channel_mask: number, position: AudioChannelPosition[]): boolean
        /**
         * Convert the @position array of @channels channels to a bitmask.
         *
         * If @force_order is %TRUE it additionally checks if the channels are
         * in the order required by GStreamer.
         * @param position The %GstAudioChannelPositions
         * @param force_order Only consider the GStreamer channel order.
         * @returns %TRUE if the channel positions are valid and could be converted., the output channel mask
         */
        function audio_channel_positions_to_mask(position: AudioChannelPosition[], force_order: boolean): [boolean, number]
        /**
         * Converts @position to a human-readable string representation for
         * debugging purposes.
         * @since 1.10
         * @param position The %GstAudioChannelPositions
          to convert.
         * @returns a newly allocated string representing `position`
         */
        function audio_channel_positions_to_string(position: AudioChannelPosition[]): string
        /**
         * Reorders the channel positions in @position from any order to
         * the GStreamer channel order.
         * @param position The channel positions to
          reorder to.
         * @returns %TRUE if the channel positions are valid and reordering was successful.
         */
        function audio_channel_positions_to_valid_order(position: AudioChannelPosition[]): boolean
        /**
         * Checks if @position contains valid channel positions for
         * @channels channels. If @force_order is %TRUE it additionally
         * checks if the channels are in the order required by GStreamer.
         * @param position The %GstAudioChannelPositions
          to check.
         * @param force_order Only consider the GStreamer channel order.
         * @returns %TRUE if the channel positions are valid.
         */
        function audio_check_valid_channel_positions(position: AudioChannelPosition[], force_order: boolean): boolean
        /**
         */
        function audio_clipping_meta_api_get_type(): GObject.GType
        /**
         */
        function audio_clipping_meta_get_info(): Gst.MetaInfo
        /**
         */
        function audio_downmix_meta_api_get_type(): GObject.GType
        /**
         */
        function audio_downmix_meta_get_info(): Gst.MetaInfo
        /**
         * Construct a #GstAudioFormat with given parameters.
         * @param sign signed or unsigned format
         * @param endianness G_LITTLE_ENDIAN or G_BIG_ENDIAN
         * @param width amount of bits used per sample
         * @param depth amount of used bits in @width
         * @returns a #GstAudioFormat or GST_AUDIO_FORMAT_UNKNOWN when no audio format exists with the given parameters.
         */
        function audio_format_build_integer(sign: boolean, endianness: number, width: number, depth: number): AudioFormat
        /**
         * Fill @length bytes in @dest with silence samples for @info.
         * @deprecated since 1.20 Use gst_audio_format_info_fill_silence() instead.
         * @param info a #GstAudioFormatInfo
         * @param dest a destination
          to fill
         */
        function audio_format_fill_silence(info: AudioFormatInfo, dest: Uint8Array): void
        /**
         * Convert the @format string to its #GstAudioFormat.
         * @param format a format string
         * @returns the #GstAudioFormat for `format` or GST_AUDIO_FORMAT_UNKNOWN when the string is not a known format.
         */
        function audio_format_from_string(format: string): AudioFormat
        /**
         * Get the #GstAudioFormatInfo for @format
         * @param format a #GstAudioFormat
         * @returns The #GstAudioFormatInfo for `format`.
         */
        function audio_format_get_info(format: AudioFormat): AudioFormatInfo
        /**
         * Returns a string containing a descriptive name for the #GstAudioFormat.
         *
         * Since 1.26 this can also be used with %GST_AUDIO_FORMAT_UNKNOWN, previous
         * versions were printing a critical warning and returned %NULL.
         * @param format a #GstAudioFormat audio format
         * @returns the name corresponding to `format`
         */
        function audio_format_to_string(format: AudioFormat): string
        /**
         * Return all the raw audio formats supported by GStreamer.
         * @since 1.18
         * @returns an array of #GstAudioFormat
         */
        function audio_formats_raw(): AudioFormat[]
        /**
         * Returns a reorder map for @from to @to that can be used in
         * custom channel reordering code, e.g. to convert from or to the
         * GStreamer channel order. @from and @to must contain the same
         * number of positions and the same positions, only in a
         * different order.
         *
         * The resulting @reorder_map can be used for reordering by assigning
         * channel i of the input to channel reorder_map[i] of the output.
         * @param from The channel positions to reorder from.
         * @param to The channel positions to reorder to.
         * @param reorder_map Pointer to the reorder map.
         * @returns %TRUE if the channel positions are valid and reordering is possible.
         */
        function audio_get_channel_reorder_map(from: AudioChannelPosition[], to: AudioChannelPosition[], reorder_map: number[]): boolean
        /**
         * Calculated the size of the buffer expected by gst_audio_iec61937_payload() for
         * payloading type from @spec.
         * @param spec the ringbufer spec
         * @returns the size or 0 if the given `type` is not supported or cannot be payloaded.
         */
        function audio_iec61937_frame_size(spec: AudioRingBufferSpec): number
        /**
         * Payloads @src in the form specified by IEC 61937 for the type from @spec and
         * stores the result in @dst. @src must contain exactly one frame of data and
         * the frame is not checked for errors.
         * @param src a buffer containing the data to payload
         * @param dst the destination buffer to store the
              payloaded contents in. Should not overlap with @src
         * @param spec the ringbufer spec for @src
         * @param endianness the expected byte order of the payloaded data
         * @returns transfer-full: %TRUE if the payloading was successful, %FALSE otherwise.
         */
        function audio_iec61937_payload(src: Uint8Array, dst: Uint8Array, spec: AudioRingBufferSpec, endianness: number): boolean
        /**
         * Parse @caps and update @info.
         * @param caps a #GstCaps
         * @returns TRUE if `caps` could be parsed, a #GstAudioInfo
         */
        function audio_info_from_caps(caps: Gst.Caps): [boolean, AudioInfo]
        /**
         * Initialize @info with default values.
         * @returns , a #GstAudioInfo
         */
        function audio_info_init(): AudioInfo
        /**
         * Return the #GType associated with #GstAudioLevelMeta.
         * @since 1.20
         * @returns a #GType
         */
        function audio_level_meta_api_get_type(): GObject.GType
        /**
         * Return the #GstMetaInfo associated with #GstAudioLevelMeta.
         * @since 1.20
         * @returns a #GstMetaInfo
         */
        function audio_level_meta_get_info(): Gst.MetaInfo
        /**
         * Return a generic raw audio caps for formats defined in @formats.
         * If @formats is %NULL returns a caps for all the supported raw audio formats,
         * see gst_audio_formats_raw().
         * @since 1.18
         * @param formats an array of raw #GstAudioFormat, or %NULL
         * @param layout the layout of audio samples
         * @returns an audio `GstCaps`
         */
        function audio_make_raw_caps(formats: AudioFormat[] | null, layout: AudioLayout): Gst.Caps
        /**
         */
        function audio_meta_api_get_type(): GObject.GType
        /**
         */
        function audio_meta_get_info(): Gst.MetaInfo
        none
        /**
         * Reorders @data from the channel positions @from to the channel
         * positions @to. @from and @to must contain the same number of
         * positions and the same positions, only in a different order.
         *
         * This function internally calls gst_audio_get_channel_reorder_map() and
         * gst_audio_reorder_channels_with_reorder_map(). It is more efficient to call
         * gst_audio_get_channel_reorder_map() once to retrieve the reorder map and
         * then call gst_audio_reorder_channels_with_reorder_map() with the same
         * reorder map until the channel positions change.
         *
         * Note: this function assumes the audio data is in interleaved layout
         * @param data The pointer to
          the memory.
         * @param format The %GstAudioFormat of the buffer.
         * @param from The channel positions in the buffer.
         * @param to The channel positions to convert to.
         * @returns %TRUE if the reordering was possible.
         */
        function audio_reorder_channels(data: Uint8Array, format: AudioFormat, from: AudioChannelPosition[], to: AudioChannelPosition[]): boolean
        /**
         * Reorders @data with the given @reorder_map.
         *
         * The reorder map can be retrieved for example with
         * gst_audio_get_channel_reorder_map().
         *
         * Note: this function assumes the audio data is in interleaved layout
         * @since 1.26
         * @param data The pointer to
          the memory.
         * @param bps The number of bytes per sample.
         * @param reorder_map The channel reorder map.
         */
        function audio_reorder_channels_with_reorder_map(data: Uint8Array, bps: number, reorder_map: number[]): void
        /**
         * Make a new resampler.
         * @param method a #GstAudioResamplerMethod
         * @param flags #GstAudioResamplerFlags
         * @param format the #GstAudioFormat
         * @param channels the number of channels
         * @param in_rate input rate
         * @param out_rate output rate
         * @param options extra options
         * @returns The new #GstAudioResampler.
         */
        function audio_resampler_new(method: AudioResamplerMethod, flags: AudioResamplerFlags, format: AudioFormat, channels: number, in_rate: number, out_rate: number, options: Gst.Structure): AudioResampler
        /**
         * Set the parameters for resampling from @in_rate to @out_rate using @method
         * for @quality in @options.
         * @param method a #GstAudioResamplerMethod
         * @param quality the quality
         * @param in_rate the input rate
         * @param out_rate the output rate
         * @param options a #GstStructure
         */
        function audio_resampler_options_set_quality(method: AudioResamplerMethod, quality: number, in_rate: number, out_rate: number, options: Gst.Structure): void
        /**
         * Attaches #GstAudioClippingMeta metadata to @buffer with the given parameters.
         * @since 1.8
         * @param buffer a #GstBuffer
         * @param format GstFormat of @start and @stop, GST_FORMAT_DEFAULT is samples
         * @param start Amount of audio to clip from start of buffer
         * @param end Amount of  to clip from end of buffer
         * @returns the #GstAudioClippingMeta on `buffer`.
         */
        function buffer_add_audio_clipping_meta(buffer: Gst.Buffer, format: Gst.Format, start: number, end: number): AudioClippingMeta
        /**
         * Attaches #GstAudioDownmixMeta metadata to @buffer with the given parameters.
         *
         * @matrix is an two-dimensional array of @to_channels times @from_channels
         * coefficients, i.e. the i-th output channels is constructed by multiplicating
         * the input channels with the coefficients in @matrix[i] and taking the sum
         * of the results.
         * @param buffer a #GstBuffer
         * @param from_position the channel positions
          of the source
         * @param to_position the channel positions of
          the destination
         * @param matrix The matrix coefficients.
         * @returns the #GstAudioDownmixMeta on `buffer`.
         */
        function buffer_add_audio_downmix_meta(buffer: Gst.Buffer, from_position: AudioChannelPosition[], to_position: AudioChannelPosition[], matrix: number): AudioDownmixMeta
        /**
         * Attaches audio level information to @buffer. (RFC 6464)
         * @since 1.20
         * @param buffer a #GstBuffer
         * @param level the -dBov from 0-127 (127 is silence).
         * @param voice_activity whether the buffer contains voice activity.
         * @returns the #GstAudioLevelMeta on `buffer`.
         */
        function buffer_add_audio_level_meta(buffer: Gst.Buffer, level: number, voice_activity: boolean): AudioLevelMeta | null
        /**
         * layout is %GST_AUDIO_LAYOUT_NON_INTERLEAVED and @offsets is
         * %NULL, the offsets are calculated with a formula that assumes the planes are
         * tightly packed and in sequence:
         * offsets[channel] = channel * @samples * sample_stride
         *
         * It is not allowed for channels to overlap in memory,
         * i.e. for each i in [0, channels), the range
         * [@offsets[i], @offsets[i] + @samples * sample_stride) must not overlap
         * with any other such range. This function will assert if the parameters
         * specified cause this restriction to be violated.
         *
         * It is, obviously, also not allowed to specify parameters that would cause
         * out-of-bounds memory access on @buffer. This is also checked, which means
         * that you must add enough memory on the @buffer before adding this meta.
         * @since 1.16
         * @param buffer a #GstBuffer
         * @param info the audio properties of the buffer
         * @param samples the number of valid samples in the buffer
         * @param offsets layout is %GST_AUDIO_LAYOUT_INTERLEAVED
         * @returns the #GstAudioMeta that was attached on the `buffer`
         */
        function buffer_add_audio_meta(buffer: Gst.Buffer, info: AudioInfo, samples: number, offsets: number | null): AudioMeta
        /**
         * Allocates and attaches a #GstDsdPlaneOffsetMeta on @buffer, which must be
         * writable for that purpose. The fields of the #GstDsdPlaneOffsetMeta are
         * directly populated from the arguments of this function.
         *
         * If @offsets is NULL, then the meta's offsets field is left uninitialized.
         * This is useful if for example offset values are to be calculated in the
         * meta's offsets field in-place. Similarly, @num_bytes_per_channel can be
         * set to 0, but only if @offsets is NULL. This is useful if the number of
         * bytes per channel is known only later.
         *
         * It is not allowed for channels to overlap in memory,
         * i.e. for each i in [0, channels), the range
         * [@offsets[i], @offsets[i] + @num_bytes_per_channel) must not overlap
         * with any other such range. This function will assert if the parameters
         * specified cause this restriction to be violated.
         *
         * It is, obviously, also not allowed to specify parameters that would cause
         * out-of-bounds memory access on @buffer. This is also checked, which means
         * that you must add enough memory on the @buffer before adding this meta.
         *
         * This meta is only needed for non-interleaved (= planar) DSD data.
         * @since 1.24
         * @param buffer a #GstBuffer
         * @param num_channels Number of channels in the DSD data
         * @param num_bytes_per_channel Number of bytes per channel
         * @param offsets the offsets (in bytes) where each channel plane starts
          in the buffer
         * @returns the #GstDsdPlaneOffsetMeta that was attached   on the `buffer`
         */
        function buffer_add_dsd_plane_offset_meta(buffer: Gst.Buffer, num_channels: number, num_bytes_per_channel: number, offsets: number | null): DsdPlaneOffsetMeta
        /**
         * Find the #GstAudioDownmixMeta on @buffer for the given destination
         * channel positions.
         * @param buffer a #GstBuffer
         * @param to_position the channel positions of
          the destination
         * @returns the #GstAudioDownmixMeta on `buffer`.
         */
        function buffer_get_audio_downmix_meta_for_channels(buffer: Gst.Buffer, to_position: AudioChannelPosition[]): AudioDownmixMeta
        /**
         * Find the #GstAudioLevelMeta on @buffer.
         * @since 1.20
         * @param buffer a #GstBuffer
         * @returns the #GstAudioLevelMeta or %NULL when there is no such metadata on `buffer`.
         */
        function buffer_get_audio_level_meta(buffer: Gst.Buffer): AudioLevelMeta | null
        /**
         * Converts DSD data from one layout and grouping format to another.
         * @num_bytes must be an integer multiple of the width of both input
         * and output format. For example, if the input format is GST_DSD_FORMAT_U32LE,
         * and the output format is GST_DSD_FORMAT_U16BE, then @num_bytes must
         * be an integer multiple of both 4 (U32LE width) and 2 (U16BE width).
         *
         * @reverse_byte_bits is necessary if the bit order within the DSD bytes
         * needs to be reversed. This is rarely necessary, and is not to be
         * confused with the endianness of formats (which determines the ordering
         * of *bytes*).
         *
         * @input_plane_offsets must not be NULL if @input_layout is set to
         * #GST_AUDIO_LAYOUT_NON_INTERLEAVED. The same applies to @output_plane_offsets.
         * These plane offsets define the starting offset of the planes (there is
         * exactly one plane per channel) within @input_data and @output_data
         * respectively. If GST_AUDIO_LAYOUT_INTERLEAVED is used, the plane offsets
         * are ignored.
         * @since 1.24
         * @param input_data the DSD format conversion's input source
         * @param output_data the DSD format conversion's output destination
         * @param input_format DSD format of the input data to convert from
         * @param output_format DSD format of the output data to convert to
         * @param input_layout Input data layout
         * @param output_layout Output data layout
         * @param input_plane_offsets Plane offsets for non-interleaved input data
         * @param output_plane_offsets Plane offsets for non-interleaved output data
         * @param num_dsd_bytes How many bytes with DSD data to convert
         * @param num_channels Number of channels (must be at least 1)
         * @param reverse_byte_bits If TRUE, reverse the bits in each DSD byte
         */
        function dsd_convert(input_data: number, output_data: number, input_format: DsdFormat, output_format: DsdFormat, input_layout: AudioLayout, output_layout: AudioLayout, input_plane_offsets: number, output_plane_offsets: number, num_dsd_bytes: number, num_channels: number, reverse_byte_bits: boolean): void
        /**
         * Convert the DSD format string @str to its #GstDsdFormat.
         * @since 1.24
         * @param str a DSD format string
         * @returns the #GstDsdFormat for `format` or GST_DSD_FORMAT_UNKNOWN when the string is not a known format.
         */
        function dsd_format_from_string(str: string): DsdFormat
        /**
         * @since 1.24
         * @param format a #GstDsdFormat
         * @returns Number of bytes in this DSD grouping format.
         */
        function dsd_format_get_width(format: DsdFormat): number
        /**
         * Returns a string containing a descriptive name for
         * the #GstDsdFormat if there is one, or NULL otherwise.
         * @since 1.24
         * @param format a #GstDsdFormat
         * @returns the name corresponding to `format`
         */
        function dsd_format_to_string(format: DsdFormat): string
        /**
         * Parse @caps and update @info.
         * @since 1.24
         * @param caps a #GstCaps
         * @returns TRUE if `caps` could be parsed, a #GstDsdInfo
         */
        function dsd_info_from_caps(caps: Gst.Caps): [boolean, DsdInfo]
        /**
         * Initialize @info with default values.
         * @since 1.24
         * @returns , a #GstDsdInfo
         */
        function dsd_info_init(): DsdInfo
        /**
         */
        function dsd_plane_offset_meta_api_get_type(): GObject.GType
        /**
         */
        function dsd_plane_offset_meta_get_info(): Gst.MetaInfo
        /**
         * @param from #GstStreamVolumeFormat to convert from
         * @param to #GstStreamVolumeFormat to convert to
         * @param val Volume in @from format that should be converted
         * @returns the converted volume
         */
        function stream_volume_convert_volume(from: StreamVolumeFormat, to: StreamVolumeFormat, val: number): number
        const AUDIO_CHANNELS_RANGE: "(int) [ 1, max ]"
        const AUDIO_CONVERTER_OPT_DITHER_METHOD: "GstAudioConverter.dither-method"
        const AUDIO_CONVERTER_OPT_DITHER_THRESHOLD: "GstAudioConverter.dither-threshold"
        const AUDIO_CONVERTER_OPT_MIX_MATRIX: "GstAudioConverter.mix-matrix"
        const AUDIO_CONVERTER_OPT_NOISE_SHAPING_METHOD: "GstAudioConverter.noise-shaping-method"
        const AUDIO_CONVERTER_OPT_QUANTIZATION: "GstAudioConverter.quantization"
        const AUDIO_CONVERTER_OPT_RESAMPLER_METHOD: "GstAudioConverter.resampler-method"
        const AUDIO_DECODER_MAX_ERRORS: -1
        const AUDIO_DECODER_SINK_NAME: "sink"
        const AUDIO_DECODER_SRC_NAME: "src"
        const AUDIO_DEF_CHANNELS: 2
        const AUDIO_DEF_FORMAT: "S16LE"
        const AUDIO_DEF_RATE: 44100
        const AUDIO_ENCODER_SINK_NAME: "sink"
        const AUDIO_ENCODER_SRC_NAME: "src"
        const AUDIO_FORMATS_ALL: "{ F64BE, F64LE, F32BE, F32LE, S32BE, S32LE, U32BE, U32LE, S24_32BE, S24_32LE, U24_32BE, U24_32LE, S24BE, S24LE, U24BE, U24LE, S20BE, S20LE, U20BE, U20LE, S18BE, S18LE, U18BE, U18LE, S16BE, S16LE, U16BE, U16LE, S8, U8 }"
        const AUDIO_FORMAT_LAST: 32
        const AUDIO_RATE_RANGE: "(int) [ 1, max ]"
        const AUDIO_RESAMPLER_OPT_CUBIC_B: "GstAudioResampler.cubic-b"
        const AUDIO_RESAMPLER_OPT_CUBIC_C: "GstAudioResampler.cubic-c"
        const AUDIO_RESAMPLER_OPT_CUTOFF: "GstAudioResampler.cutoff"
        const AUDIO_RESAMPLER_OPT_FILTER_INTERPOLATION: "GstAudioResampler.filter-interpolation"
        const AUDIO_RESAMPLER_OPT_FILTER_MODE: "GstAudioResampler.filter-mode"
        const AUDIO_RESAMPLER_OPT_FILTER_MODE_THRESHOLD: "GstAudioResampler.filter-mode-threshold"
        const AUDIO_RESAMPLER_OPT_FILTER_OVERSAMPLE: "GstAudioResampler.filter-oversample"
        const AUDIO_RESAMPLER_OPT_MAX_PHASE_ERROR: "GstAudioResampler.max-phase-error"
        const AUDIO_RESAMPLER_OPT_N_TAPS: "GstAudioResampler.n-taps"
        const AUDIO_RESAMPLER_OPT_STOP_ATTENUATION: "GstAudioResampler.stop-attenutation"
        const AUDIO_RESAMPLER_OPT_TRANSITION_BANDWIDTH: "GstAudioResampler.transition-bandwidth"
        const AUDIO_RESAMPLER_QUALITY_DEFAULT: 4
        const AUDIO_RESAMPLER_QUALITY_MAX: 10
        const AUDIO_RESAMPLER_QUALITY_MIN: 0
        const DSD_FORMATS_ALL: "{ DSDU32BE, DSDU16BE, DSDU8, DSDU32LE, DSDU16LE }"
        const DSD_MEDIA_TYPE: "audio/x-dsd"
        const DSD_SILENCE_PATTERN_BYTE: 105
        const META_TAG_AUDIO_CHANNELS_STR: "channels"
        const META_TAG_AUDIO_RATE_STR: "rate"
        const META_TAG_AUDIO_STR: "audio"
        const META_TAG_DSD_PLANE_OFFSETS_STR: "dsdplaneoffsets"
        
        namespace AudioBaseSinkDiscontReason {
            const $gtype: GObject.GType<AudioBaseSinkDiscontReason>
        }

        /**
         * Different possible reasons for discontinuities. This enum is useful for the custom
         * slave method.
         * @since 1.6
         */
        enum AudioBaseSinkDiscontReason {
            /**
             * No discontinuity occurred
             */
            "NO_DISCONT" = 0,
            /**
             * New caps are set, causing renegotiotion
             */
            "NEW_CAPS" = 1,
            /**
             * Samples have been flushed
             */
            "FLUSH" = 2,
            /**
             * Sink was synchronized to the estimated latency (occurs during initialization)
             */
            "SYNC_LATENCY" = 3,
            /**
             * Aligning buffers failed because the timestamps are too discontinuous
             */
            "ALIGNMENT" = 4,
            /**
             * Audio output device experienced and recovered from an error but introduced latency in the process (see also gst_audio_base_sink_report_device_failure())
             */
            "DEVICE_FAILURE" = 5,
        }
        
        namespace AudioBaseSinkSlaveMethod {
            const $gtype: GObject.GType<AudioBaseSinkSlaveMethod>
        }

        /**
         * Different possible clock slaving algorithms used when the internal audio
         * clock is not selected as the pipeline master clock.
         */
        enum AudioBaseSinkSlaveMethod {
            /**
             * Resample to match the master clock
             */
            "RESAMPLE" = 0,
            /**
             * Adjust playout pointer when master clock
             * drifts too much.
             */
            "SKEW" = 1,
            /**
             * No adjustment is done.
             */
            "NONE" = 2,
            /**
             * Use custom clock slaving algorithm (Since: 1.6)
             */
            "CUSTOM" = 3,
        }
        
        namespace AudioBaseSrcSlaveMethod {
            const $gtype: GObject.GType<AudioBaseSrcSlaveMethod>
        }

        /**
         * Different possible clock slaving algorithms when the internal audio clock was
         * not selected as the pipeline clock.
         */
        enum AudioBaseSrcSlaveMethod {
            /**
             * Resample to match the master clock.
             */
            "RESAMPLE" = 0,
            /**
             * Retimestamp output buffers with master
             * clock time.
             */
            "RE_TIMESTAMP" = 1,
            /**
             * Adjust capture pointer when master clock
             * drifts too much.
             */
            "SKEW" = 2,
            /**
             * No adjustment is done.
             */
            "NONE" = 3,
        }
        
        namespace AudioCdSrcMode {
            const $gtype: GObject.GType<AudioCdSrcMode>
        }

        /**
         * Mode in which the CD audio source operates. Influences timestamping,
         * EOS handling and seeking.
         */
        enum AudioCdSrcMode {
            /**
             * each single track is a stream
             */
            "NORMAL" = 0,
            /**
             * the entire disc is a single stream
             */
            "CONTINUOUS" = 1,
        }
        
        namespace AudioChannelPosition {
            const $gtype: GObject.GType<AudioChannelPosition>
        }

        /**
         * Audio channel positions.
         *
         * These are the channels defined in SMPTE 2036-2-2008
         * Table 1 for 22.2 audio systems with the Surround and Wide channels from
         * DTS Coherent Acoustics (v.1.3.1) and 10.2 and 7.1 layouts. In the caps the
         * actual channel layout is expressed with a channel count and a channel mask,
         * which describes the existing channels. The positions in the bit mask correspond
         * to the enum values.
         * For negotiation it is allowed to have more bits set in the channel mask than
         * the number of channels to specify the allowed channel positions but this is
         * not allowed in negotiated caps. It is not allowed in any situation other
         * than the one mentioned below to have less bits set in the channel mask than
         * the number of channels.
         *
         * @GST_AUDIO_CHANNEL_POSITION_MONO can only be used with a single mono channel that
         * has no direction information and would be mixed into all directional channels.
         * This is expressed in caps by having a single channel and no channel mask.
         *
         * @GST_AUDIO_CHANNEL_POSITION_NONE can only be used if all channels have this position.
         * This is expressed in caps by having a channel mask with no bits set.
         *
         * As another special case it is allowed to have two channels without a channel mask.
         * This implicitly means that this is a stereo stream with a front left and front right
         * channel.
         */
        enum AudioChannelPosition {
            /**
             * used for position-less channels, e.g.
             *     from a sound card that records 1024 channels; mutually exclusive with
             *     any other channel position
             */
            "NONE" = -3,
            /**
             * Mono without direction;
             *     can only be used with 1 channel
             */
            "MONO" = -2,
            /**
             * invalid position
             */
            "INVALID" = -1,
            /**
             * Front left
             */
            "FRONT_LEFT" = 0,
            /**
             * Front right
             */
            "FRONT_RIGHT" = 1,
            /**
             * Front center
             */
            "FRONT_CENTER" = 2,
            /**
             * Low-frequency effects 1 (subwoofer)
             */
            "LFE1" = 3,
            /**
             * Rear left
             */
            "REAR_LEFT" = 4,
            /**
             * Rear right
             */
            "REAR_RIGHT" = 5,
            /**
             * Front left of center
             */
            "FRONT_LEFT_OF_CENTER" = 6,
            /**
             * Front right of center
             */
            "FRONT_RIGHT_OF_CENTER" = 7,
            /**
             * Rear center
             */
            "REAR_CENTER" = 8,
            /**
             * Low-frequency effects 2 (subwoofer)
             */
            "LFE2" = 9,
            /**
             * Side left
             */
            "SIDE_LEFT" = 10,
            /**
             * Side right
             */
            "SIDE_RIGHT" = 11,
            /**
             * Top front left
             */
            "TOP_FRONT_LEFT" = 12,
            /**
             * Top front right
             */
            "TOP_FRONT_RIGHT" = 13,
            /**
             * Top front center
             */
            "TOP_FRONT_CENTER" = 14,
            /**
             * Top center
             */
            "TOP_CENTER" = 15,
            /**
             * Top rear left
             */
            "TOP_REAR_LEFT" = 16,
            /**
             * Top rear right
             */
            "TOP_REAR_RIGHT" = 17,
            /**
             * Top side right
             */
            "TOP_SIDE_LEFT" = 18,
            /**
             * Top rear right
             */
            "TOP_SIDE_RIGHT" = 19,
            /**
             * Top rear center
             */
            "TOP_REAR_CENTER" = 20,
            /**
             * Bottom front center
             */
            "BOTTOM_FRONT_CENTER" = 21,
            /**
             * Bottom front left
             */
            "BOTTOM_FRONT_LEFT" = 22,
            /**
             * Bottom front right
             */
            "BOTTOM_FRONT_RIGHT" = 23,
            /**
             * Wide left (between front left and side left)
             */
            "WIDE_LEFT" = 24,
            /**
             * Wide right (between front right and side right)
             */
            "WIDE_RIGHT" = 25,
            /**
             * Surround left (between rear left and side left)
             */
            "SURROUND_LEFT" = 26,
            /**
             * Surround right (between rear right and side right)
             */
            "SURROUND_RIGHT" = 27,
            /**
             * Top surround left (between rear left and side left).
             * @since 1.26
             */
            "TOP_SURROUND_LEFT" = 28,
            /**
             * Top surround right (between rear right and side right).
             * @since 1.26
             */
            "TOP_SURROUND_RIGHT" = 29,
        }
        
        namespace AudioDitherMethod {
            const $gtype: GObject.GType<AudioDitherMethod>
        }

        /**
         * Set of available dithering methods.
         */
        enum AudioDitherMethod {
            /**
             * No dithering
             */
            "NONE" = 0,
            /**
             * Rectangular dithering
             */
            "RPDF" = 1,
            /**
             * Triangular dithering (default)
             */
            "TPDF" = 2,
            /**
             * High frequency triangular dithering
             */
            "TPDF_HF" = 3,
        }
        
        namespace AudioFormat {
            const $gtype: GObject.GType<AudioFormat>
        }

        /**
         * Enum value describing the most common audio formats.
         */
        enum AudioFormat {
            /**
             * unknown or unset audio format
             */
            "UNKNOWN" = 0,
            /**
             * encoded audio format
             */
            "ENCODED" = 1,
            /**
             * 8 bits in 8 bits, signed
             */
            "S8" = 2,
            /**
             * 8 bits in 8 bits, unsigned
             */
            "U8" = 3,
            /**
             * 16 bits in 16 bits, signed, little endian
             */
            "S16LE" = 4,
            /**
             * 16 bits in 16 bits, signed, big endian
             */
            "S16BE" = 5,
            /**
             * 16 bits in 16 bits, unsigned, little endian
             */
            "U16LE" = 6,
            /**
             * 16 bits in 16 bits, unsigned, big endian
             */
            "U16BE" = 7,
            /**
             * 24 bits in 32 bits, signed, little endian
             */
            "S24_32LE" = 8,
            /**
             * 24 bits in 32 bits, signed, big endian
             */
            "S24_32BE" = 9,
            /**
             * 24 bits in 32 bits, unsigned, little endian
             */
            "U24_32LE" = 10,
            /**
             * 24 bits in 32 bits, unsigned, big endian
             */
            "U24_32BE" = 11,
            /**
             * 32 bits in 32 bits, signed, little endian
             */
            "S32LE" = 12,
            /**
             * 32 bits in 32 bits, signed, big endian
             */
            "S32BE" = 13,
            /**
             * 32 bits in 32 bits, unsigned, little endian
             */
            "U32LE" = 14,
            /**
             * 32 bits in 32 bits, unsigned, big endian
             */
            "U32BE" = 15,
            /**
             * 24 bits in 24 bits, signed, little endian
             */
            "S24LE" = 16,
            /**
             * 24 bits in 24 bits, signed, big endian
             */
            "S24BE" = 17,
            /**
             * 24 bits in 24 bits, unsigned, little endian
             */
            "U24LE" = 18,
            /**
             * 24 bits in 24 bits, unsigned, big endian
             */
            "U24BE" = 19,
            /**
             * 20 bits in 24 bits, signed, little endian
             */
            "S20LE" = 20,
            /**
             * 20 bits in 24 bits, signed, big endian
             */
            "S20BE" = 21,
            /**
             * 20 bits in 24 bits, unsigned, little endian
             */
            "U20LE" = 22,
            /**
             * 20 bits in 24 bits, unsigned, big endian
             */
            "U20BE" = 23,
            /**
             * 18 bits in 24 bits, signed, little endian
             */
            "S18LE" = 24,
            /**
             * 18 bits in 24 bits, signed, big endian
             */
            "S18BE" = 25,
            /**
             * 18 bits in 24 bits, unsigned, little endian
             */
            "U18LE" = 26,
            /**
             * 18 bits in 24 bits, unsigned, big endian
             */
            "U18BE" = 27,
            /**
             * 32-bit floating point samples, little endian
             */
            "F32LE" = 28,
            /**
             * 32-bit floating point samples, big endian
             */
            "F32BE" = 29,
            /**
             * 64-bit floating point samples, little endian
             */
            "F64LE" = 30,
            /**
             * 64-bit floating point samples, big endian
             */
            "F64BE" = 31,
            /**
             * 16 bits in 16 bits, signed, native endianness
             */
            "S16" = 4,
            /**
             * 16 bits in 16 bits, unsigned, native endianness
             */
            "U16" = 6,
            /**
             * 24 bits in 32 bits, signed, native endianness
             */
            "S24_32" = 8,
            /**
             * 24 bits in 32 bits, unsigned, native endianness
             */
            "U24_32" = 10,
            /**
             * 32 bits in 32 bits, signed, native endianness
             */
            "S32" = 12,
            /**
             * 32 bits in 32 bits, unsigned, native endianness
             */
            "U32" = 14,
            /**
             * 24 bits in 24 bits, signed, native endianness
             */
            "S24" = 16,
            /**
             * 24 bits in 24 bits, unsigned, native endianness
             */
            "U24" = 18,
            /**
             * 20 bits in 24 bits, signed, native endianness
             */
            "S20" = 20,
            /**
             * 20 bits in 24 bits, unsigned, native endianness
             */
            "U20" = 22,
            /**
             * 18 bits in 24 bits, signed, native endianness
             */
            "S18" = 24,
            /**
             * 18 bits in 24 bits, unsigned, native endianness
             */
            "U18" = 26,
            /**
             * 32-bit floating point samples, native endianness
             */
            "F32" = 28,
            /**
             * 64-bit floating point samples, native endianness
             */
            "F64" = 30,
        }
        /**
         * Construct a #GstAudioFormat with given parameters.
         * @param sign signed or unsigned format
         * @param endianness G_LITTLE_ENDIAN or G_BIG_ENDIAN
         * @param width amount of bits used per sample
         * @param depth amount of used bits in @width
         * @returns a #GstAudioFormat or GST_AUDIO_FORMAT_UNKNOWN when no audio format exists with the given parameters.
         */
        function build_integer(sign: boolean, endianness: number, width: number, depth: number): AudioFormat
        /**
         * Fill @length bytes in @dest with silence samples for @info.
         * @deprecated since 1.20 Use gst_audio_format_info_fill_silence() instead.
         * @param info a #GstAudioFormatInfo
         * @param dest a destination
          to fill
         */
        function fill_silence(info: AudioFormatInfo, dest: Uint8Array): void
        /**
         * Convert the @format string to its #GstAudioFormat.
         * @param format a format string
         * @returns the #GstAudioFormat for `format` or GST_AUDIO_FORMAT_UNKNOWN when the string is not a known format.
         */
        function from_string(format: string): AudioFormat
        /**
         * Get the #GstAudioFormatInfo for @format
         * @param format a #GstAudioFormat
         * @returns The #GstAudioFormatInfo for `format`.
         */
        function get_info(format: AudioFormat): AudioFormatInfo
        /**
         * Returns a string containing a descriptive name for the #GstAudioFormat.
         *
         * Since 1.26 this can also be used with %GST_AUDIO_FORMAT_UNKNOWN, previous
         * versions were printing a critical warning and returned %NULL.
         * @param format a #GstAudioFormat audio format
         * @returns the name corresponding to `format`
         */
        function to_string(format: AudioFormat): string
        
        namespace AudioLayout {
            const $gtype: GObject.GType<AudioLayout>
        }

        /**
         * Layout of the audio samples for the different channels.
         */
        enum AudioLayout {
            /**
             * interleaved audio
             */
            "INTERLEAVED" = 0,
            /**
             * non-interleaved audio
             */
            "NON_INTERLEAVED" = 1,
        }
        
        namespace AudioNoiseShapingMethod {
            const $gtype: GObject.GType<AudioNoiseShapingMethod>
        }

        /**
         * Set of available noise shaping methods
         */
        enum AudioNoiseShapingMethod {
            /**
             * No noise shaping (default)
             */
            "NONE" = 0,
            /**
             * Error feedback
             */
            "ERROR_FEEDBACK" = 1,
            /**
             * Simple 2-pole noise shaping
             */
            "SIMPLE" = 2,
            /**
             * Medium 5-pole noise shaping
             */
            "MEDIUM" = 3,
            /**
             * High 8-pole noise shaping
             */
            "HIGH" = 4,
        }
        
        namespace AudioResamplerFilterInterpolation {
            const $gtype: GObject.GType<AudioResamplerFilterInterpolation>
        }

        /**
         * The different filter interpolation methods.
         * @since 1.10
         */
        enum AudioResamplerFilterInterpolation {
            /**
             * no interpolation
             */
            "NONE" = 0,
            /**
             * linear interpolation of the
             *   filter coefficients.
             */
            "LINEAR" = 1,
            /**
             * cubic interpolation of the
             *   filter coefficients.
             */
            "CUBIC" = 2,
        }
        
        namespace AudioResamplerFilterMode {
            const $gtype: GObject.GType<AudioResamplerFilterMode>
        }

        /**
         * Select for the filter tables should be set up.
         * @since 1.10
         */
        enum AudioResamplerFilterMode {
            /**
             * Use interpolated filter tables. This
             *     uses less memory but more CPU and is slightly less accurate but it allows for more
             *     efficient variable rate resampling with gst_audio_resampler_update().
             */
            "INTERPOLATED" = 0,
            /**
             * Use full filter table. This uses more memory
             *     but less CPU.
             */
            "FULL" = 1,
            /**
             * Automatically choose between interpolated
             *     and full filter tables.
             */
            "AUTO" = 2,
        }
        
        namespace AudioResamplerMethod {
            const $gtype: GObject.GType<AudioResamplerMethod>
        }

        /**
         * Different subsampling and upsampling methods
         * @since 1.10
         */
        enum AudioResamplerMethod {
            /**
             * Duplicates the samples when
             *    upsampling and drops when downsampling
             */
            "NEAREST" = 0,
            /**
             * Uses linear interpolation to reconstruct
             *    missing samples and averaging to downsample
             */
            "LINEAR" = 1,
            /**
             * Uses cubic interpolation
             */
            "CUBIC" = 2,
            /**
             * Uses Blackman-Nuttall windowed sinc interpolation
             */
            "BLACKMAN_NUTTALL" = 3,
            /**
             * Uses Kaiser windowed sinc interpolation
             */
            "KAISER" = 4,
        }
        
        namespace AudioRingBufferFormatType {
            const $gtype: GObject.GType<AudioRingBufferFormatType>
        }

        /**
         * The format of the samples in the ringbuffer.
         */
        enum AudioRingBufferFormatType {
            /**
             * samples in linear or float
             */
            "RAW" = 0,
            /**
             * samples in mulaw
             */
            "MU_LAW" = 1,
            /**
             * samples in alaw
             */
            "A_LAW" = 2,
            /**
             * samples in ima adpcm
             */
            "IMA_ADPCM" = 3,
            /**
             * samples in mpeg audio (but not AAC) format
             */
            "MPEG" = 4,
            /**
             * samples in gsm format
             */
            "GSM" = 5,
            /**
             * samples in IEC958 frames (e.g. AC3)
             */
            "IEC958" = 6,
            /**
             * samples in AC3 format
             */
            "AC3" = 7,
            /**
             * samples in EAC3 format
             */
            "EAC3" = 8,
            /**
             * samples in DTS format
             */
            "DTS" = 9,
            /**
             * samples in MPEG-2 AAC ADTS format
             */
            "MPEG2_AAC" = 10,
            /**
             * samples in MPEG-4 AAC ADTS format
             */
            "MPEG4_AAC" = 11,
            /**
             * samples in MPEG-2 AAC raw format (Since: 1.12)
             */
            "MPEG2_AAC_RAW" = 12,
            /**
             * samples in MPEG-4 AAC raw format (Since: 1.12)
             */
            "MPEG4_AAC_RAW" = 13,
            /**
             * samples in FLAC format (Since: 1.12)
             */
            "FLAC" = 14,
            /**
             * samples in DSD format (Since: 1.24)
             */
            "DSD" = 15,
        }
        
        namespace AudioRingBufferState {
            const $gtype: GObject.GType<AudioRingBufferState>
        }

        /**
         * The state of the ringbuffer.
         */
        enum AudioRingBufferState {
            /**
             * The ringbuffer is stopped
             */
            "STOPPED" = 0,
            /**
             * The ringbuffer is paused
             */
            "PAUSED" = 1,
            /**
             * The ringbuffer is started
             */
            "STARTED" = 2,
            /**
             * The ringbuffer has encountered an
             *     error after it has been started, e.g. because the device was
             *     disconnected (Since: 1.2)
             */
            "ERROR" = 3,
        }
        
        namespace DsdFormat {
            const $gtype: GObject.GType<DsdFormat>
        }

        /**
         * Enum value describing how DSD bits are grouped.
         * @since 1.24
         */
        enum DsdFormat {
            /**
             * unknown / invalid DSD format
             */
            "DSD_FORMAT_UNKNOWN" = 0,
            /**
             * 8 DSD bits in 1 byte
             */
            "DSD_FORMAT_U8" = 1,
            /**
             * 16 DSD bits in 2 bytes, little endian order
             */
            "DSD_FORMAT_U16LE" = 2,
            /**
             * 16 DSD bits in 2 bytes, big endian order
             */
            "DSD_FORMAT_U16BE" = 3,
            /**
             * 32 DSD bits in 4 bytes, little endian order
             */
            "DSD_FORMAT_U32LE" = 4,
            /**
             * 32 DSD bits in 4 bytes, big endian order
             */
            "DSD_FORMAT_U32BE" = 5,
            /**
             * number of valid DSD formats
             */
            "NUM_DSD_FORMATS" = 6,
            /**
             * 16 DSD bits in 2 bytes, native endianness
             */
            "DSD_FORMAT_U16" = 2,
            /**
             * 32 DSD bits in 4 bytes, native endianness
             */
            "DSD_FORMAT_U32" = 4,
        }
        /**
         * Convert the DSD format string @str to its #GstDsdFormat.
         * @since 1.24
         * @param str a DSD format string
         * @returns the #GstDsdFormat for `format` or GST_DSD_FORMAT_UNKNOWN when the string is not a known format.
         */
        function from_string(str: string): DsdFormat
        /**
         * @since 1.24
         * @param format a #GstDsdFormat
         * @returns Number of bytes in this DSD grouping format.
         */
        function get_width(format: DsdFormat): number
        /**
         * Returns a string containing a descriptive name for
         * the #GstDsdFormat if there is one, or NULL otherwise.
         * @since 1.24
         * @param format a #GstDsdFormat
         * @returns the name corresponding to `format`
         */
        function to_string(format: DsdFormat): string
        
        namespace StreamVolumeFormat {
            const $gtype: GObject.GType<StreamVolumeFormat>
        }

        /**
         * Different representations of a stream volume. gst_stream_volume_convert_volume()
         * allows to convert between the different representations.
         *
         * Formulas to convert from a linear to a cubic or dB volume are
         * cbrt(val) and 20 * log10 (val).
         */
        enum StreamVolumeFormat {
            /**
             * Linear scale factor, 1.0 = 100%
             */
            "LINEAR" = 0,
            /**
             * Cubic volume scale
             */
            "CUBIC" = 1,
            /**
             * Logarithmic volume scale (dB, amplitude not power)
             */
            "DB" = 2,
        }
        
        namespace AudioChannelMixerFlags {
            const $gtype: GObject.GType<AudioChannelMixerFlags>
        }

        /**
         * Flags passed to gst_audio_channel_mixer_new()
         */
        enum AudioChannelMixerFlags {
            /**
             * no flag
             */
            "NONE" = 0,
            /**
             * input channels are not interleaved
             */
            "NON_INTERLEAVED_IN" = 1,
            /**
             * output channels are not interleaved
             */
            "NON_INTERLEAVED_OUT" = 2,
            /**
             * input channels are explicitly unpositioned
             */
            "UNPOSITIONED_IN" = 4,
            /**
             * output channels are explicitly unpositioned
             */
            "UNPOSITIONED_OUT" = 8,
        }
        
        namespace AudioConverterFlags {
            const $gtype: GObject.GType<AudioConverterFlags>
        }

        /**
         * Extra flags passed to gst_audio_converter_new() and gst_audio_converter_samples().
         */
        enum AudioConverterFlags {
            /**
             * no flag
             */
            "NONE" = 0,
            /**
             * the input sample arrays are writable and can be
             *    used as temporary storage during conversion.
             */
            "IN_WRITABLE" = 1,
            /**
             * allow arbitrary rate updates with
             *    gst_audio_converter_update_config().
             */
            "VARIABLE_RATE" = 2,
        }
        
        namespace AudioFlags {
            const $gtype: GObject.GType<AudioFlags>
        }

        /**
         * Extra audio flags
         */
        enum AudioFlags {
            /**
             * no valid flag
             */
            "NONE" = 0,
            /**
             * the position array explicitly
             *     contains unpositioned channels.
             */
            "UNPOSITIONED" = 1,
        }
        
        namespace AudioFormatFlags {
            const $gtype: GObject.GType<AudioFormatFlags>
        }

        /**
         * The different audio flags that a format info can have.
         */
        enum AudioFormatFlags {
            /**
             * integer samples
             */
            "INTEGER" = 1,
            /**
             * float samples
             */
            "FLOAT" = 2,
            /**
             * signed samples
             */
            "SIGNED" = 4,
            /**
             * complex layout
             */
            "COMPLEX" = 16,
            /**
             * the format can be used in
             * #GstAudioFormatUnpack and #GstAudioFormatPack functions
             */
            "UNPACK" = 32,
        }
        
        namespace AudioPackFlags {
            const $gtype: GObject.GType<AudioPackFlags>
        }

        /**
         * The different flags that can be used when packing and unpacking.
         */
        enum AudioPackFlags {
            /**
             * No flag
             */
            "NONE" = 0,
            /**
             * When the source has a smaller depth
             *   than the target format, set the least significant bits of the target
             *   to 0. This is likely slightly faster but less accurate. When this flag
             *   is not specified, the most significant bits of the source are duplicated
             *   in the least significant bits of the destination.
             */
            "TRUNCATE_RANGE" = 1,
        }
        
        namespace AudioQuantizeFlags {
            const $gtype: GObject.GType<AudioQuantizeFlags>
        }

        /**
         * Extra flags that can be passed to gst_audio_quantize_new()
         */
        enum AudioQuantizeFlags {
            /**
             * no flags
             */
            "NONE" = 0,
            /**
             * samples are non-interleaved
             */
            "NON_INTERLEAVED" = 1,
        }
        
        namespace AudioResamplerFlags {
            const $gtype: GObject.GType<AudioResamplerFlags>
        }

        /**
         * Different resampler flags.
         * @since 1.10
         */
        enum AudioResamplerFlags {
            /**
             * no flags
             */
            "NONE" = 0,
            /**
             * input samples are non-interleaved.
             *    an array of blocks of samples, one for each channel, should be passed to the
             *    resample function.
             */
            "NON_INTERLEAVED_IN" = 1,
            /**
             * output samples are non-interleaved.
             *    an array of blocks of samples, one for each channel, should be passed to the
             *    resample function.
             */
            "NON_INTERLEAVED_OUT" = 2,
            /**
             * optimize for dynamic updates of the sample
             *    rates with gst_audio_resampler_update(). This will select an interpolating filter
             *    when #GST_AUDIO_RESAMPLER_FILTER_MODE_AUTO is configured.
             */
            "VARIABLE_RATE" = 4,
        }
        /**
         *  etime
         * means it is going faster than the internal clock. etime and itime are always
         * valid timestamps, except for when a discontinuity happens.
         *
         * requested_skew is an output value the callback can write to. It informs the
         * sink of whether or not it should move the playout pointer, and if so, by how
         * much. This pointer is only NULL if a discontinuity occurs; otherwise, it is
         * safe to write to *requested_skew. The default skew is 0.
         *
         * The sink may experience discontinuities. If one happens, discont is TRUE,
         * itime, etime are set to GST_CLOCK_TIME_NONE, and requested_skew is NULL.
         * This makes it possible to reset custom clock slaving algorithms when a
         * discontinuity happens.
         * @since 1.6
         * @param sink a #GstAudioBaseSink
         * @param etime external clock time
         * @param itime internal clock time
         * @param requested_skew skew amount requested by the callback
         * @param discont_reason reason for discontinuity (if any)
         */
        type AudioBaseSinkCustomSlavingCallback = (sink: AudioBaseSink, etime: Gst.ClockTime, itime: Gst.ClockTime, requested_skew: Gst.ClockTimeDiff, discont_reason: AudioBaseSinkDiscontReason) => void
        /**
         * This function will be called whenever the current clock time needs to be
         * calculated. If this function returns #GST_CLOCK_TIME_NONE, the last reported
         * time will be returned by the clock.
         * @param clock the #GstAudioClock
         * @returns the current time or #GST_CLOCK_TIME_NONE if the previous time should be used.
         */
        type AudioClockGetTimeFunc = (clock: Gst.Clock) => Gst.ClockTime
        /**
         * Packs @length samples from @src to the data array in format @info.
         * The samples from source have each channel interleaved
         * and will be packed into @data.
         * @param info a #GstAudioFormatInfo
         * @param flags #GstAudioPackFlags
         * @param src a source array
         * @param data pointer to the destination
          data
         * @param length the amount of samples to pack.
         */
        type AudioFormatPack = (info: AudioFormatInfo, flags: AudioPackFlags, src: Uint8Array, data: Uint8Array, length: number) => void
        /**
         * Unpacks @length samples from the given data of format @info.
         * The samples will be unpacked into @dest which each channel
         * interleaved. @dest should at least be big enough to hold @length *
         * channels * size(unpack_format) bytes.
         * @param info a #GstAudioFormatInfo
         * @param flags #GstAudioPackFlags
         * @param dest a destination array
         * @param data pointer to the audio data
         * @param length the amount of samples to unpack.
         */
        type AudioFormatUnpack = (info: AudioFormatInfo, flags: AudioPackFlags, dest: Uint8Array, data: Uint8Array, length: number) => void
        /**
         * This function is set with gst_audio_ring_buffer_set_callback() and is
         * called to fill the memory at @data with @len bytes of samples.
         * @param rbuf a #GstAudioRingBuffer
         * @param data target to fill
         */
        type AudioRingBufferCallback = (rbuf: AudioRingBuffer, data: Uint8Array) => void
    }

    export default GstAudio
}